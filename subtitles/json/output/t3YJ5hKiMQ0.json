{
  "video_id": "t3YJ5hKiMQ0",
  "sentences": [
    {
      "id": 1,
      "text": "hi everyone today we are continuing our hi everyone today we are continuing our implementation of make more our favorite implementation of make more our favorite implementation of make more our favorite character level language model character level language model character level language model",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 2,
      "text": "now you'll notice that the background now you'll notice that the background now you'll notice that the background behind me is different that's because I behind me is different that's because I behind me is different that's because I am in Kyoto and it is awesome",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 3,
      "text": "so I'm in am in Kyoto and it is awesome",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 4,
      "text": "so I'm in am in Kyoto and it is awesome",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 5,
      "text": "so I'm in a hotel room here a hotel room here a hotel room here now over the last few lectures we've now over the last few lectures we've now over the last few lectures we've built up to this architecture that is a built up to this architecture that is a built up to this architecture that is a multi-layer perceptron character level multi-layer perceptron character level multi-layer perceptron character level language model",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 6,
      "text": "so we see that it language model",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 7,
      "text": "so we see that it language model",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 8,
      "text": "so we see that it receives three previous characters and receives three previous characters and receives three previous characters and tries to predict the fourth character in tries to predict the fourth character in tries to predict the fourth character in a sequence using a very simple multi a sequence using a very simple multi a sequence using a very simple multi perceptron using one hidden layer of perceptron using one hidden layer of perceptron using one hidden layer of neurons with 10ational neuralities neurons with 10ational neuralities neurons with 10ational neuralities so we'd like to do now in this lecture",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 9,
      "text": "so we'd like to do now in this lecture",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 10,
      "text": "so we'd like to do now in this lecture is I'd like to complexify this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 11,
      "text": "is I'd like to complexify this is I'd like to complexify this architecture in particular we would like architecture in particular we would like architecture in particular we would like to take more characters in a sequence as to take more characters in a sequence as to take more characters in a sequence as an input not just three and in addition an input not just three and in addition an input not just three and in addition to that we don't just want to feed them to that we don't just want to feed them to that we don't just want to feed them all into a single hidden layer because all into a single hidden layer because all into a single hidden layer because that squashes too much information too that squashes too much information too that squashes too much information too quickly instead we would like to make a quickly instead we would like to make a quickly instead we would like to make a deeper model that progressively fuses deeper model that progressively fuses deeper model that progressively fuses this information to make its guess about this information to make its guess about this information to make its guess about the next character in a sequence the next character in a sequence the next character in a sequence and so we'll see that as we make this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 12,
      "text": "and so we'll see that as we make this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 13,
      "text": "and so we'll see that as we make this architecture more complex we're actually architecture more complex we're actually architecture more complex we're actually going to arrive at something that looks going to arrive at something that looks going to arrive at something that looks very much like a wavenet very much like a wavenet very much like a wavenet the witness is this paper published by the witness is this paper published by the witness is this paper published by the point in 2016 and it is also a the point in 2016 and it is also a the point in 2016 and it is also a language model basically but it tries to language model basically but it tries to language model basically but it tries to predict audio sequences instead of predict audio sequences instead of predict audio sequences instead of character level sequences or Word level character level sequences or Word level character level sequences or Word level sequences but fundamentally the modeling sequences but fundamentally the modeling sequences but fundamentally the modeling setup is identical it is an auto setup is identical it is an auto setup is identical it is an auto aggressive model and it tries to predict aggressive model and it tries to predict aggressive model and it tries to predict next character in a sequence and the next character in a sequence and the next character in a sequence and the architecture actually takes this architecture actually takes this architecture actually takes this interesting hierarchical sort of interesting hierarchical sort of interesting hierarchical sort of approach to predicting the next approach to predicting the next approach to predicting the next character in a sequence uh with the character in a sequence uh with the character in a sequence uh with the street-like structure and this is the street-like structure and this is the street-like structure and this is the architecture and we're going to architecture and we're going to architecture and we're going to implement it in the course of this video implement it in the course of this video implement it in the course of this video",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 14,
      "text": "so let's get started so the starter code so let's get started so the starter code",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 15,
      "text": "so let's get started so the starter code for part five is very similar to where for part five is very similar to where for part five is very similar to where we ended up in in part three recall that we ended up in in part three recall that we ended up in in part three recall that part four was the manual black part four was the manual black part four was the manual black replication exercise that is kind of an replication exercise that is kind of an replication exercise that is kind of an aside",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 16,
      "text": "so we are coming back to part aside so we are coming back to part aside",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 17,
      "text": "so we are coming back to part three copy pasting chunks out of it and three copy pasting chunks out of it and three copy pasting chunks out of it and that is our starter code for part five that is our starter code for part five that is our starter code for part five I've changed very few things",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 18,
      "text": "otherwise I've changed very few things",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 19,
      "text": "otherwise I've changed very few things otherwise so a lot of this should look familiar to so a lot of this should look familiar to so a lot of this should look familiar to if you've gone through part three",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 20,
      "text": "so in if you've gone through part three so in if you've gone through part three so in particular very briefly we are doing particular very briefly we are doing particular very briefly we are doing Imports we are reading our our data set Imports we are reading our our data set Imports we are reading our our data set of words and we are processing their set of words and we are processing their set of words and we are processing their set of words into individual examples and of words into individual examples and of words into individual examples and none of this data generation code has none of this data generation code has none of this data generation code has changed and basically we have lots and changed and basically we have lots and changed and basically we have lots and lots of examples in particular we have lots of examples in particular we have lots of examples in particular we have 182 000 examples of three characters try 182 000 examples of three characters try 182 000 examples of three characters try to predict the fourth one and we've to predict the fourth one and we've to predict the fourth one and we've broken up every one of these words into broken up every one of these words into broken up every one of these words into little problems of given three little problems of given three little problems of given three characters predict the fourth one so characters predict the fourth one so characters predict the fourth one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 21,
      "text": "so this is our data set and this is what this is our data set and this is what this is our data set and this is what we're trying to get the neural lot to do we're trying to get the neural lot to do we're trying to get the neural lot to do now in part three we started to develop now in part three we started to develop now in part three we started to develop our code around these layer modules our code around these layer modules our code around these layer modules um that are for example like class um that are for example like class um that are for example like class linear and we're doing this because we linear and we're doing this because we linear and we're doing this because we want to think of these modules as want to think of these modules as want to think of these modules as building blocks and like a Lego building building blocks and like a Lego building building blocks and like a Lego building block bricks that we can sort of like block bricks that we can sort of like block bricks that we can sort of like stack up into neural networks and we can stack up into neural networks and we can stack up into neural networks and we can feed data between these layers and stack feed data between these layers and stack feed data between these layers and stack them up into a sort of graphs them up into a sort of graphs them up into a sort of graphs now we also developed these layers to now we also developed these layers to now we also developed these layers to have apis and signatures very similar to have apis and signatures very similar to have apis and signatures very similar to those that are found in pytorch so we those that are found in pytorch",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 22,
      "text": "so we those that are found in pytorch so we have torch.nn and it's got all these have torch.nn and it's got all these have torch.nn and it's got all these layer building blocks that you would use layer building blocks that you would use layer building blocks that you would use in practice and we were developing all in practice and we were developing all in practice and we were developing all of these to mimic the apis of these so of these to mimic the apis of these so of these to mimic the apis of these so for example we have linear",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 23,
      "text": "so there will for example we have linear",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 24,
      "text": "so there will for example we have linear",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 25,
      "text": "so there will also be a torch.nn.linear and its also be a torch.nn.linear and its also be a torch.nn.linear and its signature will be very similar to our signature will be very similar to our signature will be very similar to our signature and the functionality will be signature and the functionality will be signature and the functionality will be also quite identical as far as I'm aware also quite identical as far as I'm aware also quite identical as far as I'm aware so we have the linear layer with the",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 26,
      "text": "so we have the linear layer with the",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 27,
      "text": "so we have the linear layer with the Bass from 1D layer and the 10h layer",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 28,
      "text": "Bass from 1D layer and the 10h layer Bass from 1D layer and the 10h layer that we developed previously that we developed previously that we developed previously and linear just as a matrix multiply in and linear just as a matrix multiply in and linear just as a matrix multiply in the forward pass of this module batch the forward pass of this module batch the forward pass of this module batch number of course is this crazy layer number of course is this crazy layer number of course is this crazy layer that we developed in the previous that we developed in the previous that we developed in the previous lecture and what's crazy about it is lecture and what's crazy about it is lecture and what's crazy about it is well there's many things number one it",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 29,
      "text": "well there's many things number one it",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 30,
      "text": "well there's many things number one it has these running mean and variances has these running mean and variances has these running mean and variances that are trained outside of back that are trained outside of back that are trained outside of back propagation they are trained using propagation they are trained using propagation they are trained using exponential moving average inside this exponential moving average inside this exponential moving average inside this layer when we call the forward pass layer when we call the forward pass layer when we call the forward pass in addition to that in addition to that in addition to that there's this training plug because the there's this training plug because the there's this training plug because the behavior of bathroom is different during behavior of bathroom is different during behavior of bathroom is different during train time and evaluation time and so train time and evaluation time and so train time and evaluation time",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 31,
      "text": "and so suddenly we have to be very careful that suddenly we have to be very careful that suddenly we have to be very careful that bash form is in its correct state that bash form is in its correct state that bash form is in its correct state that it's in the evaluation state or training it's in the evaluation state or training it's in the evaluation state or training state",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 32,
      "text": "so that's something to now keep state so that's something to now keep state",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 33,
      "text": "so that's something to now keep track of something that sometimes track of something that sometimes track of something that sometimes introduces bugs introduces bugs introduces bugs uh because you forget to put it into the uh because you forget to put it into the uh because you forget to put it into the right mode and finally we saw that right mode",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 34,
      "text": "and finally we saw that right mode",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 35,
      "text": "and finally we saw that Bachelor couples the statistics or the Bachelor couples the statistics or the Bachelor couples the statistics or the the activations across the examples in the activations across the examples in the activations across the examples in the batch",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 36,
      "text": "so normally we thought of the the batch",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 37,
      "text": "so normally we thought of the the batch",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 38,
      "text": "so normally we thought of the bat as just an efficiency thing but now bat as just an efficiency thing but now bat as just an efficiency thing",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 39,
      "text": "but now we are coupling the computation across we are coupling the computation across we are coupling the computation across batch elements",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 40,
      "text": "and it's done for the batch elements and it's done for the batch elements and it's done for the purposes of controlling the automation purposes of controlling the automation purposes of controlling the automation statistics as we saw in the previous statistics as we saw in the previous statistics as we saw in the previous video video video",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 41,
      "text": "so it's a very weird layer at least a so it's a very weird layer at least a so it's a very weird layer at least a lot of bugs lot of bugs lot of bugs partly for example because you have to partly for example because you have to partly for example because you have to modulate the training in eval phase and modulate the training in eval phase and modulate the training in eval phase and so on so on so on um in addition for example you have to um in addition for example you have to um in addition for example you have to wait for uh the mean and the variance to wait for uh the mean and the variance to wait for uh the mean and the variance to settle and to actually reach a steady settle and to actually reach a steady settle and to actually reach a steady state",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 42,
      "text": "and so um you have to make sure state",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 43,
      "text": "and so um you have to make sure state",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 44,
      "text": "and so um you have to make sure that you basically there's state in this that you basically there's state in this that you basically there's state in this layer and state is harmful uh usually layer and state is harmful uh usually layer and state is harmful uh usually now I brought out the generator object",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 45,
      "text": "now I brought out the generator object now I brought out the generator object",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 46,
      "text": "previously we had a generator equals g previously we had a generator equals g previously we had a generator equals g and so on inside these layers I've and so on inside these layers I've and so on inside these layers I've discarded that in favor of just discarded that in favor of just discarded that in favor of just initializing the torch RNG outside here initializing the torch RNG outside here initializing the torch RNG outside here use it just once globally just for use it just once globally just for use it just once globally just for Simplicity Simplicity Simplicity and then here we are starting to build and then here we are starting to build and then here we are starting to build out some of the neural network elements out some of the neural network elements out some of the neural network elements this should look very familiar we are we this should look very familiar we are we this should look very familiar we are we have our embedding table C and then we have our embedding table C and then we have our embedding table C and then we have a list of players and uh it's a have a list of players and uh it's a have a list of players and uh it's a linear feeds to Bachelor feeds to 10h linear feeds to Bachelor feeds to 10h linear feeds to Bachelor feeds to 10h and then a linear output layer and its and then a linear output layer and its and then a linear output layer and its weights are scaled down so we are not weights are scaled down so we are not weights are scaled down so we are not confidently wrong at the initialization confidently wrong at the initialization confidently wrong at the initialization we see that this is about 12 000 we see that this is about 12 000 we see that this is about 12 000 parameters we're telling pytorch that parameters we're telling pytorch that parameters we're telling pytorch that the parameters require gradients the parameters require gradients the parameters require gradients the optimization is as far as I'm aware the optimization is as far as I'm aware the optimization is as far as I'm aware identical and should look very very identical and should look very very identical and should look very very familiar familiar familiar nothing changed here nothing changed here nothing changed here uh loss function looks very crazy we uh loss function looks very crazy we uh loss function looks very crazy we should probably fix this and that's should probably fix this and that's should probably fix this and that's because 32 batch elements are too few because 32 batch elements are too few because 32 batch elements are too few and so you can get very lucky lucky or and so you can get very lucky lucky or and so you can get very lucky lucky or unlucky in any one of these batches and unlucky in any one of these batches and unlucky in any one of these batches and it creates a very thick loss function it creates a very thick loss function it creates a very thick loss function um so we're going to fix that soon um so we're going to fix that soon um so we're going to fix that soon now once we want to evaluate the trained now once we want to evaluate the trained now once we want to evaluate the trained neural network we need to remember neural network we need to remember neural network we need to remember because of the bathroom layers to set because of the bathroom layers to set because of the bathroom layers to set all the layers to be training equals all the layers to be training equals all the layers to be training equals false so this only matters for the false",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 47,
      "text": "so this only matters for the false so this only matters for the bathroom layer so far bathroom layer so far bathroom layer so far",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 48,
      "text": "and then we evaluate and then we evaluate and then we evaluate we see that currently we have validation we see that currently we have validation we see that currently we have validation loss of 2.10 which is fairly good but loss of 2.10 which is fairly good but loss of 2.10 which is fairly good",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 49,
      "text": "but there's still ways to go but even at there's still ways to go but even at there's still ways to go but even at 2.10 we see that when we sample from the 2.10 we see that when we sample from the 2.10 we see that when we sample from the model we actually get relatively model we actually get relatively model we actually get relatively name-like results that do not exist in a name-like results that do not exist in a name-like results that do not exist in a training set so for example Yvonne kilo training set so for example Yvonne kilo training set so for example",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 50,
      "text": "Yvonne kilo Pros Pros Pros Alaia Etc so certainly not Alaia Etc so certainly not Alaia Etc so certainly not reasonable not unreasonable I would say reasonable not unreasonable I would say reasonable not unreasonable I would say but not amazing",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 51,
      "text": "and we can still push but not amazing",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 52,
      "text": "and we can still push but not amazing",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 53,
      "text": "and we can still push this validation loss even lower and get this validation loss even lower and get this validation loss even lower and get much better samples that are even more much better samples that are even more much better samples that are even more name-like name-like name-like so let's improve this model",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 54,
      "text": "so let's improve this model so let's improve this model",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 55,
      "text": "okay first let's fix this graph because okay first let's fix this graph because okay first let's fix this graph because it is daggers in my eyes",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 56,
      "text": "and I just it is daggers in my eyes",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 57,
      "text": "and I just it is daggers in my eyes and I just can't take it anymore can't take it anymore can't take it anymore",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 58,
      "text": "um",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 59,
      "text": "so last I if you recall is a python um",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 60,
      "text": "so last I if you recall is a python um",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 61,
      "text": "so last I if you recall is a python list of floats so for example the first list of floats so for example the first list of floats so for example the first 10 elements now what we'd like to do basically is we now what we'd like to do basically is we need to average up need to average up need to average up um some of these values to get a more um some of these values to get a more um some of these values to get a more sort of Representative uh value along sort of Representative uh value along sort of Representative uh value along the way so one way to do this is the the way so one way to do this is the the way so one way to do this is the following following following in part torch if I create for example in part torch if I create for example in part torch if I create for example a tensor of the first 10 numbers a tensor of the first 10 numbers a tensor of the first 10 numbers then this is currently a one-dimensional then this is currently a one-dimensional then this is currently a one-dimensional array but recall that I can view this array but recall that I can view this array but recall that I can view this array as two-dimensional so for example array as two-dimensional so for example array as two-dimensional so for example I can use it as a two by five array and I can use it as a two by five array and I can use it as a two by five array and this is a 2d tensor now two by five and this is a 2d tensor now two by five and this is a 2d tensor now two by five and you see what petroch has done is that you see what petroch has done is that you see what petroch has done is that the first row of this tensor is the the first row of this tensor is the the first row of this tensor is the first five elements and the second row first five elements and the second row first five elements and the second row is the second five elements is the second five elements is the second five elements I can also view it as a five by two as I can also view it as a five by two as I can also view it as a five by two as an example an example an example and then recall that I can also and then recall that I can also and then recall that I can also use negative one in place of one of use negative one in place of one of use negative one in place of one of these numbers these numbers these numbers and pytorch will calculate what that and pytorch will calculate what that and pytorch will calculate what that number must be in order to make the number must be in order to make the number must be in order to make the number of elements work out so this can number of elements work out so this can number of elements work out so this can be be be this or like that but it will work of this or like that but it will work of this or like that but it will work of course this would not work",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 62,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 63,
      "text": "so this allows it to spread out",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 64,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 65,
      "text": "so this allows it to spread out some of the consecutive values into rows some of the consecutive values into rows some of the consecutive values into rows so that's very helpful because what we",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 66,
      "text": "so that's very helpful because what we",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 67,
      "text": "so that's very helpful because what we can do now is first of all we're going can do now is first of all we're going can do now is first of all we're going to create a torshot tensor out of the a to create a torshot tensor out of the a to create a torshot tensor out of the a list of floats list of floats list of floats",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 68,
      "text": "and then we're going to view it as",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 69,
      "text": "and then we're going to view it as",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 70,
      "text": "and then we're going to view it as whatever it is",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 71,
      "text": "but we're going to whatever it is",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 72,
      "text": "but we're going to whatever it is",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 73,
      "text": "but we're going to stretch it out into rows of 1000 stretch it out into rows of 1000 stretch it out into rows of 1000 consecutive elements so the shape of consecutive elements so the shape of consecutive elements so the shape of this now becomes 200 by 1000.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 74,
      "text": "and each this now becomes 200 by 1000.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 75,
      "text": "and each this now becomes 200 by 1000.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 76,
      "text": "and each row is one thousand um consecutive row is one thousand um consecutive row is one thousand um consecutive elements in this list elements in this list elements in this list so that's very helpful because now we so that's very helpful because now we so that's very helpful because now we can do a mean along the rows can do a mean along the rows can do a mean along the rows and the shape of this will just be 200.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 77,
      "text": "and the shape of this will just be 200.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 78,
      "text": "and the shape of this will just be 200.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 79,
      "text": "and so we've taken basically the mean on",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 80,
      "text": "and so we've taken basically the mean on",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 81,
      "text": "and so we've taken basically the mean on every row",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 82,
      "text": "so plt.plot of that should be every row",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 83,
      "text": "so plt.plot of that should be every row",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 84,
      "text": "so plt.plot of that should be something nicer something nicer something nicer much better much better much better so we see that we basically made a lot",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 85,
      "text": "so we see that we basically made a lot",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 86,
      "text": "so we see that we basically made a lot of progress",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 87,
      "text": "and then here this is the of progress",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 88,
      "text": "and then here this is the of progress",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 89,
      "text": "and then here this is the learning rate Decay so here we see that learning rate Decay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 90,
      "text": "so here we see that learning rate Decay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 91,
      "text": "so here we see that the learning rate Decay subtracted a ton the learning rate Decay subtracted a ton the learning rate Decay subtracted a ton of energy out of the system and allowed of energy out of the system and allowed of energy out of the system and allowed us to settle into sort of the local us to settle into sort of the local us to settle into sort of the local minimum in this optimization minimum in this optimization minimum in this optimization so this is a much nicer plot let me come so this is a much nicer plot let me come so this is a much nicer plot let me come up and delete the monster and we're up and delete the monster and we're up and delete the monster and we're going to be using this going forward now going to be using this going forward now going to be using this going forward now next up what I'm bothered by is that you next up what I'm bothered by is that you next up what I'm bothered by is that you see our forward pass is a little bit see our forward pass is a little bit see our forward pass is a little bit gnarly and takes way too many lines of gnarly and takes way too many lines of gnarly and takes way too many lines of code code code",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 92,
      "text": "so in particular we see that we've so in particular we see that we've so in particular we see that we've organized some of the layers inside the organized some of the layers inside the organized some of the layers inside the layers list but not all of them uh for layers list but not all of them uh for layers list but not all of them uh for no reason so in particular we see that no reason so in particular we see that no reason so in particular we see that we still have the embedding table a we still have the embedding table a we still have the embedding table a special case outside of the layers and special case outside of the layers and special case outside of the layers and in addition to that the viewing in addition to that the viewing in addition to that the viewing operation here is also outside of our operation here is also outside of our operation here is also outside of our layers so let's create layers for these layers so let's create layers for these layers so let's create layers for these",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 93,
      "text": "and then we can add those layers to just",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 94,
      "text": "and then we can add those layers to just",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 95,
      "text": "and then we can add those layers to just our list our list our list so in particular the two things that we so in particular the two things that we so in particular the two things that we need is here we have this embedding need is here we have this embedding need is here we have this embedding table and we are indexing at the table and we are indexing at the table and we are indexing at the integers inside uh the batch XB uh integers inside uh the batch XB uh integers inside uh the batch XB uh inside the tensor xB inside the tensor xB inside the tensor xB",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 96,
      "text": "so that's an embedding table lookup just so that's an embedding table lookup just so that's an embedding table lookup just done with indexing",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 97,
      "text": "and then here we see done with indexing",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 98,
      "text": "and then here we see done with indexing",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 99,
      "text": "and then here we see that we have this view operation which that we have this view operation which that we have this view operation which if you recall from the previous video if you recall from the previous video if you recall from the previous video Simply rearranges the character Simply rearranges the character Simply rearranges the character embeddings and stretches them out into a embeddings and stretches them out into a embeddings and stretches them out into a row and effectively what print that does row and effectively what print that does row",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 100,
      "text": "and effectively what print that does is the concatenation operation basically is the concatenation operation basically is the concatenation operation basically except it's free because viewing is very except it's free because viewing is very except it's free because viewing is very cheap in pytorch",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 101,
      "text": "no no memory is being cheap in pytorch",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 102,
      "text": "no no memory is being cheap in pytorch",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 103,
      "text": "no no memory is being copied we're just re-representing how we copied we're just re-representing how we copied we're just re-representing how we view that tensor so let's create view that tensor",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 104,
      "text": "so let's create view that tensor",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 105,
      "text": "so let's create um um um modules for both of these operations the modules for both of these operations the modules for both of these operations the embedding operation and flattening embedding operation and flattening embedding operation and flattening operation operation operation",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 106,
      "text": "so I actually wrote the code in just to",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 107,
      "text": "so I actually wrote the code in just to",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 108,
      "text": "so I actually wrote the code in just to save some time save some time save some time",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 109,
      "text": "so we have a module embedding and a so we have a module embedding and a so we have a module embedding and a module pattern and both of them simply module pattern and both of them simply module pattern and both of them simply do the indexing operation in the forward do the indexing operation in the forward do the indexing operation in the forward pass and the flattening operation here pass and the flattening operation here pass and the flattening operation here and this C now will just become a salt and this C now will just become a salt and this C now will just become a salt dot weight inside an embedding module dot weight inside an embedding module dot weight inside an embedding module and I'm calling these layers and I'm calling these layers and I'm calling these layers specifically embedding a platinum specifically embedding a platinum specifically embedding a platinum because it turns out that both of them because it turns out that both of them because it turns out that both of them actually exist in pi torch so in actually exist in pi torch so in actually exist in pi torch so in phytorch we have n and Dot embedding and phytorch we have n and Dot embedding and phytorch we have n and Dot embedding and it also takes the number of embeddings it also takes the number of embeddings it also takes the number of embeddings and the dimensionality of the bedding and the dimensionality of the bedding and the dimensionality of the bedding just like we have here but in addition just like we have here but in addition just like we have here but in addition python takes in a lot of other keyword python takes in a lot of other keyword python takes in a lot of other keyword arguments that we are not using for our arguments that we are not using for our arguments that we are not using for our purposes yet purposes yet purposes yet and for flatten that also exists in and for flatten that also exists in and for flatten that also exists in pytorch and it also takes additional pytorch and it also takes additional pytorch and it also takes additional keyword arguments that we are not using keyword arguments that we are not using keyword arguments that we are not using so we have a very simple platform",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 110,
      "text": "so we have a very simple platform",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 111,
      "text": "so we have a very simple platform but both of them exist in pytorch but both of them exist in pytorch but both of them exist in pytorch they're just a bit more simpler and now they're just a bit more simpler and now they're just a bit more simpler and now that we have these we can simply take that we have these we can simply take that we have these we can simply take out some of these special cased out some of these special cased out some of these special cased um things so instead of C we're just um things so instead of C",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 112,
      "text": "we're just um things so instead of C",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 113,
      "text": "we're just going to have an embedding going to have an embedding going to have an embedding and of a cup size and N embed and of a cup size and N embed and of a cup size and N embed and then after the embedding we are and then after the embedding we are and then after the embedding we are going to flatten going to flatten going to flatten so let's construct those modules and now so let's construct those modules and now so let's construct those modules and now I can take out this the",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 114,
      "text": "I can take out this the I can take out this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 115,
      "text": "the",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 116,
      "text": "and here I don't have to special case",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 117,
      "text": "and here I don't have to special case",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 118,
      "text": "and here I don't have to special case anymore because now C is the embeddings anymore because now C is the embeddings anymore because now C is the embeddings weight and it's inside layers weight and it's inside layers weight and it's inside layers",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 119,
      "text": "so this should just work so this should just work so this should just work",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 120,
      "text": "and then here our forward pass",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 121,
      "text": "and then here our forward pass",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 122,
      "text": "and then here our forward pass simplifies substantially because we simplifies substantially because we simplifies substantially because we don't need to do these now outside of don't need to do these now outside of don't need to do these now outside of these layer outside and explicitly these layer outside and explicitly these layer outside and explicitly they're now inside layers they're now inside layers they're now inside layers so we can delete those so we can delete those so we can delete those but now to to kick things off we want but now to to kick things off we want but now to to kick things off we want this little X which in the beginning is this little X which in the beginning is this little X which in the beginning is just XB uh the tensor of integers just XB uh the tensor of integers just XB uh the tensor of integers specifying the identities of these specifying the identities of these specifying the identities of these characters at the input characters at the input characters at the input and so these characters can now directly and so",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 123,
      "text": "these characters can now directly and so these characters can now directly feed into the first layer and this feed into the first layer and this feed into the first layer and this should just work should just work should just work so let me come here and insert a break",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 124,
      "text": "so let me come here and insert a break so let me come here and insert a break because I just want to make sure that because I just want to make sure that because I just want to make sure that the first iteration of this runs and the first iteration of this runs and the first iteration of this runs and then there's no mistake so that ran then there's no mistake so that ran then there's no mistake so that ran properly and",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 125,
      "text": "basically we substantially properly and basically we substantially properly and basically we substantially simplified the forward pass here okay simplified the forward pass here okay simplified the forward pass here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 126,
      "text": "okay I'm sorry I changed my microphone",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 127,
      "text": "so I'm sorry I changed my microphone",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 128,
      "text": "so I'm sorry I changed my microphone so hopefully the audio is a little bit hopefully the audio is a little bit hopefully the audio is a little bit better better better now one more thing that I would like to now one more thing that I would like to now one more thing that I would like to do in order to pytortify our code even do in order to pytortify our code even do in order to pytortify our code even further is that right now we are further is that right now we are further is that right now we are maintaining all of our modules in a maintaining all of our modules in a maintaining all of our modules in a naked list of layers and we can also naked list of layers and we can also naked list of layers and we can also simplify this uh because we can simplify this uh because we can simplify this uh because we can introduce the concept of Pi torch introduce the concept of Pi torch introduce the concept of Pi torch containers so in tors.nn which we are containers so in tors.nn which we are containers so in tors.nn which we are basically rebuilding from scratch here basically rebuilding from scratch here basically rebuilding from scratch here there's a concept of containers there's a concept of containers there's a concept of containers and these containers are basically a way and these containers are basically a way and these containers are basically a way of organizing layers into of organizing layers into of organizing layers into lists or dicts and so on so in lists or dicts and so on so in lists or dicts and so on so in particular there's a sequential which particular there's a sequential which particular there's a sequential which maintains a list of layers and is a maintains a list of layers and is a maintains a list of layers and is a module class in pytorch and it basically module class in pytorch and it basically module class in pytorch and it basically just passes a given input through all just passes a given input through all just passes a given input through all the layers sequentially exactly",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 129,
      "text": "as we the layers sequentially exactly",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 130,
      "text": "as we the layers sequentially exactly as we are doing here are doing here are doing here so let's write our own sequential so let's write our own sequential so let's write our own sequential I've written a code here and basically I've written a code here and basically I've written a code here and basically the code for sequential is quite the code for sequential is quite the code for sequential is quite straightforward we pass in a list of straightforward we pass in a list of straightforward we pass in a list of layers which we keep here and then given layers which we keep here and then given layers which we keep here and then given any input in a forward pass we just call any input in a forward pass we just call any input in a forward pass we just call all the layers sequentially and return all the layers sequentially and return all the layers sequentially and return the result in terms of the parameters the result in terms of the parameters the result in terms of the parameters it's just all the parameters of the it's just all the parameters of the it's just all the parameters of the child modules child modules child modules so we can run this and we can again so we can run this and we can again so we can run this and we can again simplify this substantially because we simplify this substantially because we simplify this substantially because we don't maintain this naked list of layers don't maintain this naked list of layers don't maintain this naked list of layers we now have a notion of a model which is we now have a notion of a model which is we now have a notion of a model which is a module and in particular is a a module and in particular is a a module and in particular is a sequential of all these layers and now parameters are simply just a and now parameters are simply just a model about parameters model about parameters model about parameters and so that list comprehension now lives and so that list comprehension now lives and so that list comprehension now lives here here here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 131,
      "text": "and then here we are press here we are",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 132,
      "text": "and then here we are press here we are",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 133,
      "text": "and then here we are press here we are doing all the things we used to do doing all the things we used to do doing all the things we used to do now here the code again simplifies now here the code again simplifies now here the code again simplifies substantially because we don't have to substantially because we don't have to substantially because we don't have to do this forwarding here instead of just do this forwarding here instead of just do this forwarding here instead of just call the model on the input data and the call the model on the input data and the call the model on the input data and the input data here are the integers inside input data here are the integers inside input data here are the integers inside xB so we can simply do logits which are xB so we can simply do logits which are xB so we can simply do logits which are the outputs of our model are simply the the outputs of our model are simply the the outputs of our model are simply the model called on xB model called on xB model called on xB and then the cross entropy here takes and then the cross entropy here takes and then the cross entropy here takes the logits and the targets the logits and the targets the logits and the targets so this simplifies substantially so this simplifies substantially so this simplifies substantially",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 134,
      "text": "and then this looks good",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 135,
      "text": "so let's just",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 136,
      "text": "and then this looks good",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 137,
      "text": "so let's just",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 138,
      "text": "and then this looks good",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 139,
      "text": "so let's just make sure this runs that looks good make sure this runs that looks good make sure this runs that looks good now here we actually have some work to now here we actually have some work to now here we actually have some work to do still here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 140,
      "text": "but I'm going to come back",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 141,
      "text": "do still here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 142,
      "text": "but I'm going to come back",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 143,
      "text": "do still here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 144,
      "text": "but I'm going to come back later for now there's no more layers later for now there's no more layers later for now there's no more layers there's a model that layers",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 145,
      "text": "but it's not there's a model that layers",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 146,
      "text": "but it's not there's a model that layers",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 147,
      "text": "but it's not a to access attributes of these classes a to access attributes of these classes a to access attributes of these classes directly so we'll come back and fix this directly",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 148,
      "text": "so we'll come back and fix this directly so we'll come back and fix this later later later and then here of course this simplifies and then here of course this simplifies and then here of course this simplifies substantially as well because logits are substantially as well because logits are substantially as well because logits are the model called on x the model called on x the model called on x and then these low Jets come here and then these low Jets come here and then these low Jets come here so we can evaluate the train",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 149,
      "text": "and so we can evaluate the train",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 150,
      "text": "and so we can evaluate the train and validation loss which currently is validation loss which currently is validation loss which currently is terrible because we just initialized the terrible because we just initialized the terrible because we just initialized the neural net",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 151,
      "text": "and then we can also sample neural net",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 152,
      "text": "and then we can also sample neural net",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 153,
      "text": "and then we can also sample from the model and this simplifies from the model and this simplifies from the model and this simplifies dramatically as well dramatically as well dramatically as well because we just want to call the model because we just want to call the model because we just want to call the model onto the context and outcome logits onto the context and outcome logits onto the context and outcome logits and these logits go into softmax and get and these logits go into softmax and get and these logits go into softmax and get the probabilities",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 154,
      "text": "Etc so we can sample the probabilities Etc so we can sample the probabilities",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 155,
      "text": "Etc so we can sample from this model from this model from this model what did I screw up",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 156,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 157,
      "text": "so I fixed the issue and we now get",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 158,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 159,
      "text": "so I fixed the issue and we now get the result that we expect which is the result that we expect which is the result that we expect which is gibberish because the model is not gibberish because the model is not gibberish because the model is not trained because we re-initialize it from trained because we re-initialize it from trained because we re-initialize it from scratch scratch scratch the problem was that when I fixed this the problem was that when I fixed this the problem was that when I fixed this cell to be modeled out layers instead of cell to be modeled out layers instead of cell to be modeled out layers instead of just layers I did not actually run the just layers I did not actually run the just layers I did not actually run the cell and so our neural net was in a cell and so our neural net was in a cell and so our neural net was in a training mode and what caused the issue training mode and what caused the issue training mode and what caused the issue here is the bathroom layer as bathroom here is the bathroom layer as bathroom here is the bathroom layer as bathroom layer of the likes to do because layer of the likes to do because layer of the likes to do because Bachelor was in a training mode and here Bachelor was in a training mode and here Bachelor was in a training mode and here we are passing in an input which is a we are passing in an input which is a we are passing in an input which is a batch of just a single example made up batch of just a single example made up batch of just a single example made up of the context of the context of the context",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 160,
      "text": "and so if you are trying to pass in a",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 161,
      "text": "and so if you are trying to pass in a",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 162,
      "text": "and so if you are trying to pass in a single example into a bash Norm that is single example into a bash Norm that is single example into a bash Norm that is in the training mode you're going to end in the training mode you're going to end in the training mode you're going to end up estimating the variance using the up estimating the variance using the up estimating the variance using the input and the variance of a single input and the variance of a single input and the variance of a single number is is not a number because it is number is is not a number because it is number is is not a number because it is a measure of a spread so for example the a measure of a spread so for example the a measure of a spread so for example the variance of just the single number five variance of just the single number five variance of just the single number five you can see is not a number",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 163,
      "text": "and so you can see is not a number",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 164,
      "text": "and so you can see is not a number",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 165,
      "text": "and so that's what happened in the master that's what happened in the master that's what happened in the master basically caused an issue",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 166,
      "text": "and then that basically caused an issue and then that basically caused an issue and then that polluted all of the further processing polluted all of the further processing polluted all of the further processing so all that we have to do was make sure so all that we have to do was make sure so all that we have to do was make sure that this runs and we basically made the that this runs and we basically made the that this runs and we basically made the issue of issue of issue of again we didn't actually see the issue again we didn't actually see the issue again we didn't actually see the issue with the loss we could have evaluated with the loss we could have evaluated with the loss we could have evaluated the loss",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 167,
      "text": "but we got the wrong result the loss",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 168,
      "text": "but we got the wrong result the loss",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 169,
      "text": "but we got the wrong result because basharm was in the training mode because basharm was in the training mode because basharm was in the training mode and",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 170,
      "text": "uh and so we still get a result it's",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 171,
      "text": "and uh and so we still get a result it's and",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 172,
      "text": "uh and so we still get a result it's just the wrong result because it's using just the wrong result because it's using just the wrong result because it's using the uh sample statistics of the batch the uh sample statistics of the batch the uh sample statistics of the batch whereas we want to use the running mean whereas we want to use the running mean whereas we want to use the running mean and running variants inside the bachelor and running variants inside the bachelor and running variants inside the bachelor and so and so and so again an example of introducing a bug again an example of introducing a bug again an example of introducing a bug inline because we did not properly inline because we did not properly inline because we did not properly maintain the state of what is training maintain the state of what is training maintain the state of what is training or not",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 173,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 174,
      "text": "so I Rewritten everything or not",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 175,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 176,
      "text": "so I Rewritten everything or not",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 177,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 178,
      "text": "so I Rewritten everything and here's where we are as a reminder we and here's where we are as a reminder we and here's where we are as a reminder we have the training loss of 2.05 and have the training loss of 2.05 and have the training loss of 2.05 and validation 2.10 validation 2.10 validation 2.10 now because these losses are very now because these losses are very now because these losses are very similar to each other we have a sense similar to each other we have a sense similar to each other we have a sense that we are not overfitting too much on that we are not overfitting too much on that we are not overfitting too much on this task and we can make additional this task",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 179,
      "text": "and we can make additional this task",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 180,
      "text": "and we can make additional progress in our performance by scaling progress in our performance by scaling progress in our performance by scaling up the size of the neural network and up the size of the neural network and up the size of the neural network and making everything bigger and deeper making everything bigger and deeper making everything bigger and deeper now currently we are using this now currently we are using this now currently we are using this architecture here where we are taking in architecture here where we are taking in architecture here where we are taking in some number of characters going into a some number of characters going into a some number of characters going into a single hidden layer and then going to single hidden layer and then going to single hidden layer and then going to the prediction of the next character the prediction of the next character the prediction of the next character the problem here is we don't have a the problem here is we don't have a the problem here is we don't have a naive way of making this bigger in a naive way of making this bigger in a naive way of making this bigger in a productive way we could of course use productive way we could of course use productive way we could of course use our layers sort of building blocks and our layers sort of building blocks and our layers sort of building blocks and materials to introduce additional layers materials to introduce additional layers materials to introduce additional layers here and make the network deeper but",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 181,
      "text": "it here and make the network deeper but it here and make the network deeper but it is still the case that we are crushing is still the case that we are crushing is still the case that we are crushing all of the characters into a single all of the characters into a single all of the characters into a single layer all the way at the beginning layer all the way at the beginning layer all the way at the beginning and even if we make this a bigger layer and even if we make this a bigger layer and even if we make this a bigger layer and add neurons it's still kind of like and add neurons it's still kind of like and add neurons it's still kind of like silly to squash all that information so silly to squash all that information so silly to squash all that information so fast in a single step fast in a single step fast in a single step",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 182,
      "text": "so we'd like to do instead is we'd like",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 183,
      "text": "so we'd like to do instead is we'd like",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 184,
      "text": "so we'd like to do instead is we'd like our Network to look a lot more like this our Network to look a lot more like this our Network to look a lot more like this in the wavenet case",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 185,
      "text": "so you see in the in the wavenet case",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 186,
      "text": "so you see in the in the wavenet case",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 187,
      "text": "so you see in the wavenet when we are trying to make the wavenet when we are trying to make the wavenet when we are trying to make the prediction for the next character in the prediction for the next character in the prediction for the next character in the sequence it is a function of the sequence it is a function of the sequence it is a function of the previous characters that are feeding previous characters that are feeding previous characters that are feeding that feed in but not all of these that feed in but not all of these that feed in but not all of these different characters are not just different characters are not just different characters are not just crushed to a single layer",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 188,
      "text": "and then you crushed to a single layer",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 189,
      "text": "and then you crushed to a single layer",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 190,
      "text": "and then you have a sandwich they are crushed slowly have a sandwich they are crushed slowly have a sandwich they are crushed slowly so in particular we take two characters so in particular we take two characters so in particular we take two characters and we fuse them into sort of like a",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 191,
      "text": "and we fuse them into sort of like a",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 192,
      "text": "and we fuse them into sort of like a diagram representation and we do that diagram representation and we do that diagram representation and we do that for all these characters consecutively for all these characters consecutively for all these characters consecutively",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 193,
      "text": "and then we take the bigrams and we fuse and then we take the bigrams and we fuse",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 194,
      "text": "and then we take the bigrams and we fuse those into four character level chunks those into four character level chunks those into four character level chunks",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 195,
      "text": "and then we fuse that again",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 196,
      "text": "and so we do",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 197,
      "text": "and then we fuse that again",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 198,
      "text": "and so we do",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 199,
      "text": "and then we fuse that again",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 200,
      "text": "and so we do that in this like tree-like hierarchical that in this like tree-like hierarchical that in this like tree-like hierarchical manner",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 201,
      "text": "so we fuse the information from manner",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 202,
      "text": "so we fuse the information from manner",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 203,
      "text": "so we fuse the information from the previous context slowly into the the previous context slowly into the the previous context slowly into the network as it gets deeper",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 204,
      "text": "and so this is network as it gets deeper",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 205,
      "text": "and so this is network as it gets deeper",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 206,
      "text": "and so this is the kind of architecture that we want to the kind of architecture that we want to the kind of architecture that we want to implement implement implement now in the wave Nets case this is a now in the wave Nets case this is a now in the wave Nets case this is a visualization of a stack of dilated visualization of a stack of dilated visualization of a stack of dilated causal convolution layers and this makes causal convolution layers and this makes causal convolution layers and this makes it sound very scary",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 207,
      "text": "but actually the it sound very scary",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 208,
      "text": "but actually the it sound very scary",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 209,
      "text": "but actually the idea is very simple and the fact that idea is very simple and the fact that idea is very simple and the fact that it's a dilated causal convolution layer it's a dilated causal convolution layer it's a dilated causal convolution layer is really just an implementation detail is really just an implementation detail is really just an implementation detail to make everything fast we're going to to make everything fast we're going to to make everything fast we're going to see that later but for now let's just see that later but for now let's just see that later but for now let's just keep the basic idea of it which is this keep the basic idea of it which is this keep the basic idea of it which is this Progressive Fusion so we want to make Progressive Fusion so we want to make Progressive Fusion so we want to make the network deeper and at each level we the network deeper and at each level we the network deeper and at each level we want to fuse only two consecutive want to fuse only two consecutive want to fuse only two consecutive elements two characters then two bigrams elements two characters then two bigrams elements two characters then two bigrams then two four grams and so on so let's then two four grams and so on so let's then two four grams and so on so let's unplant this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 210,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 211,
      "text": "so first up let me unplant this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 212,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 213,
      "text": "so first up let me unplant this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 214,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 215,
      "text": "so first up let me scroll to where we built the data set scroll to where we built the data set scroll to where we built the data set and let's change the block size from 3 and let's change the block size from 3 and let's change the block size from 3 to 8.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 216,
      "text": "so we're going to be taking eight to 8.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 217,
      "text": "so we're going to be taking eight to 8.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 218,
      "text": "so we're going to be taking eight characters of context to predict the characters of context to predict the characters of context to predict the ninth character so the data set now ninth character so the data set now ninth character so the data set now looks like this we have a lot more looks like this we have a lot more looks like this we have a lot more context feeding in to predict any next context feeding in to predict any next context feeding in to predict any next character in a sequence and these eight character in a sequence and these eight character in a sequence and these eight characters are going to be processed in characters are going to be processed in characters are going to be processed in this tree like structure this tree like structure this tree like structure now if we scroll here everything here now if we scroll here everything here now if we scroll here everything here should just be able to work so we should should just be able to work so we should should just be able to work so we should be able to redefine the network be able to redefine the network be able to redefine the network you see the number of parameters has you see the number of parameters has you see the number of parameters has increased by 10 000",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 219,
      "text": "and that's because increased by 10 000 and that's because increased by 10 000",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 220,
      "text": "and that's because the block size has grown so this first the block size has grown so this first the block size has grown so this first linear layer is much much bigger our linear layer is much much bigger our linear layer is much much bigger our linear layer now takes eight characters linear layer now takes eight characters linear layer now takes eight characters into this middle layer so there's a lot into this middle layer so there's a lot into this middle layer so there's a lot more parameters there",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 221,
      "text": "but this should more parameters there but this should more parameters there",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 222,
      "text": "but this should just run let me just break right after just run let me just break right after just run let me just break right after the very first iteration",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 223,
      "text": "so you see that the very first iteration",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 224,
      "text": "so you see that the very first iteration",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 225,
      "text": "so you see that this runs just fine it's just that this this runs just fine it's just that this this runs just fine it's just that this network doesn't make too much sense network doesn't make too much sense network doesn't make too much sense we're crushing way too much information we're crushing way too much information we're crushing way too much information way too fast way too fast way too fast so let's now come in and see how we so let's now come in and see how we so let's now come in and see how we could try to implement the hierarchical could try to implement the hierarchical could try to implement the hierarchical scheme now before we dive into the scheme now before we dive into the scheme now before we dive into the detail of the re-implementation here I detail of the re-implementation here I detail of the re-implementation here I was just curious to actually run it and was just curious to actually run it and was just curious to actually run it and see where we are in terms of the see where we are in terms of the see where we are in terms of the Baseline performance of just lazily Baseline performance of just lazily Baseline performance of just lazily scaling up the context length",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 226,
      "text": "so I'll scaling up the context length",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 227,
      "text": "so I'll scaling up the context length",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 228,
      "text": "so I'll let it run we get a nice loss curve and let it run we get a nice loss curve and let it run we get a nice loss curve and then evaluating the loss we actually see then evaluating the loss we actually see then evaluating the loss we actually see quite a bit of improvement just from quite a bit of improvement just from quite a bit of improvement just from increasing the context line length",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 229,
      "text": "so I increasing the context line length",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 230,
      "text": "so I increasing the context line length",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 231,
      "text": "so I started a little bit of a performance started a little bit of a performance started a little bit of a performance log here and previously where we were is log here and previously where we were is log here and previously where we were is we were getting a performance of 2.10 on we were getting a performance of 2.10 on we were getting a performance of 2.10 on the validation loss and now simply the validation loss and now simply the validation loss and now simply scaling up the contact length from 3 to scaling up the contact length from 3 to scaling up the contact length from 3 to 8 gives us a performance of 2.02 so 8 gives us a performance of 2.02 so 8 gives us a performance of 2.02 so quite a bit of an improvement here and quite a bit of an improvement here and quite a bit of an improvement here and also when you sample from the model you also when you sample from the model you also when you sample from the model you see that the names are definitely see that the names are definitely see that the names are definitely improving qualitatively as well improving qualitatively as well improving qualitatively as well",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 232,
      "text": "so we could of course spend a lot of so we could of course spend a lot of so we could of course spend a lot of time here tuning time here tuning time here tuning um uh tuning things and making it even um uh tuning things and making it even um uh tuning things and making it even bigger and scaling up the network bigger and scaling up the network bigger and scaling up the network further even with the simple further even with the simple further even with the simple um sort of setup here but let's continue um sort of setup here but let's continue um sort of setup here but let's continue and let's Implement here model and treat and let's Implement here model and treat and let's Implement here model and treat this as just a rough Baseline this as just a rough Baseline this as just a rough Baseline performance but there's a lot of performance but there's a lot of performance but there's a lot of optimization like left on the table in optimization like left on the table in optimization like left on the table in terms of some of the hyper parameters terms of some of the hyper parameters terms of some of the hyper parameters that you're hopefully getting a sense of that you're hopefully getting a sense of that you're hopefully getting a sense of now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 233,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 234,
      "text": "so let's scroll up now now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 235,
      "text": "okay so let's scroll up now now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 236,
      "text": "okay so let's scroll up now and come back up and what I've done here and come back up and what I've done here and come back up and what I've done here is I've created a bit of a scratch space is I've created a bit of a scratch space is I've created a bit of a scratch space for us to just like look at the forward for us to just like look at the forward for us to just like look at the forward pass of the neural net and inspect the pass of the neural net and inspect the pass of the neural net and inspect the shape of the tensor along the way as the shape of the tensor along the way as the shape of the tensor along the way as the neural net uh forwards so here I'm just neural net uh forwards",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 237,
      "text": "so here I'm just neural net uh forwards so here I'm just temporarily for debugging creating a temporarily for debugging creating a temporarily for debugging creating a batch of just say four examples so four batch of just say four examples so four batch of just say four examples so four random integers then I'm plucking out random integers then I'm plucking out random integers then I'm plucking out those rows from our training set those rows from our training set those rows from our training set and then I'm passing into the model",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 238,
      "text": "the and then I'm passing into the model the",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 239,
      "text": "and then I'm passing into the model the input xB input xB input xB now the shape of XB here because we have now the shape of XB here because we have now the shape of XB here because we have only four examples is four by eight and only four examples is four by eight and only four examples is four by eight and this eight is now the current block size this eight is now the current block size this eight is now the current block size so uh inspecting XP",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 240,
      "text": "we just see that we so uh inspecting XP we just see that we so uh inspecting XP we just see that we have four examples each one of them is a have four examples each one of them is a have four examples each one of them is a row of xB row of xB row of xB and we have eight characters here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 241,
      "text": "and and we have eight characters here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 242,
      "text": "and and we have eight characters here and this integer tensor just contains the this integer tensor just contains the this integer tensor just contains the identities of those characters so the first layer of our neural net is so the first layer of our neural net is the embedding layer so passing XB this the embedding layer so passing XB this the embedding layer so passing XB this integer tensor through the embedding integer tensor through the embedding integer tensor through the embedding layer creates an output that is four by layer creates an output that is four by layer creates an output that is four by eight by ten eight by ten eight by ten",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 243,
      "text": "so our embedding table has for each so our embedding table has for each so our embedding table has for each character a 10-dimensional vector that character a 10-dimensional vector that character a 10-dimensional vector that we are trying to learn we are trying to learn we are trying to learn",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 244,
      "text": "and so what the embedding layer does",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 245,
      "text": "and so what the embedding layer does and so what the embedding layer does here is it plucks out the embedding here is it plucks out the embedding here is it plucks out the embedding Vector for each one of these integers Vector for each one of these integers Vector for each one of these integers and organizes it all in a four by eight and organizes it all in a four by eight and organizes it all in a four by eight by ten tensor now by ten tensor now by ten tensor now so all of these integers are translated so all of these integers are translated so all of these integers are translated into 10 dimensional vectors inside this into 10 dimensional vectors inside this into 10 dimensional vectors inside this three-dimensional tensor now three-dimensional tensor now three-dimensional tensor now passing that through the flattened layer passing that through the flattened layer passing that through the flattened layer as you recall what this does is it views as you recall what this does is it views as you recall what this does is it views this tensor as just a 4 by 80 tensor and this tensor as just a 4 by 80 tensor and this tensor as just a 4 by 80 tensor and what that effectively does is that all what that effectively does is that all what that effectively does is that all these 10 dimensional embeddings for all these 10 dimensional embeddings for all these 10 dimensional embeddings for all these eight characters just end up being these eight characters just end up being these eight characters just end up being stretched out into a long row stretched out into a long row stretched out into a long row and that looks kind of like a and that looks kind of like a and that looks kind of like a concatenation operation basically so by concatenation operation basically so by concatenation operation basically so by viewing the tensor differently we now viewing the tensor differently we now viewing the tensor differently we now have a four by eighty and inside this 80 have a four by eighty and inside this 80 have a four by eighty and inside this 80",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 246,
      "text": "it's all the 10 dimensional uh it's all the 10 dimensional uh it's all the 10 dimensional uh vectors just uh concatenate next to each vectors just uh concatenate next to each vectors just uh concatenate next to each other other other and then the linear layer of course and then the linear layer of course and then the linear layer of course takes uh 80 and creates 200 channels takes uh 80 and creates 200 channels takes uh 80 and creates 200 channels just via matrix multiplication just via matrix multiplication just via matrix multiplication so so far so good now I'd like to show so so far so good now I'd like to show so so far so good now I'd like to show you something surprising you something surprising you something surprising let's look at the insides of the linear let's look at the insides of the linear let's look at the insides of the linear layer and remind ourselves how it works layer and remind ourselves how it works layer and remind ourselves how it works the linear layer here in the forward the linear layer here in the forward the linear layer here in the forward pass takes the input X multiplies",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 247,
      "text": "it pass takes the input X multiplies",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 248,
      "text": "it pass takes the input X multiplies it with a weight and then optionally adds with a weight and then optionally adds with a weight and then optionally adds bias and the weight here is bias and the weight here is bias and the weight here is two-dimensional as defined here and the two-dimensional as defined here and the two-dimensional as defined here and the bias is one dimensional here bias is one dimensional here bias is one dimensional here so effectively in terms of the shapes so effectively in terms of the shapes so effectively in terms of the shapes involved what's happening inside this involved what's happening inside this involved what's happening inside this linear layer looks like this right now linear layer looks like this right now linear layer looks like this right now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 249,
      "text": "and I'm using random numbers here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 250,
      "text": "but and I'm using random numbers here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 251,
      "text": "but and I'm using random numbers here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 252,
      "text": "but I'm just illustrating the shapes",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 253,
      "text": "and I'm just illustrating the shapes and I'm just illustrating the shapes and what happens what happens what happens basically a 4 by 80 input comes into the basically a 4 by 80 input comes into the basically a 4 by 80 input comes into the linear layer that's multiplied by this linear layer that's multiplied by this linear layer that's multiplied by this 80 by 200 weight Matrix inside and 80 by 200 weight Matrix inside and 80 by 200 weight Matrix inside and there's a plus 200 bias and the shape of there's a plus 200 bias and the shape of there's a plus 200 bias and the shape of the whole thing that comes out of the the whole thing that comes out of the the whole thing that comes out of the linear layer is four by two hundred as linear layer is four by two hundred as linear layer is four by two hundred as we see here we see here we see here now notice here by the way that this now notice here by the way that this now notice here by the way that this here will create a 4x200 tensor and then here will create a 4x200 tensor and then here will create a 4x200 tensor and then plus 200 there's a broadcasting plus 200 there's a broadcasting plus 200 there's a broadcasting happening here about 4 by 200 broadcasts happening here about 4 by 200 broadcasts happening here about 4 by 200 broadcasts with 200 uh so everything works here with 200 uh so everything works here with 200 uh so everything works here so now the surprising thing that I'd so now the surprising thing that I'd so now the surprising thing that I'd like to show you that you may not expect like to show you that you may not expect like to show you that you may not expect is that this input here that is being is that this input here that is being is that this input here that is being multiplied uh doesn't actually have to multiplied uh doesn't actually have to multiplied uh doesn't actually have to be two-dimensional this Matrix multiply be two-dimensional this Matrix multiply be two-dimensional this Matrix multiply operator in pytorch is quite powerful operator in pytorch is quite powerful operator in pytorch is quite powerful and in fact you can actually pass in and in fact you can actually pass in and in fact you can actually pass in higher dimensional arrays or tensors and higher dimensional arrays or tensors and higher dimensional arrays or tensors and everything works fine so for example everything works fine so for example everything works fine so for example this could be four by five by eighty and this could be four by five by eighty and this could be four by five by eighty and the result in that case will become four the result in that case will become four the result in that case will become four by five by two hundred by five by two hundred by five by two hundred you can add as many dimensions as you you can add as many dimensions as you you can add as many dimensions as you like on the left here like on the left here like on the left here and so effectively what's happening is and so effectively what's happening is and so effectively what's happening is that the matrix multiplication only that the matrix multiplication only that the matrix multiplication only works on the last Dimension and the works on the last Dimension and the works on the last Dimension and the dimensions before it in the input tensor dimensions before it in the input tensor dimensions before it in the input tensor are left unchanged so that is basically these um these so that is basically these um these dimensions on the left are all treated dimensions on the left are all treated dimensions on the left are all treated as just a batch Dimension so we can have as just a batch Dimension",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 254,
      "text": "so we can have as just a batch Dimension",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 255,
      "text": "so we can have multiple batch dimensions and then in multiple batch dimensions and then in multiple batch dimensions and then in parallel over all those Dimensions we parallel over all those Dimensions we parallel over all those Dimensions we are doing the matrix multiplication on are doing the matrix multiplication on are doing the matrix multiplication on the last dimension the last dimension the last dimension so this is quite convenient because we so this is quite convenient because we so this is quite convenient because we can use that in our Network now can use that in our Network now can use that in our Network now because remember that we have these because remember that we have these because remember that we have these eight characters coming in eight characters coming in eight characters coming in and we don't want to now uh flatten all",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 256,
      "text": "and we don't want to now uh flatten all",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 257,
      "text": "and we don't want to now uh flatten all of it out into a large eight-dimensional of it out into a large eight-dimensional of it out into a large eight-dimensional vector vector vector because we don't want to Matrix multiply because we don't want to Matrix multiply because we don't want to Matrix multiply 80.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 258,
      "text": "80.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 259,
      "text": "80.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 260,
      "text": "into a weight Matrix multiply into a weight Matrix multiply into a weight Matrix multiply immediately instead we want to group immediately instead we want to group immediately instead we want to group these these these like this like this like this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 261,
      "text": "so every consecutive two elements so every consecutive two elements so every consecutive two elements one two and three and four and five and one two and three and four and five and one two and three and four and five and six and seven and eight all of these six and seven and eight all of these six and seven and eight all of these should be now should be now should be now basically flattened out and multiplied basically flattened out and multiplied basically flattened out and multiplied by weight Matrix but all of these four by weight Matrix but all of these four by weight Matrix but all of these four groups here we'd like to process in groups here we'd like to process in groups here we'd like to process in parallel",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 262,
      "text": "so it's kind of like a batch parallel",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 263,
      "text": "so it's kind of like a batch parallel",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 264,
      "text": "so it's kind of like a batch Dimension that we can introduce Dimension that we can introduce Dimension that we can introduce",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 265,
      "text": "and then we can in parallel basically",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 266,
      "text": "and then we can in parallel basically",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 267,
      "text": "and then we can in parallel basically process all of these uh bigram groups in process all of these uh bigram groups in process all of these uh bigram groups in the four batch dimensions of an the four batch dimensions of an the four batch dimensions of an individual example and also over the individual example and also over the individual example and also over the actual batch dimension of the you know actual batch dimension of the you know actual batch dimension of the you know four examples in our example here so four examples in our example here so four examples in our example here so let's see how that works effectively let's see how that works effectively let's see how that works effectively what we want is right now we take a 4 by what we want is right now we take a 4 by what we want is right now we take a 4 by 80 80 80 and multiply it by 80 by 200 and multiply it by 80 by 200 and multiply it by 80 by 200 to in the linear layer this is what to in the linear layer this is what to in the linear layer this is what happens happens happens",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 268,
      "text": "but instead what we want is we don't",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 269,
      "text": "but instead what we want is we don't but instead what we want is we don't want 80 characters or 80 numbers to come want 80 characters or 80 numbers to come want 80 characters or 80 numbers to come in we only want two characters to come in we only want two characters to come in we only want two characters to come in on the very first layer and those two in on the very first layer and those two in on the very first layer and those two characters should be fused characters should be fused characters should be fused so in other words we just want 20 to so in other words we just want 20 to so in other words we just want 20 to come in right 20 numbers would come in come in right 20 numbers would come in come in right 20 numbers would come in and here we don't want a 4 by 80 to feed and here we don't want a 4 by 80 to feed and here we don't want a 4 by 80 to feed into the linear layer we actually want into the linear layer we actually want into the linear layer we actually want these groups of two to feed in so these groups of two to feed in so these groups of two to feed in so instead of four by eighty we want this instead of four by eighty",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 270,
      "text": "we want this instead of four by eighty",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 271,
      "text": "we want this to be a 4 by 4 by 20.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 272,
      "text": "to be a 4 by 4 by 20.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 273,
      "text": "to be a 4 by 4 by 20.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 274,
      "text": "so these are the four groups of two and so these are the four groups of two and so these are the four groups of two and each one of them is ten dimensional each one of them is ten dimensional each one of them is ten dimensional vector vector",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 275,
      "text": "so what we want is now is we need to",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 276,
      "text": "so what we want is now is we need to",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 277,
      "text": "so what we want is now is we need to change the flattened layer so it doesn't change the flattened layer",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 278,
      "text": "so it doesn't change the flattened layer so it doesn't output a four by eighty",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 279,
      "text": "but it outputs a output a four by eighty",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 280,
      "text": "but it outputs a output a four by eighty",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 281,
      "text": "but it outputs a four by four by Twenty where basically four by four by Twenty where basically four by four by Twenty where basically these um these um these um every two consecutive characters are uh every two consecutive characters are uh every two consecutive characters are uh packed in on the very last Dimension and packed in on the very last Dimension and packed in on the very last Dimension and then these four is the first batch then these four is the first batch then these four is the first batch Dimension and this four is the second Dimension and this four is the second Dimension and this four is the second batch Dimension referring to the four batch Dimension referring to the four batch Dimension referring to the four groups inside every one of these groups inside every one of these groups inside every one of these examples examples examples and then this will just multiply like and then this will just multiply like and then this will just multiply like this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 282,
      "text": "so this is what we want to get to this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 283,
      "text": "so this is what we want to get to this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 284,
      "text": "so this is what we want to get to",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 285,
      "text": "so we're going to have to change",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 286,
      "text": "the so we're going to have to change",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 287,
      "text": "the so we're going to have to change the linear layer in terms of how many inputs linear layer in terms of how many inputs linear layer in terms of how many inputs it expects it shouldn't expect 80 it it expects it shouldn't expect 80",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 288,
      "text": "it it expects it shouldn't expect 80 it should just expect 20 numbers and we should just expect 20 numbers and we should just expect 20 numbers and we have to change our flattened layer",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 289,
      "text": "so it have to change our flattened layer",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 290,
      "text": "so it have to change our flattened layer",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 291,
      "text": "so it doesn't just fully flatten out this doesn't just fully flatten out this doesn't just fully flatten out this entire example it needs to create a 4x4 entire example it needs to create a 4x4 entire example it needs to create a 4x4 by 20 instead of four by eighty",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 292,
      "text": "so let's by 20 instead of four by eighty",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 293,
      "text": "so let's by 20 instead of four by eighty",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 294,
      "text": "so let's see how this could be implemented see how this could be implemented see how this could be implemented basically right now we have an input basically right now we have an input basically right now we have an input that is a four by eight by ten that that is a four by eight by ten that that is a four by eight by ten that feeds into the flattened layer and feeds into the flattened layer and feeds into the flattened layer and currently the flattened layer just currently the flattened layer just currently the flattened layer just stretches it out so if you remember the stretches it out so if you remember the stretches it out so if you remember the implementation of flatten implementation of flatten implementation of flatten it takes RX and it just views it as it takes RX and it just views it as it takes RX and it just views it as whatever the batch Dimension is and then whatever the batch Dimension is and then whatever the batch Dimension is and then negative one negative one negative one so effectively what it does right now is so effectively what it does right now is so effectively what it does right now is it does e dot view of 4 negative one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 295,
      "text": "and it does e dot view of 4 negative one and it does e dot view of 4 negative one and the shape of this of course is 4 by 80.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 296,
      "text": "the shape of this of course is 4 by 80.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 297,
      "text": "the shape of this of course is 4 by 80.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 298,
      "text": "so that's what currently happens and we",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 299,
      "text": "so that's what currently happens",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 300,
      "text": "and we so that's what currently happens",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 301,
      "text": "and we instead want this to be a four by four instead want this to be a four by four instead want this to be a four by four by Twenty where these consecutive by Twenty where these consecutive by Twenty where these consecutive ten-dimensional vectors get concatenated ten-dimensional vectors get concatenated ten-dimensional vectors get concatenated",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 302,
      "text": "so you know how in Python you can take",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 303,
      "text": "a so you know how in Python you can take",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 304,
      "text": "a so you know how in Python you can take a list of range of 10 list of range of 10 list of range of 10",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 305,
      "text": "so we have numbers from zero to nine and so we have numbers from zero to nine and so we have numbers from zero to nine and we can index like this to get all the we can index like this to get all the we can index like this to get all the even parts even parts even parts and we can also index like starting at and we can also index like starting at and we can also index like starting at one and going in steps up two to get all one and going in steps up two to get all one and going in steps up two to get all the odd parts the odd parts the odd parts so one way to implement this it would be so one way to implement this it would be so one way to implement this it would be as follows we can take e and we can as follows we can take e and we can as follows we can take e and we can index into it for all the batch elements index into it for all the batch elements index into it for all the batch elements and then just even elements in this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 306,
      "text": "and then just even elements in this and then just even elements in this Dimension so at indexes 0 2 4 and 8.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 307,
      "text": "Dimension so at indexes 0 2 4 and 8.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 308,
      "text": "Dimension so at indexes 0 2 4 and 8.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 309,
      "text": "and then all the parts here from this and then all the parts here from this and then all the parts here from this last dimension last dimension last dimension and this gives us the even characters and this gives us the even characters and this gives us the even characters and",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 310,
      "text": "then here and then here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 311,
      "text": "and then here this gives us all the odd characters and this gives us all the odd characters and this gives us all the odd characters and basically what we want to do is we make basically what we want to do is we make basically what we want to do is we make sure we want to make sure that these get sure we want to make sure that these get sure we want to make sure that these get concatenated in pi torch",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 312,
      "text": "and then we concatenated in pi torch and then we concatenated in pi torch and then we want to concatenate these two tensors want to concatenate these two tensors want to concatenate these two tensors along the second dimension along the second dimension along the second dimension so this and the shape of it would be so this and the shape of it would be so this and the shape of it would be four by four by Twenty this is four by four by Twenty this is four by four by Twenty this is definitely the result we want we are definitely the result we want we are definitely the result we want we are explicitly grabbing the even parts and explicitly grabbing the even parts and explicitly grabbing the even parts and the odd parts and we're arranging those the odd parts and we're arranging those the odd parts and we're arranging those four by four by ten right next to each four by four by ten right next to each four by four by ten right next to each other and concatenate other and concatenate other and concatenate",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 313,
      "text": "so this works but it turns out that what so this works",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 314,
      "text": "but it turns out that what so this works",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 315,
      "text": "but it turns out that what also works is you can simply use a view also works is you can simply use a view also works is you can simply use a view again and just request the right shape again and just request the right shape again and just request the right shape",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 316,
      "text": "and it just so happens that in this case and it just so happens that in this case and it just so happens that in this case those vectors will again end up being those vectors will again end up being those vectors will again end up being arranged in exactly the way we want so arranged in exactly the way we want so arranged in exactly the way we want so in particular if we take e",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 317,
      "text": "and we just in particular if we take e",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 318,
      "text": "and we just in particular if we take e",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 319,
      "text": "and we just view it as a four by four by Twenty view it as a four by four by Twenty view it as a four by four by Twenty which is what we want which is what we want which is what we want we can check that this is exactly equal we can check that this is exactly equal we can check that this is exactly equal to but let me call this this is the to but let me call this this is the to but let me call this this is the explicit concatenation I suppose explicit concatenation",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 320,
      "text": "I suppose explicit concatenation",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 321,
      "text": "I suppose um um so explosives dot shape is 4x4 by 20.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 322,
      "text": "if so explosives dot shape is 4x4 by 20.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 323,
      "text": "if so explosives dot shape is 4x4 by 20.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 324,
      "text": "if you just view it as 4x4 by 20 you can you just view it as 4x4 by 20 you can you just view it as 4x4 by 20 you can check that when you compare to explicit check that when you compare to explicit check that when you compare to explicit uh you got a big this is element wise",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 325,
      "text": "uh you got a big this is element",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 326,
      "text": "wise uh you got a big this is element wise operation so making sure that all of operation so making sure that all of operation so making sure that all of them are true",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 327,
      "text": "that is the truth so them are true that is the truth so them are true that is the truth so basically long story short",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 328,
      "text": "we don't need basically long story short we don't need basically long story short we don't need to make an explicit call to concatenate to make an explicit call to concatenate to make an explicit call to concatenate Etc we can simply take this input tensor",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 329,
      "text": "Etc we can simply take this input tensor Etc we can simply take this input tensor to flatten and we can just view it in to flatten and we can just view it in to flatten and we can just view it in whatever way we want whatever way we want whatever way we want and in particular you don't want to and in particular you don't want to and in particular you don't want to stretch things out with negative one we stretch things out with negative one we stretch things out with negative one we want to actually create a want to actually create a want to actually create a three-dimensional array and depending on three-dimensional array and depending on three-dimensional array and depending on how many vectors that are consecutive we how many vectors that are consecutive we how many vectors that are consecutive we want to want to want to um fuse like for example two then we can um fuse like for example two then we can um fuse like for example two",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 330,
      "text": "then we can just simply ask for this Dimension to be just simply ask for this Dimension to be just simply ask for this Dimension to be 20.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 331,
      "text": "and um 20.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 332,
      "text": "and um 20.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 333,
      "text": "and um use a negative 1 here and python will use a negative 1 here and python will use a negative 1 here and python will figure out how many groups it needs to figure out how many groups it needs to figure out how many groups it needs to pack into this additional batch pack into this additional batch pack into this additional batch dimension dimension dimension",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 334,
      "text": "so let's now go into flatten",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 335,
      "text": "and so let's now go into flatten",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 336,
      "text": "and so let's now go into flatten and implement this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 337,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 338,
      "text": "so I scroll up here implement this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 339,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 340,
      "text": "so I scroll up here implement this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 341,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 342,
      "text": "so I scroll up here to flatten and what we'd like to do is to flatten and what we'd like to do is to flatten and what we'd like to do is we'd like to change it now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 343,
      "text": "so let me we'd like to change it now so let me we'd like to change it now so let me create a Constructor and take the number create a Constructor and take the number create a Constructor and take the number of elements that are consecutive that we of elements that are consecutive that we of elements that are consecutive that we would like to concatenate now in the would like to concatenate now in the would like to concatenate now in the last dimension of the output last dimension of the output last dimension of the output so here we're just going to remember so here we're just going to remember so here we're just going to remember solve.n equals n solve.n equals n solve.n equals n",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 344,
      "text": "and then I want to be careful here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 345,
      "text": "and then I want to be careful here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 346,
      "text": "and then I want to be careful here because pipe pytorch actually has a because pipe pytorch actually has a because pipe pytorch actually has a torch to flatten and its keyword torch to flatten and its keyword torch to flatten and its keyword arguments are different and they kind of arguments are different and they kind of arguments are different and they kind of like function differently",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 347,
      "text": "so R flatten like function differently",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 348,
      "text": "so R flatten like function differently so R flatten is going to start to depart from patreon is going to start to depart from patreon is going to start to depart from patreon flatten so let me call it flat flatten flatten so let me call it flat flatten flatten so let me call it flat flatten consecutive or something like that just consecutive or something like that just consecutive or something like that just to make sure that our apis are about to make sure that our apis are about to make sure that our apis are about equal equal equal",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 349,
      "text": "so this uh basically flattens only some so this uh basically flattens only some so this uh basically flattens only some n consecutive elements and puts them n consecutive elements and puts them n consecutive elements and puts them into the last dimension into the last dimension into the last dimension now here the shape of X is B by T by C now here the shape of X is B by T by C now here the shape of X is B by T by C so let me so let me so let me pop those out into variables and recall pop those out into variables and recall pop those out into variables and recall that in our example down below B was 4 T that in our example down below B was 4 T that in our example down below B was 4 T was 8 and C was 10.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 350,
      "text": "now instead of doing x dot view of B by now instead of doing x dot view of B by negative one negative one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 351,
      "text": "right",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 352,
      "text": "this is what we had before we want this to be B by we want this to be B by um negative 1 by um negative 1 by um negative 1 by and basically here we want c times n and basically here we want c times n and basically here we want c times n that's how many consecutive elements we that's how many consecutive elements we that's how many consecutive elements we want want want and here instead of negative one I don't and here instead of negative one I don't and here instead of negative one I don't super love the use of negative one super love the use of negative one super love the use of negative one because I like to be very explicit so because I like to be very explicit so because I like to be very explicit so that you get error messages when things that you get error messages when things that you get error messages when things don't go according to your expectation don't go according to your expectation don't go according to your expectation so what do we expect here we expect this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 353,
      "text": "so what do we expect here we expect this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 354,
      "text": "so what do we expect here we expect this to become t to become t to become t divide n using integer division here divide n using integer division here divide n using integer division here so that's what I expect to happen so that's what I expect to happen so that's what I expect to happen and then one more thing I want to do and then one more thing I want to do and then one more thing I want to do here is remember previously all the way here is remember previously all the way here is remember previously all the way in the beginning n was three and uh in the beginning n was three and uh in the beginning n was three and uh basically we're concatenating basically we're concatenating basically we're concatenating um all the three characters that existed um all the three characters that existed um all the three characters that existed there there there",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 355,
      "text": "so we basically are concatenated so we basically are concatenated so we basically are concatenated everything everything everything",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 356,
      "text": "and so sometimes I can create a spurious",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 357,
      "text": "and so sometimes I can create a spurious",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 358,
      "text": "and so sometimes I can create a spurious dimension of one here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 359,
      "text": "so if it is the dimension of one here so if it is the dimension of one here so if it is the case that x dot shape at one is one then case that x dot shape at one is one then case that x dot shape at one is one then it's kind of like a spurious dimension it's kind of like a spurious dimension it's kind of like a spurious dimension um so we don't want to return a um so we don't want to return a um so we don't want to return a three-dimensional tensor with a one here three-dimensional tensor with a one here three-dimensional tensor with a one here we just want to return a two-dimensional we just want to return a two-dimensional we just want to return a two-dimensional tensor exactly as we did before tensor exactly as we did before tensor exactly as we did before so in this case basically we will just so in this case basically we will just so in this case basically we will just say x equals x dot squeeze that is a say x equals x dot squeeze that is a say x equals x dot squeeze that is a pytorch function pytorch function pytorch function and squeeze takes a dimension that it and squeeze takes a dimension that it and squeeze takes a dimension that it either squeezes out all the dimensions either squeezes out all the dimensions either squeezes out all the dimensions of a tensor that are one or you can of a tensor that are one or you can of a tensor that are one or you can specify the exact Dimension that you specify the exact Dimension that you specify the exact Dimension that you want to be squeezed and again I like to want to be squeezed and again I like to want to be squeezed and again I like to be as explicit as possible always so I be as explicit as possible always so I be as explicit as possible always so I expect to squeeze out the First expect to squeeze out the First expect to squeeze out the First Dimension only Dimension only Dimension only of this tensor of this tensor of this tensor this three-dimensional tensor and if this three-dimensional tensor and if this three-dimensional tensor and if this Dimension here is one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 360,
      "text": "then I just this Dimension here is one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 361,
      "text": "then I just this Dimension here is one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 362,
      "text": "then I just want to return B by c times n want to return B by c times n want to return B by c times n and so self dot out will be X",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 363,
      "text": "and then and so self dot out will be X and then and so self dot out will be X",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 364,
      "text": "and then we return salt dot out we return salt dot out we return salt dot out so that's the candidate implementation so that's the candidate implementation so that's the candidate implementation and of course this should be self.n and of course this should be self.n and of course this should be self.n instead of just n instead of just n instead of just n so let's run so let's run so let's run and let's come here now and let's come here now and let's come here now and take it for a spin so flatten and take it for a spin so flatten and take it for a spin so flatten consecutive and in the beginning let's just use and in the beginning let's just use eight so this should recover the eight so this should recover the eight so this should recover the previous Behavior so flagging previous Behavior so flagging previous Behavior so flagging consecutive of eight uh which is the consecutive of eight uh which is the consecutive of eight uh which is the current block size current block size current block size we can do this uh that should recover we can do this uh that should recover we can do this uh that should recover the previous Behavior the previous Behavior the previous Behavior so we should be able to run the model so we should be able to run the model so we should be able to run the model and here we can inspect I have a little",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 365,
      "text": "and here we can inspect I have a little",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 366,
      "text": "and here we can inspect I have a little code snippet here where I iterate over code snippet here where I iterate over code snippet here where I iterate over all the layers I print the name of this all the layers I print the name of this all the layers I print the name of this class and the shape class and the shape class and the shape",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 367,
      "text": "and so we see the shapes as we expect",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 368,
      "text": "and so we see the shapes as we expect",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 369,
      "text": "and so we see the shapes as we expect them after every single layer in the top them after every single layer in the top them after every single layer in the top bit",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 370,
      "text": "so now let's try to restructure it bit so now let's try to restructure it bit so now let's try to restructure it using our flattened consecutive and do using our flattened consecutive and do using our flattened consecutive and do it hierarchically",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 371,
      "text": "so in particular it hierarchically",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 372,
      "text": "so in particular it hierarchically",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 373,
      "text": "so in particular we want to flatten consecutive not just we want to flatten consecutive not just we want to flatten consecutive not just not block size",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 374,
      "text": "but just two not block size but just two not block size but just two",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 375,
      "text": "and then we want to process this with",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 376,
      "text": "and then we want to process this with and then we want to process this with linear now then the number of inputs to linear now then the number of inputs to linear now then the number of inputs to this linear will not be an embed times this linear will not be an embed times this linear will not be an embed times block size it will now only be n embed block size it will now only be n embed block size it will now only be n embed times two times two times two 20. 20. 20.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 377,
      "text": "this goes through the first layer and this goes through the first layer and this goes through the first layer and now we can in principle just copy paste now we can in principle just copy paste now we can in principle just copy paste this this this now the next linear layer should expect now the next linear layer should expect now the next linear layer should expect and hidden times two and hidden times two and hidden times two and the last piece of it should expect and the last piece of it should expect and the last piece of it should expect and it enters 2 again and it enters 2 again and it enters 2 again",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 378,
      "text": "so this is sort of like the naive so this is sort of like the naive so this is sort of like the naive version of it version of it version of it",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 379,
      "text": "um um so running this we now have a much much so running this we now have a much much so running this we now have a much much bigger model bigger model bigger model and we should be able to basically just",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 380,
      "text": "and we should be able to basically just",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 381,
      "text": "and we should be able to basically just forward the model forward the model forward the model and now we can inspect uh the numbers in and now we can inspect uh the numbers in and now we can inspect uh the numbers in between between between so four byte by 20 so four byte by 20 so four byte by 20 was Platinum consecutively into four by was Platinum consecutively into four by was Platinum consecutively into four by four by Twenty four by Twenty four by Twenty this was projected into four by four by this was projected into four by four by this was projected into four by four by two hundred two hundred two hundred and then bash storm just worked out of and then bash storm just worked out of and then bash storm just worked out of the box we have to verify that bastron the box we have to verify that bastron the box we have to verify that bastron does the correct thing even though it does the correct thing even though it does the correct thing even though it takes a three-dimensional impedance that takes a three-dimensional impedance that takes a three-dimensional impedance that are two dimensional input are two dimensional input are two dimensional input then we have 10h which is element",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 382,
      "text": "wise then we have 10h which is element wise",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 383,
      "text": "then we have 10h which is element wise",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 384,
      "text": "then we crushed it again",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 385,
      "text": "so if we then we crushed it again",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 386,
      "text": "so if we then we crushed it again so if we flatten consecutively and ended up with flatten consecutively and ended up with flatten consecutively and ended up with a four by two by 400 now a four by two by 400 now a four by two by 400 now then linear brought it back down to 200 then linear brought it back down to 200 then linear brought it back down to 200 batch room 10h and lastly we get a 4 by batch room 10h and lastly we get a 4 by batch room 10h and lastly we get a 4 by 400",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 387,
      "text": "and we see that the flattened 400",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 388,
      "text": "and we see that the flattened 400",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 389,
      "text": "and we see that the flattened consecutive for the last flatten here uh consecutive for the last flatten here uh consecutive for the last flatten here uh it squeezed out that dimension of one so it squeezed out that dimension of one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 390,
      "text": "so it squeezed out that dimension of one so we only ended up with four by four we only ended up with four by four we only ended up with four by four hundred and then linear Bachelor on 10h hundred and then linear Bachelor on 10h hundred and then linear Bachelor on 10h and uh the last linear layer to get our and uh the last linear layer to get our and uh the last linear layer to get our logents",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 391,
      "text": "and so The Lodges end up in the logents and so The Lodges end up in the logents",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 392,
      "text": "and so The Lodges end up in the same shape as they were before but now same shape as they were before but now same shape as they were before but now we actually have a nice three layer we actually have a nice three layer we actually have a nice three layer neural nut",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 393,
      "text": "and it basically corresponds neural nut",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 394,
      "text": "and it basically corresponds neural nut",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 395,
      "text": "and it basically corresponds to whoops",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 396,
      "text": "sorry it basically corresponds to whoops",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 397,
      "text": "sorry it basically corresponds to whoops",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 398,
      "text": "sorry it basically corresponds exactly to this network now except only exactly to this network now except only exactly to this network now except only this piece here because we only have this piece here because we only have this piece here because we only have three layers whereas here in this three layers whereas here in this three layers whereas here in this example there's uh four layers with the example there's uh four layers with the example there's uh four layers with the total receptive field size of 16 total receptive field size of 16 total receptive field size of 16 characters instead of just eight characters instead of just eight characters instead of just eight characters so the block size here is 16.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 399,
      "text": "characters so the block size here is 16.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 400,
      "text": "characters so the block size here is 16.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 401,
      "text": "so this piece of it's basically so this piece of it's basically so this piece of it's basically implemented here implemented here implemented here um now we just have to kind of figure",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 402,
      "text": "um now we just have to kind of figure",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 403,
      "text": "um now we just have to kind of figure out some good Channel numbers to use out some good Channel numbers to use out some good Channel numbers to use here now in particular I changed the here now in particular I changed the here now in particular I changed the number of hidden units to be 68 in this number of hidden units to be 68 in this number of hidden units to be 68 in this architecture because when I use 68 the architecture because when I use 68 the architecture because when I use 68 the number of parameters comes out to be 22 number of parameters comes out to be 22 number of parameters comes out to be 22 000",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 404,
      "text": "so that's exactly the same that we 000",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 405,
      "text": "so that's exactly the same that we 000",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 406,
      "text": "so that's exactly the same that we had before and we have the same amount had before and we have the same amount had before and we have the same amount of capacity at this neural net in terms of capacity at this neural net in terms of capacity at this neural net in terms of the number of parameters but the of the number of parameters but the of the number of parameters but the question is whether we are utilizing question is whether we are utilizing question is whether we are utilizing those parameters in a more efficient those parameters in a more efficient those parameters in a more efficient architecture so what I did then is I got architecture",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 407,
      "text": "so what I did then is I got architecture",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 408,
      "text": "so what I did then is I got rid of a lot of the debugging cells here rid of a lot of the debugging cells here rid of a lot of the debugging cells here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 409,
      "text": "and I rerun the optimization and and I rerun the optimization and and I rerun the optimization and scrolling down to the result we see that scrolling down to the result we see that scrolling down to the result we see that we get the identical performance roughly we get the identical performance roughly we get the identical performance roughly so our validation loss now is 2.029",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 410,
      "text": "and so our validation loss now is 2.029",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 411,
      "text": "and so our validation loss now is 2.029 and previously it was 2.027 so controlling previously it was 2.027 so controlling previously it was 2.027 so controlling for the number of parameters changing for the number of parameters changing for the number of parameters changing from the flat to hierarchical is not from the flat to hierarchical is not from the flat to hierarchical is not giving us anything yet giving us anything yet giving us anything yet that said there are two things that said there are two things that said there are two things um to point out number one we didn't um to point out number one we didn't um to point out number one we didn't really torture the um architecture here really torture the um architecture here really torture the um architecture here very much this is just my first guess very much this is just my first guess very much this is just my first guess and there's a bunch of hyper parameters and there's a bunch of hyper parameters and there's a bunch of hyper parameters search that we could do in order in search that we could do in order in search that we could do in order in terms of how we allocate uh our budget terms of how we allocate uh our budget terms of how we allocate uh our budget of parameters to what layers number two of parameters to what layers number two of parameters to what layers",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 412,
      "text": "number two we still may have a bug inside the we still may have a bug inside the we still may have a bug inside the bachelor 1D layer so let's take a look bachelor 1D layer so let's take a look bachelor 1D layer so let's take a look at at at um uh that because it runs but does it um uh that because it runs but does it um uh that because it runs but does it do the right thing do the right thing do the right thing",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 413,
      "text": "so I pulled up the layer inspector sort",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 414,
      "text": "so I pulled up the layer inspector sort",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 415,
      "text": "so I pulled up the layer inspector sort of that we have here and printed out the of that we have here and printed out the of that we have here and printed out the shape along the way and currently it shape along the way and currently it shape along the way and currently it looks like the batch form is receiving looks like the batch form is receiving looks like the batch form is receiving an input that is 32 by 4 by 68 right and an input that is 32 by 4 by 68 right and an input that is 32 by 4 by 68 right and here on the right I have the current here on the right I have the current here on the right I have the current implementation of Bachelor that we have implementation of Bachelor that we have implementation of Bachelor that we have right now right now right now now this bachelor assumed in the way we now this bachelor assumed in the way we now this bachelor assumed in the way we wrote it and at the time that X is wrote it and at the time that X is wrote it and at the time that X is two-dimensional",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 416,
      "text": "so it was n by D where n two-dimensional",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 417,
      "text": "so it was n by D where n two-dimensional",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 418,
      "text": "so it was n by D where n was the batch size so that's why we only was the batch size",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 419,
      "text": "so that's why we only was the batch size so that's why we only reduced uh the mean and the variance reduced uh the mean and the variance reduced uh the mean and the variance over the zeroth dimension but now X will over the zeroth dimension but now X will over the zeroth dimension but now X will basically become three-dimensional so basically become three-dimensional so basically become three-dimensional",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 420,
      "text": "so what's happening inside the bachelor what's happening inside the bachelor what's happening inside the bachelor right now and how come it's working at right now and how come it's working at right now and how come it's working at all and not giving any errors the reason all and not giving any errors the reason all and not giving any errors the reason for that is basically because everything for that is basically because everything for that is basically because everything broadcasts properly but the bachelor is broadcasts properly but the bachelor is broadcasts properly but the bachelor is not doing what we need what we wanted to not doing what we need what we wanted to not doing what we need what we wanted to do do do so in particular let's basically think so in particular let's basically think so in particular let's basically think through what's happening inside the through what's happening inside the through what's happening inside the bathroom uh looking at what's what's do bathroom uh looking at what's what's do bathroom uh looking at what's what's",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 421,
      "text": "do",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 422,
      "text": "What's Happening Here What's Happening Here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 423,
      "text": "What's Happening Here I have the code here I have the code here I have the code here so we're receiving an input of 32 by 4 so we're receiving an input of 32 by 4 so we're receiving an input of 32 by 4 by 68 and then we are doing uh here x by 68 and then we are doing uh here x by 68 and then we are doing uh here x dot mean here I have e instead of X but dot mean here I have e instead of X but dot mean here I have e instead of X",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 424,
      "text": "but we're doing the mean over zero and we're doing the mean over zero and we're doing the mean over zero and that's actually giving us 1 by 4 by 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 425,
      "text": "that's actually giving us 1 by 4 by 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 426,
      "text": "that's actually giving us 1 by 4 by 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 427,
      "text": "so we're doing the mean only over the so we're doing the mean only over the",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 428,
      "text": "so we're doing the mean only over the very first Dimension and it's giving us very first Dimension and it's giving us very first Dimension and it's giving us a mean and a variance that still a mean and a variance that still a mean and a variance that still maintain this Dimension here maintain this Dimension here maintain this Dimension here so these means are only taking over 32 so these means are only taking over 32 so these means are only taking over 32 numbers in the First Dimension and then numbers in the First Dimension and then numbers in the First Dimension and then when we perform this everything when we perform this everything when we perform this everything broadcasts correctly still broadcasts correctly still broadcasts correctly still but basically what ends up happening is but basically what ends up happening is but basically what ends up happening is when we also look at the running mean the shape of it",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 429,
      "text": "so I'm looking at the the shape of it",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 430,
      "text": "so I'm looking at the model that layers at three which is the model that layers at three which is the model that layers at three which is the first bathroom layer and they're looking first bathroom layer and they're looking first bathroom layer and they're looking at whatever the running mean became and at whatever the running mean became and at whatever the running mean became and its shape its shape its shape the shape of this running mean now is 1 the shape of this running mean now is 1 the shape of this running mean now is 1 by 4 by 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 431,
      "text": "by 4 by 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 432,
      "text": "by 4 by 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 433,
      "text": "right instead of it being right instead of it being right instead of it being um you know just a size of dimension",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 434,
      "text": "um you know just a size of dimension um you know just a size of dimension because we have 68 channels we expect to because we have 68 channels we expect to because we have 68 channels we expect to have 68 means and variances that we're have 68 means and variances that we're have 68 means and variances that we're maintaining but actually we have an maintaining but actually we have an maintaining but actually we have an array of 4 by 68 and so basically what array of 4 by 68 and so basically what array of 4 by 68 and so basically what this is telling us is this bash",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 435,
      "text": "Norm is this is telling us is this bash",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 436,
      "text": "Norm is this is telling us is this bash",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 437,
      "text": "Norm is only only only this bachelor is currently working in this bachelor is currently working in this bachelor is currently working in parallel parallel parallel over 4 times 68 instead of just 68 channels 4 times 68 instead of just 68 channels so basically we are maintaining so basically we are maintaining so basically we are maintaining statistics for every one of these four statistics for every one of these four statistics for every one of these four positions individually and independently positions individually and independently positions individually and independently and instead what we want to do is we and instead what we want to do is we and instead what we want to do is we want to treat this four as a batch want to treat this four as a batch want to treat this four as a batch Dimension just like the zeroth dimension",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 438,
      "text": "Dimension just like the zeroth dimension Dimension just like the zeroth dimension so as far as the bachelor is concerned so as far as the bachelor is concerned so as far as the bachelor is concerned it doesn't want to average we don't want it doesn't want to average we don't want it doesn't want to average we don't want to average over 32 numbers we want to to average over 32 numbers we want to to average over 32 numbers we want to now average over 32 times four numbers now average over 32 times four numbers now average over 32 times four numbers for every single one of these 68 for every single one of these 68 for every single one of these 68 channels channels channels and uh so let me now and uh so let me now and uh so let me now remove this remove this remove this it turns out that when you look at the it turns out that when you look at the it turns out that when you look at the documentation of torch.mean documentation of torch.mean documentation of torch.mean so let's go to torch.me in one of its signatures when we specify in one of its signatures when we specify the dimension the dimension the dimension we see that the dimension here is not we see that the dimension here is not we see that the dimension here is not just it can be in or it can also be a just it can be in or it can also be a just it can be in or it can also be a tuple of ins so we can reduce over tuple of ins so we can reduce over tuple of ins so we can reduce over multiple integers at the same time over multiple integers at the same time over multiple integers at the same time over multiple Dimensions at the same time so multiple Dimensions at the same time so multiple Dimensions at the same time so instead of just reducing over zero we instead of just reducing over zero we instead of just reducing over zero we can pass in a tuple 0 1. can pass in a tuple 0 1. can pass in a tuple 0 1.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 439,
      "text": "and here zero one as well and then and here zero one as well and then and here zero one as well",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 440,
      "text": "and then what's going to happen is the output of what's going to happen is the output of what's going to happen is the output of course is going to be the same course is going to be the same course is going to be the same but now what's going to happen is but now what's going to happen is but now what's going to happen is because we reduce over 0 and 1 if we because we reduce over 0 and 1 if we because we reduce over 0 and 1 if we look at immin.shape look at immin.shape look at immin.shape we see that now we've reduced we took we see that now we've reduced we took we see that now we've reduced we took the mean over both the zeroth and the the mean over both the zeroth and the the mean over both the zeroth and the First Dimension First Dimension First Dimension",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 441,
      "text": "so we're just getting 68 numbers and a so we're just getting 68 numbers and a so we're just getting 68 numbers and a bunch of spurious Dimensions here bunch of spurious Dimensions here bunch of spurious Dimensions here so now this becomes 1 by 1 by 68 and",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 442,
      "text": "the so now this becomes 1 by 1 by 68 and the so now this becomes 1 by 1 by 68 and the running mean and",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 443,
      "text": "the running variance running mean and the running variance running mean and the running variance analogously will become one by one by analogously will become one by one by analogously will become one by one by 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 444,
      "text": "so even though there are the 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 445,
      "text": "so even though there are the 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 446,
      "text": "so even though there are the spurious Dimensions uh the current the spurious Dimensions uh the current the spurious Dimensions uh the current the current the correct thing will happen in current the correct thing will happen in current the correct thing will happen in that we are only maintaining means and that we are only maintaining means and that we are only maintaining means and variances for 64 sorry for 68 channels variances for 64 sorry for 68 channels variances for 64 sorry for 68 channels and we're not calculating the mean",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 447,
      "text": "and we're not calculating the mean",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 448,
      "text": "and we're not calculating the mean variance across 32 times 4 dimensions so variance across 32 times 4 dimensions so variance across 32 times 4 dimensions so that's exactly what we want and let's that's exactly what we want and let's that's exactly what we want and let's change the implementation of bash term change the implementation of bash term change the implementation of bash term 1D that we have so that it can take in 1D that we have so that it can take in 1D that we have so that it can take in two-dimensional or three-dimensional two-dimensional or three-dimensional two-dimensional or three-dimensional inputs and perform accordingly so at the inputs and perform accordingly so at the inputs and perform accordingly so at the end of the day the fix is relatively end of the day the fix is relatively end of the day the fix is relatively straightforward basically the dimension straightforward basically the dimension straightforward basically the dimension we want to reduce over is either 0",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 449,
      "text": "or we want to reduce over is either 0",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 450,
      "text": "or we want to reduce over is either 0 or the Tuple zero and one depending on the the Tuple zero and one depending on the the Tuple zero and one depending on the dimensionality of X so if x dot and dim dimensionality of X",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 451,
      "text": "so if x dot and dim dimensionality of X",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 452,
      "text": "so if x dot and dim is two",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 453,
      "text": "so it's a two dimensional tensor is two",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 454,
      "text": "so it's a two dimensional tensor is two",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 455,
      "text": "so it's a two dimensional tensor then Dimension we want to reduce over is then Dimension we want to reduce over is then Dimension we want to reduce over is just the integer zero just the integer zero just the integer zero L if x dot ending is three so it's a L if x dot ending is three",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 456,
      "text": "so it's a L if x dot ending is three",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 457,
      "text": "so it's a three-dimensional tensor then the dims three-dimensional tensor then the dims three-dimensional tensor then the dims we're going to assume are zero and one we're going to assume are zero and one we're going to assume are zero and one that we want to reduce over",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 458,
      "text": "and then that we want to reduce over and then that we want to reduce over",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 459,
      "text": "and then here we just pass in dim here we just pass in dim here we just pass in dim and if the dimensionality of X is and if the dimensionality of X is and if the dimensionality of X is anything else we'll now get an error anything else we'll now get an error anything else we'll now get an error which is good which is good which is good",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 460,
      "text": "um so that should be the fix now I want um so that should be the fix now I want um so that should be the fix now I want to point out one more thing we're to point out one more thing we're to point out one more thing we're actually departing from the API of Pi actually departing from the API of Pi actually departing from the API of Pi torch here a little bit because when you torch here a little bit because when you torch here a little bit because when you come to batch room 1D and pytorch you come to batch room 1D and pytorch you come to batch room 1D and pytorch you can scroll down and you can see that the can scroll down and you can see that the can scroll down and you can see that the input to this layer can either be n by C input to this layer can either be n by C input to this layer can either be n by C where n is the batch size and C is the where n is the batch size and C is the where n is the batch size and C is the number of features or channels or it number of features or channels or it number of features or channels or it actually does accept three-dimensional actually does accept three-dimensional actually does accept three-dimensional inputs but it expects it to be n by C by inputs",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 461,
      "text": "but it expects it to be n by C by inputs but it expects it to be n by C by L L L",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 462,
      "text": "where LSA like the sequence length or where LSA like the sequence length or where LSA like the sequence length or something like that something like that something like that so um so um so um this is problem because you see how C is this is problem because you see how C is this is problem because you see how C is nested here in the middle",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 463,
      "text": "and so when it nested here in the middle",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 464,
      "text": "and so when it nested here in the middle",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 465,
      "text": "and so when it gets three-dimensional inputs this bash gets three-dimensional inputs this bash gets three-dimensional inputs this bash term layer will reduce over zero and two term layer will reduce over zero and two term layer will reduce over zero and two instead of zero and one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 466,
      "text": "so it basically instead of zero and one so it basically instead of zero and one so it basically Pi torch batch number one D layer Pi torch batch number one D layer Pi torch batch number one D layer assumes that c will always be the First assumes that c will always be the First assumes that c will always be the First Dimension whereas we'll we assume here Dimension whereas we'll we assume here Dimension whereas we'll we assume here that c is the last Dimension and there that c is the last Dimension and there that c is the last Dimension and there are some number of batch Dimensions are some number of batch Dimensions are some number of batch Dimensions beforehand beforehand beforehand um um and so",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 467,
      "text": "and so it expects n by C or M by C by all we it expects n by C or M by C by all we it expects n by C or M by C by all we expect and by C or n by L by C expect and by C or n by L by C expect and by C or n by L by C",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 468,
      "text": "and so it's a deviation",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 469,
      "text": "and so it's a deviation",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 470,
      "text": "and so it's a deviation um um I think it's okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 471,
      "text": "I prefer it this way I think it's okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 472,
      "text": "I prefer it this way I think it's okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 473,
      "text": "I prefer it this way honestly so this is the way that we will honestly so this is the way that we will honestly so this is the way that we will keep it for our purposes keep it for our purposes keep it for our purposes",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 474,
      "text": "so I redefined the layers re-initialize so I redefined the layers re-initialize",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 475,
      "text": "so I redefined the layers re-initialize the neural net and did a single forward the neural net and did a single forward the neural net and did a single forward pass with a break just for one step pass with a break just for one step pass with a break just for one step looking at the shapes along the way looking at the shapes along the way looking at the shapes along the way they're of course identical all the they're of course identical all the they're of course identical all the shapes are the same but the way we see shapes are the same but the way we see shapes are the same but the way we see that things are actually working as we that things are actually working as we that things are actually working as we want them to now is that when we look at want them to now is that when we look at want them to now is that when we look at the bathroom layer the running mean the bathroom layer the running mean the bathroom layer the running mean shape is now one by one by 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 476,
      "text": "so we're shape is now one by one by 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 477,
      "text": "so we're shape is now one by one by 68.",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 478,
      "text": "so we're only maintaining 68 means for every one only maintaining 68 means for every one only maintaining 68 means for every one of our channels and we're treating both of our channels and we're treating both of our channels and we're treating both the zeroth and the First Dimension as a the zeroth and the First Dimension as a the zeroth and the First Dimension as a batch Dimension which is exactly what we batch Dimension which is exactly what we batch Dimension which is exactly what we want so let me retrain the neural lot want so let me retrain the neural lot want",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 479,
      "text": "so let me retrain the neural lot now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 480,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 481,
      "text": "so I retrained the neural net now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 482,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 483,
      "text": "so I retrained the neural net now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 484,
      "text": "okay",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 485,
      "text": "so I retrained the neural net with the bug fix we get a nice curve and with the bug fix we get a nice curve and with the bug fix we get a nice curve and when we look at the validation when we look at the validation when we look at the validation performance we do actually see a slight performance we do actually see a slight performance we do actually see a slight Improvement",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 486,
      "text": "so we went from 2.029 to Improvement",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 487,
      "text": "so we went from 2.029 to Improvement",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 488,
      "text": "so we went from 2.029 to 2.022 so basically the bug inside the 2.022 so basically the bug inside the 2.022 so basically the bug inside the bathroom was holding up us back like a bathroom was holding up us back like a bathroom was holding up us back like a little bit it looks like and we are little bit it looks like and we are little bit it looks like and we are getting a tiny Improvement now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 489,
      "text": "but it's getting a tiny Improvement now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 490,
      "text": "but it's getting a tiny Improvement now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 491,
      "text": "but it's not clear if this is statistical not clear if this is statistical not clear if this is statistical significant significant significant um um and the reason we slightly expect an and the reason we slightly expect an and the reason we slightly expect an improvement is because we're not improvement is because we're not improvement is because we're not maintaining so many different means and maintaining so many different means and maintaining so many different means and variances that are only estimated using variances that are only estimated using variances that are only estimated using using 32 numbers effectively now we are using 32 numbers effectively now we are using 32 numbers effectively now we are estimating them using 32 times 4 numbers estimating them using 32 times 4 numbers estimating them using 32 times 4 numbers so you just have a lot more numbers that so you just have a lot more numbers that so you just have a lot more numbers that go into any one estimate of the mean and go into any one estimate of the mean and go into any one estimate of the mean and variance and it allows things to be a variance and it allows things to be a variance and it allows things to be a bit more stable and less Wiggly inside bit more stable and less Wiggly inside bit more stable and less Wiggly inside those estimates of those statistics",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 492,
      "text": "so those estimates of those statistics so those estimates of those statistics so pretty nice with this more General pretty nice with this more General pretty nice with this more General architecture in place we are now set up architecture in place we are now set up architecture in place we are now set up to push the performance further by to push the performance further by to push the performance further by increasing the size of the network so increasing the size of the network so increasing the size of the network so for example I bumped up the number of for example I bumped up the number of for example I bumped up the number of embeddings to 24 instead of 10 and also embeddings to 24 instead of 10 and also embeddings to 24 instead of 10 and also increased number of hidden units but increased number of hidden units but increased number of hidden units but using the exact same architecture we now using the exact same architecture we now using the exact same architecture we now have 76 000 parameters and the training have 76 000 parameters and the training have 76 000 parameters and the training takes a lot longer but we do get a nice takes a lot longer but we do get a nice takes a lot longer but we do get a nice curve and then when you actually curve and then when you actually curve and then when you actually evaluate the performance we are now evaluate the performance we are now evaluate the performance we are now getting validation performance of 1.993 getting validation performance of 1.993 getting validation performance of 1.993 so we've crossed over the 2.0 sort of so we've crossed over the 2.0 sort of so we've crossed over the 2.0 sort of territory and right about 1.99 but we territory and right about 1.99 but we territory and right about 1.99 but we are starting to have to wait quite a bit are starting to have to wait quite a bit are starting to have to wait quite a bit longer and we're a little bit in the longer and we're a little bit in the longer",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 493,
      "text": "and we're a little bit in the dark with respect to the correct setting dark with respect to the correct setting dark with respect to the correct setting of the hyper parameters here and the of the hyper parameters here and the of the hyper parameters here and the learning rates and so on because the learning rates and so on because the learning rates and so on because the experiments are starting to take longer experiments are starting to take longer experiments are starting to take longer to train",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 494,
      "text": "and so we are missing sort of to train",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 495,
      "text": "and so we are missing sort of to train",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 496,
      "text": "and so we are missing sort of like an experimental harness on which we like an experimental harness on which we like an experimental harness on which we could run a number of experiments and could run a number of experiments and could run a number of experiments and really tune this architecture very well really tune this architecture very well really tune this architecture very well",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 497,
      "text": "so I'd like to conclude now with a few",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 498,
      "text": "so I'd like to conclude now with a few",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 499,
      "text": "so I'd like to conclude now with a few notes we basically improved our notes we basically improved our notes we basically improved our performance from a starting of 2.1 down performance from a starting of 2.1 down performance from a starting of 2.1 down to 1.9",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 500,
      "text": "but I don't want that to be the to 1.9",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 501,
      "text": "but I don't want that to be the to 1.9",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 502,
      "text": "but I don't want that to be the focus because honestly we're kind of in focus because honestly we're kind of in focus because honestly we're kind of in the dark we have no experimental harness the dark we have no experimental harness the dark we have no experimental harness we're just guessing and checking and we're just guessing and checking and we're just guessing and checking",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 503,
      "text": "and this whole thing is terrible we're just this whole thing is terrible we're just this whole thing is terrible we're just looking at the training loss normally looking at the training loss normally looking at the training loss normally you want to look at both the training you want to look at both the training you want to look at both the training and the validation loss together and the and the validation loss together and",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 504,
      "text": "the and the validation loss together and the whole thing looks different if you're whole thing looks different if you're whole thing looks different if you're actually trying to squeeze out numbers actually trying to squeeze out numbers actually trying to squeeze out numbers that said we did implement this that said we did implement this that said we did implement this architecture from the wavenet paper but architecture from the wavenet paper but architecture from the wavenet paper but we did not implement this specific uh we did not implement this specific uh we did not implement this specific uh forward pass of it where you have a more forward pass of it where you have a more forward pass of it where you have a more complicated a linear layer sort of that complicated a linear layer sort of that complicated a linear layer sort of that is this gated linear layer kind of and is this gated linear layer kind of and is this gated linear layer kind of and there's residual connections and",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 505,
      "text": "Skip there's residual connections and Skip there's residual connections and Skip connections and so on so we did not connections and so on so we did not connections and",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 506,
      "text": "so on so we did not Implement that we just implemented this Implement that we just implemented this Implement that we just implemented this structure I would like to briefly hint structure I would like to briefly hint structure I would like to briefly hint or preview how what we've done here or preview how what we've done here or preview how what we've done here relates to convolutional neural networks relates to convolutional neural networks relates to convolutional neural networks as used in the wavenet paper and as used in the wavenet paper and as used in the wavenet paper and basically the use of convolutions is basically the use of convolutions is basically the use of convolutions is strictly for efficiency it doesn't strictly for efficiency it doesn't strictly for efficiency it doesn't actually change the model we've actually change the model we've actually change the model we've implemented implemented implemented so here for example so here for example so here for example let me look at a specific name to work let me look at a specific name to work let me look at a specific name to work with an example so there's a name in our with an example so there's a name in our with an example so there's a name in our training set and it's DeAndre and it has training set",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 507,
      "text": "and it's DeAndre",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 508,
      "text": "and it has training set",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 509,
      "text": "and it's DeAndre",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 510,
      "text": "and it has seven letters so that is eight seven letters so that is eight seven letters so that is eight independent examples in our model so all independent examples in our model so all independent examples in our model so all these rows here are independent examples these rows here are independent examples these rows here are independent examples of the Android of the Android of the Android now you can forward of course",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 511,
      "text": "any one of now you can forward of course any one of now you can forward of course any one of these rows independently so I can take these rows independently so I can take these rows independently so I can take my model and call call it on any my model and call call it on any my model and call call it on any individual index notice by the way here individual index notice by the way here individual index notice by the way here I'm being a little bit tricky I'm being a little bit tricky I'm being a little bit tricky the reason for this is that extra at the reason for this is that extra at the reason for this is that extra at seven that shape is just seven that shape is just seven that shape is just um one dimensional array of eight",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 512,
      "text": "so you um one dimensional array of eight",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 513,
      "text": "so you um one dimensional array of eight so you can't actually call the model on it can't actually call the model on it can't actually call the model on it you're going to get an error because you're going to get an error because you're going to get an error because there's no batch dimension there's no batch dimension there's no batch dimension",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 514,
      "text": "so when you do extra at so when you do extra at so when you do extra at a list of seven then the shape of this a list of seven then the shape of this a list of seven then the shape of this becomes one by eight",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 515,
      "text": "so I get an extra becomes one by eight",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 516,
      "text": "so I get an extra becomes one by eight",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 517,
      "text": "so I get an extra batch dimension of one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 518,
      "text": "and then we can batch dimension of one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 519,
      "text": "and then we can batch dimension of one",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 520,
      "text": "and then we can forward the model forward the model",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 521,
      "text": "so",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 522,
      "text": "so so that forwards a single example and you that forwards a single example and you that forwards a single example",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 523,
      "text": "and you might imagine that you actually may want might imagine that you actually may want might imagine that you actually may want to forward all of these eight to forward all of these eight to forward all of these eight um at the same time um at the same time um at the same time so pre-allocating some memory and then so pre-allocating some memory and then so pre-allocating some memory and then doing a for Loop eight times and doing a for Loop eight times and doing a for Loop eight times and forwarding all of those eight here will forwarding all of those eight here will forwarding all of those eight here will give us all the logits in all these give us all the logits in all these give us all the logits in all these different cases different cases different cases now for us with the model as we've now for us with the model as we've now for us with the model as we've implemented it right now this is eight implemented it right now this is eight implemented it right now this is eight independent calls to our model independent calls to our model independent calls to our model but what convolutions allow you to do is but what convolutions allow you to do is",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 524,
      "text": "but what convolutions allow you to do is it allow you to basically slide this it allow you to basically slide this it allow you to basically slide this model efficiently over the input model efficiently over the input model efficiently over the input sequence",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 525,
      "text": "and so this for Loop can be sequence",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 526,
      "text": "and so this for Loop can be sequence",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 527,
      "text": "and so this for Loop can be done not outside in Python but inside of done not outside in Python but inside of done not outside in Python but inside of kernels in Cuda and so this for Loop kernels in Cuda and so this for Loop kernels in Cuda and so this for Loop gets hidden into the convolution gets hidden into the convolution gets hidden into the convolution so the convolution basically you can so the convolution basically you can so the convolution basically you can cover this it's a for Loop applying a cover this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 528,
      "text": "it's a for Loop applying a cover this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 529,
      "text": "it's a for Loop applying a little linear filter over space of some little linear filter over space of some little linear filter over space of some input sequence and in our case the space input sequence and in our case the space input sequence and in our case the space we're interested in is one dimensional we're interested in is one dimensional we're interested in is one dimensional and we're interested in sliding these and we're interested in sliding these and we're interested in sliding these filters over the input data filters over the input data filters over the input data",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 530,
      "text": "so this diagram actually is fairly good so this diagram actually is fairly good",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 531,
      "text": "so this diagram actually is fairly good as well as well as well basically what we've done is here they basically what we've done is here they basically what we've done is here they are highlighting in Black one individ are highlighting in Black one individ are highlighting in Black one individ one single sort of like tree of this one single sort of like tree of this one single sort of like tree of this calculation so just calculating the calculation so just calculating the calculation so just calculating the single output example here single output example here single output example here um um",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 532,
      "text": "and so this is basically what we've",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 533,
      "text": "and so this is basically what we've",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 534,
      "text": "and so this is basically what we've implemented here we've implemented a implemented here we've implemented a implemented here we've implemented a single this black structure we've single this black structure",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 535,
      "text": "we've single this black structure we've implemented that and calculated a single implemented that and calculated a single implemented that and calculated a single output like a single example output like a single example output like a single example but what collusions allow you to do is but what collusions allow you to do is but what collusions allow you to do is it allows you to take this black it allows you to take this black it allows you to take this black structure and kind of like slide it over structure and kind of like slide it over structure and kind of like slide it over the input sequence here and calculate the input sequence here and calculate the input sequence here and calculate all of these orange outputs at the same all of these orange outputs at the same all of these orange outputs at the same time or here that corresponds to time or here that corresponds to time or here that corresponds to calculating all of these outputs of calculating all of these outputs of calculating all of these outputs of um at all the positions of DeAndre at um at all the positions of DeAndre at um at all the positions of DeAndre at the same time the same time the same time and the reason that this is much more and the reason that this is much more and the reason that this is much more efficient is because number one as I efficient is because number one as I efficient is because number one as I mentioned the for Loop is inside the mentioned the for Loop is inside the mentioned the for Loop is inside the Cuda kernels in the sliding so that Cuda kernels in the sliding so that Cuda kernels in the sliding so that makes it efficient but number two notice makes it efficient but number two notice makes it efficient but number two notice the variable reuse here for example if the variable reuse here for example if the variable reuse here for example if we look at this circle this node here we look at this circle this node here we look at this circle this node here this node here is the right child of this node here is the right child of this node here is the right child of this node but is also the left child of this node but is also the left child of this node but is also the left child of the node here the node here the node here",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 536,
      "text": "and so basically this node and its value",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 537,
      "text": "and so basically this node and its value",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 538,
      "text": "and so basically this node and its value is used twice is used twice is used twice and so right now in this naive way we'd and so right now in this naive way we'd and so right now in this naive way we'd have to recalculate it but here we are have to recalculate it but here we are have to recalculate it but here we are allowed to reuse it allowed to reuse it allowed to reuse it so in the convolutional neural network so in the convolutional neural network so in the convolutional neural network you think of these linear layers that we you think of these linear layers that we you think of these linear layers that we have up above as filters and we take have up above as filters and we take have up above as filters and we take these filters and they're linear filters these filters",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 539,
      "text": "and they're linear filters these filters",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 540,
      "text": "and they're linear filters and you slide them over input sequence and you slide them over input sequence and you slide them over input sequence and we calculate the first layer and and we calculate the first layer and and we calculate the first layer",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 541,
      "text": "and then the second layer and then the third then the second layer and then the third then the second layer and then the third layer and then the output layer of the layer and then the output layer of the layer and then the output layer of the sandwich",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 542,
      "text": "and it's all done very sandwich",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 543,
      "text": "and it's all done very sandwich",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 544,
      "text": "and it's all done very efficiently using these convolutions efficiently using these convolutions efficiently using these convolutions so we're going to cover that in a future",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 545,
      "text": "so we're going to cover that in a future",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 546,
      "text": "so we're going to cover that in a future video the second thing I hope you took video the second thing I hope you took video the second thing I hope you took away from this video is you've seen me away from this video is you've seen me away from this video is you've seen me basically Implement all of these layer basically Implement all of these layer basically Implement all of these layer Lego building blocks or module building Lego building blocks or module building Lego building blocks or module building blocks and I'm implementing them over blocks",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 547,
      "text": "and I'm implementing them over blocks and I'm implementing them over here and we've implemented a number of here and we've implemented a number of here and we've implemented a number of layers together and we've also layers together and we've also layers together and we've also implemented these these containers and implemented these these containers and implemented these these containers and we've overall pytorchified our code we've overall pytorchified our code we've overall pytorchified our code quite a bit more quite a bit more quite a bit more now basically what we're doing here is now basically what we're doing here is now basically what we're doing here is we're re-implementing torch.nn which is we're re-implementing torch.nn which is we're re-implementing torch.nn which is the neural networks library on top of the neural networks library on top of the neural networks library on top of torch.tensor and it looks very much like torch.tensor and it looks very much like torch.tensor and it looks very much like this except it is much better because this except it is much better because this except it is much better because because it's in pi torch instead of because it's in pi torch instead of because it's in pi torch instead of jingling my Jupiter notebook",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 548,
      "text": "so I think jingling my Jupiter notebook",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 549,
      "text": "so I think jingling my Jupiter notebook",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 550,
      "text": "so I think going forward I will probably have going forward",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 551,
      "text": "I will probably have going forward",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 552,
      "text": "I will probably have considered us having unlocked considered us having unlocked considered us having unlocked um torch.nn we understand roughly what's um torch.nn we understand roughly what's um torch.nn we understand roughly what's in there how these modules work how in there how these modules work how in there how these modules work how they're nested and what they're doing on they're nested and what they're doing on they're nested and what they're doing on top of torture tensor",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 553,
      "text": "so hopefully we'll top of torture tensor so hopefully we'll top of torture tensor",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 554,
      "text": "so hopefully we'll just uh we'll just switch over and just uh we'll just switch over and just uh we'll just switch over and continue and start using torch.net continue and start using torch.net continue and start using torch.net directly the next thing I hope you got a directly the next thing I hope you got a directly the next thing I hope you got a bit of a sense of is what the bit of a sense of is what the bit of a sense of is what the development process of building deep development process of building deep development process of building deep neural networks looks like which I think neural networks looks like which I think neural networks looks like which I think was relatively representative to some was relatively representative to some was relatively representative to some extent",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 555,
      "text": "so number one we are spending a extent so number one we are spending a extent so number one we are spending a lot of time in the documentation page of lot of time in the documentation page of lot of time in the documentation page of pytorch and we're reading through all pytorch and we're reading through all pytorch and we're reading through all the layers looking at documentations the layers looking at documentations the layers looking at documentations where the shapes of the inputs what can where the shapes of the inputs what can where the shapes of the inputs what can they be what does the layer do",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 556,
      "text": "and so on they be what does the layer do",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 557,
      "text": "and so on they be what does the layer do and so on unfortunately I have to say the unfortunately I have to say the unfortunately I have to say the patreon's documentation is not are very patreon's documentation is not are very patreon's documentation is not are very good they spend a ton of time on good they spend a ton of time on good they spend a ton of time on Hardcore engineering of all kinds of Hardcore engineering of all kinds of Hardcore engineering of all kinds of distributed Primitives Etc but as far as distributed Primitives Etc but as far as distributed Primitives Etc but as far as I can tell no one is maintaining any I can tell no one is maintaining any I can tell no one is maintaining any documentation it will lie to you it will documentation it will lie to you it will documentation it will lie to you it will be wrong it will be incomplete it will be wrong it will be incomplete it will be wrong it will be incomplete it will be unclear",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 558,
      "text": "so unfortunately it is what be unclear",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 559,
      "text": "so unfortunately it is what be unclear",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 560,
      "text": "so unfortunately it is what it is",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 561,
      "text": "and you just kind of do your best it is",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 562,
      "text": "and you just kind of do your best it is",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 563,
      "text": "and you just kind of do your best um with what they've given us um with what they've given us um with what they've given us um number two um number two um number two uh the other thing that I hope you got a uh the other thing that I hope you got a uh the other thing that I hope you got a sense of is there's a ton of trying to sense of is there's a ton of trying to sense of is there's a ton of trying to make the shapes work and there's a lot make the shapes work and there's a lot make the shapes work and there's a lot of gymnastics around these of gymnastics around these of gymnastics around these multi-dimensional arrays and are they multi-dimensional arrays and are they multi-dimensional arrays and are they two-dimensional three-dimensional two-dimensional three-dimensional two-dimensional three-dimensional four-dimensional uh what layers take four-dimensional uh what layers take four-dimensional uh what layers take what shapes is it NCL or NLC",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 564,
      "text": "and you're what shapes is it NCL or NLC",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 565,
      "text": "and you're what shapes is it NCL or NLC",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 566,
      "text": "and you're promoting and viewing",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 567,
      "text": "and it just can promoting and viewing and it just can promoting and viewing and it just can get pretty messy and so that brings me get pretty messy and so that brings me get pretty messy and so that brings me to number three",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 568,
      "text": "I very often prototype to number three I very often prototype to number three I very often prototype these layers and implementations in these layers and implementations in these layers and implementations in jupyter notebooks and make sure that all jupyter notebooks and make sure that all jupyter notebooks and make sure that all the shapes work out and I'm spending a the shapes work out and I'm spending a the shapes work out and I'm spending a lot of time basically babysitting the lot of time basically babysitting the lot of time basically babysitting the shapes and making sure everything is shapes and making sure everything is shapes and making sure everything is correct and then once I'm satisfied with correct",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 569,
      "text": "and then once I'm satisfied with correct",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 570,
      "text": "and then once I'm satisfied with the functionality in the Jupiter the functionality in the Jupiter the functionality in the Jupiter notebook I will take that code and copy notebook I will take that code and copy notebook I will take that code and copy paste it into my repository of actual paste it into my repository of actual paste it into my repository of actual code that I'm training with and so then code that I'm training with and so then code that I'm training with",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 571,
      "text": "and so then I'm working with vs code on the side",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 572,
      "text": "so I'm working with vs code on the side",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 573,
      "text": "so I'm working with vs code on the side",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 574,
      "text": "so I usually have jupyter notebook and vs I usually have jupyter notebook and vs I usually have jupyter notebook and vs code",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 575,
      "text": "I develop in Jupiter notebook I code I develop in Jupiter notebook",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 576,
      "text": "I code I develop in Jupiter notebook I paste into vs code",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 577,
      "text": "and then I kick off paste into vs code",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 578,
      "text": "and then I kick off paste into vs code",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 579,
      "text": "and then I kick off experiments from from the reaper of experiments from from the reaper of experiments from from the reaper of course from the code repository so course from the code repository so course from the code repository so that's roughly some notes on the that's roughly some notes on the that's roughly some notes on the development process of working with development process of working with development process of working with neurons lastly I think this lecture neurons lastly I think this lecture neurons lastly I think this lecture unlocks a lot of potential further unlocks a lot of potential further unlocks a lot of potential further lectures because number one we have to lectures because number one we have to lectures because number one we have to convert our neural network to actually convert our neural network to actually convert our neural network to actually use these dilated causal convolutional use these dilated causal convolutional use these dilated causal convolutional layers so implementing the comnet number layers so implementing the comnet number layers so implementing the comnet number two potentially starting to get into two potentially starting to get into two potentially starting to get into what this means whatever residual what this means whatever residual what this means whatever residual connections and Skip connections and why connections and Skip connections and why connections and Skip connections and why are they useful are they useful are they useful number three we as I mentioned we don't number three we as I mentioned we don't number three we as I mentioned we don't have any experimental harness",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 580,
      "text": "so right have any experimental harness so right have any experimental harness so right now I'm just guessing checking now I'm just guessing checking now I'm just guessing checking everything this is not representative of everything this is not representative of everything this is not representative of typical deep learning workflows you have typical deep learning workflows you have typical deep learning workflows you have to set up your evaluation harness you to set up your evaluation harness you to set up your evaluation harness you can kick off experiments you have lots can kick off experiments you have lots can kick off experiments you have lots of arguments that your script can take of arguments that your script can take of arguments that your script can take you're you're kicking off a lot of you're you're kicking off a lot of you're you're kicking off a lot of experimentation you're looking at a lot experimentation you're looking at a lot experimentation you're looking at a lot of plots of training and validation of plots of training and validation of plots of training and validation losses and you're looking at what is losses and you're looking at what is losses and you're looking at what is working and what is not working and working and what is not working and working and what is not working and you're working on this like population you're working on this like population you're working on this like population level and you're doing all these hyper level and you're doing all these hyper level and you're doing all these hyper parameter searches and so we've done parameter searches and so we've done parameter searches and so we've done none of that so far so how to set that none of that so far so how to set that none of that so far so how to set that up and how to make it good I think as a up and how to make it good",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 581,
      "text": "I think as a up and how to make it good",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 582,
      "text": "I think as a whole another topic number three we whole another topic number three we whole another topic number three we should probably cover recurring neural should probably cover recurring neural should probably cover recurring neural networks RNs lstm's grooves and of networks RNs lstm's grooves and of networks RNs lstm's grooves and of course Transformers so many uh places to course Transformers so many uh places to course Transformers so many uh places to go and we'll cover that in the future go",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 583,
      "text": "and we'll cover that in the future go",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 584,
      "text": "and we'll cover that in the future for now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 585,
      "text": "bye sorry I forgot to say that for now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 586,
      "text": "bye sorry I forgot to say that for now",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 587,
      "text": "bye sorry I forgot to say that if you are interested I think it is kind if you are interested I think it is kind if you are interested I think it is kind of interesting to try to beat this of interesting to try to beat this of interesting to try to beat this number 1.993 because I really haven't number 1.993 because I really haven't number 1.993 because I really haven't tried a lot of experimentation here and tried a lot of experimentation here and tried a lot of experimentation here and there's quite a bit of fruit potentially there's quite a bit of fruit potentially there's quite a bit of fruit potentially to still purchase further so I haven't to still purchase further",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 588,
      "text": "so I haven't to still purchase further",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 589,
      "text": "so I haven't tried any other ways of allocating these tried any other ways of allocating these tried any other ways of allocating these channels in this neural net maybe the channels in this neural net maybe the channels in this neural net maybe the number of dimensions for the embedding number of dimensions for the embedding number of dimensions for the embedding is all wrong maybe it's possible to is all wrong maybe it's possible to is all wrong maybe it's possible to actually take the original network with actually take the original network with actually take the original network with just one hidden layer and make it big just one hidden layer and make it big just one hidden layer and make it big enough and actually beat my fancy enough and actually beat my fancy enough and actually beat my fancy hierarchical Network it's not obvious hierarchical Network it's not obvious hierarchical Network",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 590,
      "text": "it's not obvious that would be kind of embarrassing if that would be kind of embarrassing if that would be kind of embarrassing if this did not do better even once you this did not do better even once you this did not do better even once you torture it a little bit maybe you can torture it a little bit maybe you can torture it a little bit maybe you can read the weight net paper and try to read the weight net paper and try to read the weight net paper and try to figure out how some of these layers work figure out how some of these layers work figure out how some of these layers work and Implement them yourselves using what and Implement them yourselves using what and Implement them yourselves using what we have we have we have and of course you can always tune some and of course you can always tune some and of course you can always tune some of the initialization or some of the of the initialization or some of the of the initialization or some of the optimization and see if you can improve optimization and see if you can improve optimization and see if you can improve it that way",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 591,
      "text": "so I'd be curious if people it that way",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 592,
      "text": "so I'd be curious if people it that way",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 593,
      "text": "so I'd be curious if people can come up with some ways to beat this can come up with some ways to beat this can come up with some ways to beat this",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 594,
      "text": "and yeah",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    },
    {
      "id": 595,
      "text": "that's it for now bye",
      "start_time": "00:00:02.570",
      "end_time": "00:56:22.880"
    }
  ]
}