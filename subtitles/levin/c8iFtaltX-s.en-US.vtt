WEBVTT
Kind: captions
Language: en-US

00:00:00.000 --> 00:00:04.320
The hardware does not define you. I get lots of emails from people who say,

00:00:04.320 --> 00:00:07.760
I've read your papers. I understand I'm a collective intelligence of groups of cells.

00:00:07.760 --> 00:00:11.760
What do I do now? I just learned that I'm full of cogs and gears. Therefore,

00:00:11.760 --> 00:00:15.920
I'm not what I thought I was. And I think this is a really unfortunate way to think.

00:00:15.920 --> 00:00:21.040
The bottom line is you are still the amazing integrated being with potential and a

00:00:21.040 --> 00:00:26.959
responsibility to do things. I think we are actually a collection of interacting perspectives

00:00:26.959 --> 00:00:33.680
and interacting consciousnesses. Professor Michael Levin, welcome. What's one of the biggest

00:00:33.680 --> 00:00:38.000
myths in biology that you, with your research, with your lab, is helping overturn?

00:00:38.720 --> 00:00:44.959
Yeah. Hey Curt, great to see you again. I think that one of the biggest myths in biology is that

00:00:44.959 --> 00:00:51.279
the best explanations come at the level of molecules. So this biochemistry, what they call

00:00:51.279 --> 00:00:58.320
molecular mechanism, is usually currently taken to be the gold standard of what we're looking for

00:00:58.320 --> 00:01:06.000
in terms of explanations. And I think in some cases that has the most value, but in most cases,

00:01:06.000 --> 00:01:14.000
I think it's not the right level. And Dennis Noble has a really interesting set of papers and talks on

00:01:14.639 --> 00:01:20.320
biological relativity. So this idea that different levels of explanation, especially in biology,

00:01:20.400 --> 00:01:25.919
provide the most bang for the buck. And I think in terms of looking forward as to what do these

00:01:25.919 --> 00:01:31.279
explanations let you do as a next step, I think we really need to go beyond the molecular level

00:01:31.279 --> 00:01:35.680
for many of these things. What's the difference between weak emergence and strong emergence?

00:01:36.720 --> 00:01:42.879
I think that emergence in general is basically just the measure of surprise for the observer.

00:01:42.879 --> 00:01:47.760
So I think a phenomenon is considered emergent by us if whatever it's doing was something that

00:01:47.760 --> 00:01:52.559
we didn't anticipate. And so it's relative. I don't think emergence is an absolute thing that

00:01:53.279 --> 00:01:57.760
either is there or isn't, or is weak or strong. It's just a measure of the amount of surprise.

00:01:57.760 --> 00:02:02.160
You know, how much extra is the system doing that you, knowing the rules and the various

00:02:02.160 --> 00:02:06.080
properties of its parts, didn't see coming? That's emergence, I think.

00:02:07.360 --> 00:02:13.119
Would you say then that biology has physics fundamentally? So it goes biology, chemistry, physics?

00:02:14.000 --> 00:02:21.279
I mean, people have certainly made that kind of ladder. I'm not sure what we can do with that. I

00:02:21.279 --> 00:02:27.919
think that it's more like these different levels have their own types of concepts that are useful

00:02:27.919 --> 00:02:31.279
for understanding what's going on, and they have their own autonomy. That's really important.

00:02:31.279 --> 00:02:36.800
That I think there's a lot of utility in considering how some of these higher levels

00:02:36.800 --> 00:02:41.520
are autonomous, and they do things that the lower levels don't do. And that gives us power,

00:02:42.160 --> 00:02:45.440
that gives us experimental power. And would you say that there's something

00:02:45.440 --> 00:02:52.160
that the lower levels don't do in principle or in practice? So for instance, is there something

00:02:52.160 --> 00:02:57.279
that a cell is doing that in principle can't be derived from the underlying chemistry,

00:02:57.279 --> 00:03:00.160
which in principle can't be derived from the underlying physics?

00:03:00.720 --> 00:03:03.839
Yeah, it really depends on what you mean by derived. But for example,

00:03:03.839 --> 00:03:09.199
there are certainly aspects of, let's say, cognitive functions that we normally associate with

00:03:09.279 --> 00:03:14.800
fairly complex creatures, brains, and so on, that we are now seeing in very simple basal media.

00:03:14.800 --> 00:03:19.119
So even something as simple as a gene regulatory network can have six different kinds of learning

00:03:19.119 --> 00:03:23.919
and memory, for example, Pavlovian conditioning. And so there, what you would see is on the one

00:03:23.919 --> 00:03:27.600
hand, you say, okay, well, look, here's a simple bit of chemistry that's actually doing these

00:03:27.600 --> 00:03:32.880
complex things that we normally associate with behavior science and with investigating cognitive

00:03:32.880 --> 00:03:38.720
systems. You can always tell a chemistry story about any effect. In fact, you could also tell

00:03:38.800 --> 00:03:42.720
physics story as well. If you look under the hood, all you ever find is chemistry and physics,

00:03:42.720 --> 00:03:48.960
right? But the more interesting thing about that story is that you actually can use paradigms from

00:03:48.960 --> 00:03:53.520
behavioral science, such as learning and conditioning and communication and active

00:03:53.520 --> 00:03:58.080
inference and things like that. And that lets you do way more than if you were to restrict yourself

00:03:58.080 --> 00:04:02.559
to an understanding at the level of mechanism. What's super interesting there is that you said

00:04:02.559 --> 00:04:06.720
you could always tell a chemistry story or you could always tell a physics story to explain

00:04:06.720 --> 00:04:11.520
some biological process, but you can't always tell a biological story to something that's physics

00:04:11.520 --> 00:04:16.640
related. So what people would consider more fundamental or what gives rise to the rest in

00:04:16.640 --> 00:04:23.519
terms of ontology would be, well, can you tell a story in terms of so-and-so? So can you tell a

00:04:23.519 --> 00:04:27.839
story in terms of biology of physics? Can you tell a story of, well, you could tell a story of

00:04:27.839 --> 00:04:33.200
architecture for these buildings behind us, maybe even of biology because people comprise the people

00:04:33.200 --> 00:04:39.200
who made this. And you could tell a mathematical story, but it would be difficult to make the case

00:04:39.200 --> 00:04:43.839
that you could tell an architectural story in the way that we understand architecture, not a metaphor

00:04:44.480 --> 00:04:47.600
about mathematics. Do you agree with that or do you disagree with that?

00:04:48.720 --> 00:04:53.920
I think that's somewhat true, although it's not as true as we think. So oftentimes you actually

00:04:53.920 --> 00:04:59.440
can tell an interesting story cashed out in the terms of behavioral science, for example,

00:04:59.519 --> 00:05:04.640
active inference, for example, various learning modalities of objects that are really thought to

00:05:04.640 --> 00:05:10.320
be the domain of physics and chemistry. So I think there's more of that than we tend to

00:05:10.320 --> 00:05:16.160
understand as of now. But it is also the case that the fact that you can tell a physics story

00:05:16.160 --> 00:05:23.600
doesn't mean that there's that much value in it necessarily. So for example, imagine that

00:05:23.600 --> 00:05:28.480
there's a chess game going on. So you could absolutely tell the story of that chess game

00:05:28.480 --> 00:05:32.559
in terms of particle movements or maybe quantum foam or I don't know what, whatever the bottom

00:05:32.559 --> 00:05:37.839
level is. So you can do that. How much does that help you in playing the next game of chess?

00:05:37.839 --> 00:05:43.519
Almost not at all, right? If your goal is to understand what happened at the physical level,

00:05:43.519 --> 00:05:47.600
yes, you can tell a story about all the atoms that were pushing and pulling and all of that.

00:05:47.600 --> 00:05:52.559
But if your goal is to understand the large scale rules of the game of chess, the principles,

00:05:53.200 --> 00:05:57.040
and more importantly, to play the next game of chess better than what you just witnessed,

00:05:57.359 --> 00:06:02.160
that story is almost completely useless to you. And this abounds in biology, where

00:06:02.160 --> 00:06:06.880
you can use chemistry and physics to tell a story looking backwards about what just

00:06:06.880 --> 00:06:11.440
happened and why. But in terms of understanding what it means and developing that into a new

00:06:12.399 --> 00:06:16.799
research direction, new biomedicine, new discoveries, it often means that you actually

00:06:16.799 --> 00:06:22.079
have to tell a much larger scale story about memories, about goals, about preferences,

00:06:22.079 --> 00:06:26.880
and these other kinds of concepts. What would be the analogy here for,

00:06:26.880 --> 00:06:30.640
so the rules of chess, what are you trying to understand? The rules of what? Biology,

00:06:30.640 --> 00:06:36.320
developmental biology, cellular biology? Well, the thing that ties all of our work together,

00:06:36.320 --> 00:06:40.000
I mean, we do a lot of different things. We do cancer biology, we do developmental biology,

00:06:40.000 --> 00:06:45.760
we do regeneration, aging, not to mention AI and some other things. What ties it all together

00:06:45.760 --> 00:06:52.959
is really an effort to understand embodied mind. So the center focus of all my work is really to

00:06:52.959 --> 00:07:00.320
understand cognition broadly in very unconventional, diverse embodiments. And in biology,

00:07:01.040 --> 00:07:09.119
what we try to understand is how life and mind intersect, and what are the features that allow

00:07:10.399 --> 00:07:14.799
biological systems to have preferences, to have goals, to have intelligence, to have

00:07:15.519 --> 00:07:20.880
clever problem-solving in different spaces. Okay, great. Because there are a variety of

00:07:20.880 --> 00:07:26.399
different themes that your work touches on. So regeneration, cancer research, basal cognition,

00:07:26.399 --> 00:07:30.959
cross-embryomorphic genetic assistance, which is from a podcast that we did a few months ago,

00:07:30.959 --> 00:07:35.760
and that will be on screen, link in the description. There's xenobots, anthropots.

00:07:36.480 --> 00:07:42.880
Please talk about what ties that all together. Yeah. What ties it all together is the effort

00:07:42.880 --> 00:07:48.000
to understand intelligence. All of those things are really different ways that intelligence

00:07:48.559 --> 00:07:53.119
is embodied in the physical world. And so, for example, when we made xenobots and anthropots,

00:07:53.119 --> 00:07:58.720
our goal with all of these kinds of synthetic constructs is to understand where the goals of

00:07:58.720 --> 00:08:04.959
novel systems come from. So typically, when you have a natural plant or animal and it's doing

00:08:04.959 --> 00:08:10.480
various things, not only the structure and the behavior of that organism, but also whatever goals

00:08:10.480 --> 00:08:16.720
it may have, we typically think of are driven by evolutionary past. So these are set by the

00:08:16.720 --> 00:08:21.119
evolutionary history, by adaptation to the environment. So for eons, everything that

00:08:21.920 --> 00:08:25.279
wasn't quite good at pursuing those goals died out, and then this is what you have. That's the

00:08:25.279 --> 00:08:29.920
standard story. So the reason that we make these synthetic constructs is to ask, okay, well,

00:08:29.920 --> 00:08:34.719
for creatures that never existed before, that do not have an evolutionary history of selection,

00:08:34.719 --> 00:08:39.599
where do their goals come from? So that's just part of that research program to understand

00:08:39.599 --> 00:08:44.400
where do the properties of novel cognitive systems come from that do not have a long history

00:08:44.400 --> 00:08:51.679
of selection as that system. Everything else that we do is an extension of our search for

00:08:51.679 --> 00:08:57.840
intelligence. So basically, cancer, right? So the way we think about cancer is as the size of the

00:08:57.840 --> 00:09:04.000
cognitive light cone of living or of cognitive systems. So what I mean by that is every agent

00:09:04.479 --> 00:09:10.559
can be defined by the size of the largest goal it can pursue. So that's the cognitive light cone in

00:09:10.559 --> 00:09:14.640
space and time. What are the biggest goals that it can pursue? So if you think about individual

00:09:14.640 --> 00:09:20.080
cells, they have really sort of humble single cell scale goals. They have metabolic goals,

00:09:20.080 --> 00:09:25.440
they have proliferative goals, and things like that. They handle the situation on a very small

00:09:25.440 --> 00:09:29.919
single cell kind of scale. But during embryonic development and during evolution in general,

00:09:30.320 --> 00:09:36.960
policies for interaction between these cells were developed that allow them to scale the

00:09:36.960 --> 00:09:41.039
cognitive light cone. So groups of cells, for example, the groups of cells

00:09:41.500 --> 00:09:44.600
that are involved in making a salamander limb,

00:09:44.600 --> 00:09:46.400
they have this incredibly grandiose goal

00:09:46.400 --> 00:09:47.240
in a different space.

00:09:47.240 --> 00:09:48.600
Instead of metabolic space,

00:09:48.600 --> 00:09:50.840
they are building something in anatomical space.

00:09:50.840 --> 00:09:52.280
So they have a particular path

00:09:52.280 --> 00:09:53.560
that they want to take in the space

00:09:53.560 --> 00:09:55.340
of possible anatomical shapes.

00:09:55.340 --> 00:09:57.120
So when a salamander loses their limb,

00:09:57.120 --> 00:09:58.959
the cells can tell that they've been pulled away

00:09:58.959 --> 00:10:01.480
from the correct region of anatomical space.

00:10:01.480 --> 00:10:03.440
They work really hard, they rebuild,

00:10:03.440 --> 00:10:04.660
they take that journey again,

00:10:04.660 --> 00:10:06.840
they rebuild that limb, and then they stop.

00:10:06.840 --> 00:10:07.680
And they stop because they know

00:10:07.680 --> 00:10:08.840
they've gotten to where they need to go.

00:10:08.840 --> 00:10:11.160
That whole thing is a navigational task, right?

00:10:11.160 --> 00:10:13.799
And there's some degree of intelligent problem-solving

00:10:13.799 --> 00:10:15.799
that they can use in taking that task.

00:10:15.799 --> 00:10:20.799
So that amazing scale-up of the cognitive light cone,

00:10:21.000 --> 00:10:24.360
that, you know, the light cone measures

00:10:24.360 --> 00:10:25.400
what do you care about?

00:10:25.400 --> 00:10:27.380
So, you know, if you're a bacterium,

00:10:27.380 --> 00:10:29.459
maybe you care about the local sugar concentration

00:10:29.459 --> 00:10:30.299
and a couple of other things,

00:10:30.299 --> 00:10:31.480
but that's basically it.

00:10:31.480 --> 00:10:33.160
If you're a set of salamander cells,

00:10:33.160 --> 00:10:34.119
what you really care about

00:10:34.119 --> 00:10:35.820
is your position in anatomical space.

00:10:35.820 --> 00:10:37.759
Do we have the right number of fingers?

00:10:37.759 --> 00:10:39.360
Is everything the right size?

00:10:39.360 --> 00:10:40.200
And so on.

00:10:40.200 --> 00:10:42.560
And so understanding that scaling of cognition,

00:10:42.560 --> 00:10:43.720
the scaling of goals,

00:10:43.720 --> 00:10:46.279
the how does a collective intelligence work

00:10:46.279 --> 00:10:50.120
that takes the little tiny, very competent tiny components

00:10:50.120 --> 00:10:51.839
that have little tiny light cones,

00:10:51.839 --> 00:10:53.040
and how do they come together

00:10:53.040 --> 00:10:56.839
to form a very large cognitive light cone

00:10:56.839 --> 00:10:58.500
that actually projects into a different space,

00:10:58.500 --> 00:11:01.360
anatomical space now instead of a metabolic space.

00:11:01.360 --> 00:11:04.440
So that's fundamentally a question of intelligence.

00:11:04.440 --> 00:11:07.320
And the other thing about it is that this kind of thinking,

00:11:07.320 --> 00:11:08.279
so this is really important,

00:11:08.639 --> 00:11:10.680
this kind of thinking is not just, you know,

00:11:10.680 --> 00:11:12.480
sort of philosophical embellishment

00:11:12.480 --> 00:11:15.559
because it leads directly to biomedical research programs.

00:11:15.559 --> 00:11:17.160
If you have this kind of idea,

00:11:17.160 --> 00:11:18.599
what you can ask is, well, let's see,

00:11:18.599 --> 00:11:21.919
then if cancer is that type of phenomenon,

00:11:21.919 --> 00:11:24.919
it's a breakdown of that scaling

00:11:24.919 --> 00:11:26.680
and that basically individual cells

00:11:26.680 --> 00:11:28.559
just shrink their light cone back down

00:11:28.559 --> 00:11:31.019
to the level of a primitive microbial cell

00:11:31.019 --> 00:11:32.320
as they were once.

00:11:32.320 --> 00:11:35.080
And that boundary between self and world now shrinks,

00:11:35.080 --> 00:11:36.720
whereas before the boundary was that whole limb,

00:11:36.720 --> 00:11:39.440
now the boundary is just every cell is the self.

00:11:39.440 --> 00:11:41.360
So from that perspective, they're not more selfish,

00:11:41.360 --> 00:11:42.839
they just have smaller selves.

00:11:42.839 --> 00:11:43.680
So that's really important

00:11:43.680 --> 00:11:48.480
because a lot of work in cancer models cancer cell behavior

00:11:48.480 --> 00:11:49.800
from a perspective of game theory,

00:11:49.800 --> 00:11:52.000
like they're less cooperative and they're more selfish.

00:11:52.000 --> 00:11:53.479
Actually, I'm not sure that's true at all.

00:11:53.479 --> 00:11:55.199
I think they just have smaller selves.

00:11:55.199 --> 00:11:56.479
And so-

00:11:56.479 --> 00:11:57.320
Just a moment.

00:11:57.320 --> 00:11:58.139
So you think you would say

00:11:58.139 --> 00:12:00.399
that every organism is equally as selfish,

00:12:00.399 --> 00:12:03.000
it just depends on their concept of self?

00:12:03.000 --> 00:12:05.919
Yeah, I think all agents are,

00:12:05.919 --> 00:12:08.199
one of the things agents do is operate,

00:12:08.199 --> 00:12:09.039
it's not the only thing they do,

00:12:09.039 --> 00:12:10.160
but one of the things they do

00:12:10.160 --> 00:12:12.039
is they operate in their self-interest,

00:12:12.039 --> 00:12:14.440
but the size of that self can grow and shrink.

00:12:14.440 --> 00:12:15.759
So individual cells,

00:12:15.759 --> 00:12:18.479
when they're tied into these large networks,

00:12:18.479 --> 00:12:22.399
using electrical cues, chemical cues, biomechanical cues,

00:12:22.399 --> 00:12:24.440
they're tied into these larger networks

00:12:24.440 --> 00:12:26.800
that partially erase their individuality.

00:12:26.800 --> 00:12:28.800
And we could talk about how I think that happens,

00:12:28.800 --> 00:12:31.839
but what you end up with is a collective intelligence

00:12:31.839 --> 00:12:34.479
that has a much bigger, like a cognitive light cone,

00:12:34.479 --> 00:12:35.880
the goals are much bigger.

00:12:36.720 --> 00:12:37.559
You can scale that up,

00:12:37.559 --> 00:12:41.000
I mean, humans have enormous, enormous cognitive light cones,

00:12:42.000 --> 00:12:44.520
and whatever's beyond that, but that's the thing,

00:12:44.520 --> 00:12:46.440
it's the size of your cognitive light cone

00:12:46.440 --> 00:12:49.160
that determines what kinds of goals you can pursue

00:12:49.160 --> 00:12:51.320
and what space you pursue them in.

00:12:51.320 --> 00:12:54.080
So we talk about goals and we talk about intelligence,

00:12:54.080 --> 00:12:55.199
and you said something interesting,

00:12:55.199 --> 00:12:59.880
which is that life is the embodiment of intelligence,

00:12:59.880 --> 00:13:02.600
or something akin to that, the embodiment of intelligence.

00:13:02.600 --> 00:13:04.279
So it's as if there's intelligence somewhere

00:13:04.279 --> 00:13:07.720
and then you pull from it and you instantiate intelligence.

00:13:07.720 --> 00:13:10.000
So is that the way that you think of it?

00:13:10.000 --> 00:13:11.800
Let me be clear about what I mean.

00:13:12.759 --> 00:13:15.479
In philosophy, there's this concept of universals.

00:13:15.479 --> 00:13:17.240
So Plato had the forms,

00:13:17.240 --> 00:13:19.639
and then would say that this is almost rectangular,

00:13:19.639 --> 00:13:22.559
so it's embodying the rectangularness,

00:13:22.559 --> 00:13:25.000
which is somehow somewhere out there akin to

00:13:25.000 --> 00:13:26.600
what I imagine you meant when you said

00:13:26.600 --> 00:13:28.800
intelligence is there being embodied by this.

00:13:28.800 --> 00:13:30.240
But then there's Aristotle, which says,

00:13:30.240 --> 00:13:32.399
okay, yes, there is something akin to a form,

00:13:32.399 --> 00:13:33.639
it's just not out there,

00:13:33.639 --> 00:13:34.720
it's actually in here,

00:13:34.720 --> 00:13:38.919
the rectangularness is a property of this microphone.

00:13:38.919 --> 00:13:42.119
So I imagine this latter view

00:13:42.119 --> 00:13:44.880
is the one that most biologists would take.

00:13:44.880 --> 00:13:46.639
Not that there's intelligence out there,

00:13:46.639 --> 00:13:49.240
let's just grab it and instantiate it here.

00:13:49.240 --> 00:13:52.880
No, something has the property of intelligence.

00:13:52.880 --> 00:13:55.600
So explain what you mean when you say embodying intelligence

00:13:55.600 --> 00:13:57.240
and also what you mean by intelligent.

00:13:57.240 --> 00:13:58.679
Yeah, let's see.

00:13:58.679 --> 00:14:01.160
And just a quick thing to finish real quick,

00:14:01.160 --> 00:14:02.000
the previous thought,

00:14:02.000 --> 00:14:05.359
which is that the reason I think this stuff is not,

00:14:05.359 --> 00:14:06.720
these are not questions of philosophy,

00:14:06.720 --> 00:14:08.720
these are very practical questions of science,

00:14:08.720 --> 00:14:11.440
because they lead to specific actionable technology.

00:14:11.440 --> 00:14:13.920
So the idea that what's going on in cancer

00:14:13.920 --> 00:14:15.959
is a shrinking of the cognitive icon

00:14:15.959 --> 00:14:18.399
leads directly to a research program where you say,

00:14:18.399 --> 00:14:20.279
well, instead of killing these cells

00:14:20.279 --> 00:14:21.760
with chemotoxic chemotherapies,

00:14:21.760 --> 00:14:23.799
because I believe that they're genetically

00:14:23.799 --> 00:14:26.200
irrevocably damaged,

00:14:26.200 --> 00:14:28.279
maybe what we can do is force them

00:14:28.279 --> 00:14:30.559
into better electrical networks with their neighbors.

00:14:30.600 --> 00:14:32.320
And that's exactly what we've done.

00:14:32.320 --> 00:14:36.839
And so we've had lots of success

00:14:36.839 --> 00:14:41.079
expressing strong human oncogenes in frog embryo cells,

00:14:41.079 --> 00:14:44.160
and then leaving the oncoproteins be,

00:14:44.160 --> 00:14:46.559
but instead making sure that they're connected

00:14:46.559 --> 00:14:48.920
into tight electrical networks with their neighbors,

00:14:48.920 --> 00:14:49.839
and they normalize.

00:14:49.839 --> 00:14:51.239
They make nice skin, nice muscle,

00:14:51.239 --> 00:14:54.720
they do their normal thing instead of being metastatic.

00:14:54.720 --> 00:14:57.079
And so that kind of thing,

00:14:57.079 --> 00:14:58.839
it's very important to me that all these ideas,

00:14:58.839 --> 00:14:59.920
and so we'll talk about in a minute

00:15:00.279 --> 00:15:01.600
about platonic space and things like that.

00:15:01.600 --> 00:15:03.440
It's important to me that all of these ideas

00:15:03.440 --> 00:15:06.519
don't just remain as kind of philosophical musings,

00:15:06.519 --> 00:15:08.720
but they have to make contact with the real world,

00:15:08.720 --> 00:15:11.880
and specifically, not just explaining stuff

00:15:11.880 --> 00:15:14.760
that was done before, but facilitating new advances.

00:15:14.760 --> 00:15:17.440
They have to enable new research programs

00:15:17.440 --> 00:15:18.600
that weren't possible before.

00:15:18.600 --> 00:15:21.000
That's what I think is the value of all of this kind of,

00:15:21.000 --> 00:15:23.239
these deep philosophical discussions.

00:15:23.239 --> 00:15:26.239
So let's see, with respect to definition of intelligence.

00:15:26.239 --> 00:15:29.160
So I like, for practical purposes,

00:15:29.160 --> 00:15:31.279
I like William James's definition,

00:15:31.279 --> 00:15:33.640
which is some degree of the ability

00:15:33.640 --> 00:15:36.320
to reach the same goal by different means.

00:15:36.320 --> 00:15:39.559
And that presupposes, it's an interesting definition

00:15:39.559 --> 00:15:43.720
because it presupposes that there is some problem space

00:15:43.720 --> 00:15:45.480
that the agent is working on,

00:15:45.480 --> 00:15:47.200
but it does not say you have to be a brain.

00:15:47.200 --> 00:15:49.160
It doesn't say you have to be natural versus artificial.

00:15:49.160 --> 00:15:50.000
It doesn't say any of that.

00:15:50.000 --> 00:15:51.640
It's a very cybernetic definition.

00:15:51.640 --> 00:15:54.200
What it says is that you have some amount of skill

00:15:54.200 --> 00:15:56.200
in navigating that problem space

00:15:56.200 --> 00:15:58.480
to get to where you want to go,

00:15:58.480 --> 00:16:00.559
despite interventions, despite surprise,

00:16:00.559 --> 00:16:02.359
despite various barriers in your way.

00:16:02.359 --> 00:16:05.320
How much competency do you have to achieve that?

00:16:05.320 --> 00:16:07.160
And that was his definition of intelligence.

00:16:07.160 --> 00:16:10.640
Now, I will certainly agree that that doesn't capture

00:16:10.640 --> 00:16:13.160
everything that we care about in cognition.

00:16:13.160 --> 00:16:16.399
So a focus on problem solving doesn't handle play

00:16:16.399 --> 00:16:20.579
and it doesn't handle emotions and things like that.

00:16:20.579 --> 00:16:22.799
But for the purposes of our work,

00:16:22.799 --> 00:16:26.679
I focus on the problem solving aspects of intelligence.

00:16:26.679 --> 00:16:31.679
So within that, your point about the platonic space.

00:16:33.679 --> 00:16:36.760
So now to be clear, everything that I was saying before,

00:16:36.760 --> 00:16:40.359
I think we have very strong empirical evidence for.

00:16:40.359 --> 00:16:42.480
And so now I'm going to, in answering this question,

00:16:42.480 --> 00:16:44.799
I'm just gonna talk about stuff that I'm not sure of yet

00:16:44.799 --> 00:16:47.040
and that these are ideas we don't,

00:16:47.040 --> 00:16:48.839
I don't feel strongly that we've shown

00:16:48.839 --> 00:16:50.920
that any of this is true, but this is my opinion

00:16:50.920 --> 00:16:54.359
and this is where our research is going now.

00:16:54.359 --> 00:16:59.359
I actually think that the platonic view is more correct.

00:17:00.679 --> 00:17:03.359
And I know this is not how most biologists

00:17:03.359 --> 00:17:04.440
think about things.

00:17:04.440 --> 00:17:08.899
I think that in the exact same way that mathematicians

00:17:08.899 --> 00:17:11.959
that are sympathetic to the platonic worldview,

00:17:11.959 --> 00:17:14.440
this idea that there are in fact, in some way,

00:17:14.440 --> 00:17:17.679
there is a separate world in which various rules

00:17:17.679 --> 00:17:20.200
of number theory and various facts of mathematics

00:17:20.200 --> 00:17:22.920
and various properties of computation

00:17:22.920 --> 00:17:23.760
and things like that, right?

00:17:24.079 --> 00:17:25.679
That there's a separate space where these things live.

00:17:25.679 --> 00:17:27.720
And importantly, the idea is that,

00:17:27.720 --> 00:17:29.160
they think that we discover those things,

00:17:29.160 --> 00:17:30.760
we don't invent them or create them,

00:17:30.760 --> 00:17:34.000
we discover them and that they would be true still

00:17:34.000 --> 00:17:35.959
if all the facts of the physical universe were different,

00:17:35.959 --> 00:17:39.440
they would still be true, right?

00:17:39.440 --> 00:17:42.200
I extend that idea in a couple of ways.

00:17:42.200 --> 00:17:46.880
One is I think that what exists in that platonic space

00:17:46.880 --> 00:17:51.320
is not just rules of mathematics and things like that,

00:17:51.320 --> 00:17:54.239
which are in a certain sense, low agency kind of objects

00:17:54.239 --> 00:17:56.239
because they just sort of sit there doing,

00:17:56.239 --> 00:17:57.239
they don't do much.

00:17:57.239 --> 00:18:00.320
I actually think that there's a spectrum of that.

00:18:00.320 --> 00:18:02.799
And some of the components of that platonic space

00:18:02.799 --> 00:18:04.079
have much higher agency.

00:18:04.079 --> 00:18:06.119
I think it's a space of minds as well

00:18:06.119 --> 00:18:07.959
and of different ways to be intelligent.

00:18:07.959 --> 00:18:11.839
And I think that just like when you make certain devices,

00:18:11.839 --> 00:18:16.039
you suddenly harness the rules of computation,

00:18:16.039 --> 00:18:18.719
rules of mathematics that are basically free lunches.

00:18:18.719 --> 00:18:20.440
There are so many things you can build

00:18:20.440 --> 00:18:23.119
that will suddenly have properties

00:18:23.119 --> 00:18:24.599
that you didn't have to bake in.

00:18:24.599 --> 00:18:27.280
You get that for free basically, right?

00:18:27.280 --> 00:18:28.760
I think intelligence is like that.

00:18:28.760 --> 00:18:31.280
I think some of the components of that platonic space

00:18:31.280 --> 00:18:32.719
are actually minds.

00:18:32.719 --> 00:18:36.599
And sometimes what happens when you build

00:18:36.599 --> 00:18:37.960
a particular kind of body,

00:18:37.960 --> 00:18:39.919
whether it's one that's familiar to us with a brain

00:18:39.919 --> 00:18:42.479
and so on, or really some very unfamiliar architectures,

00:18:42.479 --> 00:18:44.799
whether they be alien or synthetic or whatever,

00:18:44.799 --> 00:18:46.919
I think what you're doing is you're harnessing

00:18:46.919 --> 00:18:51.239
a preexisting intelligence that is there

00:18:51.239 --> 00:18:53.400
in the same way that you harness various laws

00:18:53.400 --> 00:18:54.919
of mathematics and computation

00:18:54.919 --> 00:18:56.559
when you build specific devices.

00:18:57.559 --> 00:18:59.239
Okay, well, that's super interesting.

00:18:59.239 --> 00:19:02.080
So at any moment, there's Mike 11,

00:19:02.080 --> 00:19:03.719
but there's Mike 11 at 11 a.m.,

00:19:03.719 --> 00:19:05.880
then there's Mike 11 at 11.01 a.m.,

00:19:05.880 --> 00:19:08.960
and it's not clear they're the same.

00:19:08.960 --> 00:19:10.359
So there's the two, the river,

00:19:10.359 --> 00:19:12.000
do you step in it and this is the same river?

00:19:12.000 --> 00:19:13.239
Okay, cool.

00:19:13.239 --> 00:19:14.599
There's a through line.

00:19:14.599 --> 00:19:16.039
There's something there though.

00:19:16.039 --> 00:19:18.320
Maybe it's something like you're akin

00:19:18.320 --> 00:19:21.479
to what you were an epsilon amount of time previous.

00:19:21.650 --> 00:19:26.130
And then that's the through line. So as long as that's true, then you can draw a worm of

00:19:26.130 --> 00:19:31.650
you throughout time. Are you saying that at any slice of that, there was a Michael Levin

00:19:31.650 --> 00:19:37.110
in some Michael Levin space, which is also in the minds of human space and you're picking

00:19:37.110 --> 00:19:41.570
out points somehow, you're traversing the space of minds?

00:19:41.570 --> 00:19:45.670
That's actually even more specific than what I was saying. I mean, that's interesting.

00:19:45.670 --> 00:19:54.069
And I think that's what I was saying, that in general, kinds of minds. So there are different,

00:19:54.069 --> 00:20:00.870
I don't know quite what to think about individual instances, but kinds of minds, you know.

00:20:00.870 --> 00:20:03.350
Because that would be an extremely large space then.

00:20:03.350 --> 00:20:07.909
Well, I think, yes, I think the space is extremely large, possibly infinite, but in fact, probably

00:20:07.909 --> 00:20:14.810
infinite. But I think what I was talking about was mainly types of different minds, types

00:20:14.810 --> 00:20:19.690
of cognitive systems. Now, for individuals, you raise a really interesting point, which

00:20:19.690 --> 00:20:23.970
is, I call them selflets, which are the kind of the thin slices of experience that-

00:20:23.970 --> 00:20:26.410
You call them selflets?

00:20:26.410 --> 00:20:31.450
Selflets. Because you have a self and then the different slices of it are the selflets.

00:20:31.450 --> 00:20:36.010
And you can look at it as, you know, kind of like that special relativity, you know,

00:20:36.010 --> 00:20:41.090
bread loaf, you know, sliced into pieces, that kind of thing. So I think what's interesting

00:20:41.090 --> 00:20:46.289
about asking that question about the self and what is the through line, is what's really

00:20:46.289 --> 00:20:51.130
important there is to pick a vantage point of an observer. Again, kind of akin to what

00:20:51.130 --> 00:20:55.130
happens in relativity. You have to ask, from whose perspective? So one of the things about

00:20:55.130 --> 00:21:00.489
being a continuous self is that other observers can count on your behaviors and your properties

00:21:00.489 --> 00:21:04.249
staying more or less constant. So the reason that we identify, oh yes, you know, you're

00:21:04.249 --> 00:21:09.130
the same person as you were before, is basically, nobody cares that you have the same atoms

00:21:09.130 --> 00:21:14.730
or you don't, or the cells have been replaced. What you really care about is that this being,

00:21:14.730 --> 00:21:18.569
I can have the same kind of relationship with them that I had before. In other words, they're

00:21:18.569 --> 00:21:21.770
consistent. I can expect the same behaviors, the things that I think they know, they still

00:21:21.770 --> 00:21:29.650
know and so on. And so that, of course, in our human lives, that often breaks down because

00:21:29.650 --> 00:21:35.849
humans grow from being children to being adults. All their preferences change. The things that

00:21:35.849 --> 00:21:40.090
they remember and the things that they value change. In our own lives, we sometimes change.

00:21:40.090 --> 00:21:45.250
And that's a much more important change. Are you the same person, even though if all your

00:21:45.250 --> 00:21:50.250
material components remained the same, but you changed all your beliefs, all your preferences,

00:21:50.250 --> 00:21:55.929
would you still be the same person? So I think what we mean when we say the same is not about

00:21:55.929 --> 00:22:02.450
the matter at all. It's about what kind of relationship we can still have and what do

00:22:02.450 --> 00:22:07.730
I expect from you behavior-wise and so on. And there's some really interesting, and so that's

00:22:07.730 --> 00:22:14.370
from the perspective of an external observer. Now, the latest work that I just published a

00:22:14.370 --> 00:22:19.329
couple of days ago looks at what does that mean from the perspective of the agent themselves?

00:22:19.329 --> 00:22:25.170
And this idea that you don't have access to your past. What you have access to are memory

00:22:25.170 --> 00:22:31.569
engrams, traces of past experience that were deposited in your brain and possibly in your body

00:22:31.569 --> 00:22:38.370
that future you is going to have to interpret. And so that leads to a kind of

00:22:38.370 --> 00:22:46.769
scenario where you treat your own memories as messages from your past self. The idea

00:22:46.769 --> 00:22:50.530
then that is that those memories have to be interpreted. You don't necessarily know what

00:22:50.530 --> 00:22:54.209
they mean right away because you're different. You're not the same as you were, especially over

00:22:54.209 --> 00:22:59.010
long periods of time. And this comes out very starkly in organisms that change radically,

00:22:59.010 --> 00:23:05.409
like caterpillars to butterfly. So memories persist from caterpillar to butterfly, but

00:23:05.409 --> 00:23:10.849
the actual detailed memories of the caterpillar are of absolutely no use to the butterfly. It

00:23:10.849 --> 00:23:14.450
doesn't eat the same stuff. It doesn't move in the same way. It has a completely different body,

00:23:14.450 --> 00:23:18.849
completely different brain. You can't just take the same memories. And so I think what happens

00:23:18.849 --> 00:23:25.250
in biology is that it is very comfortable. In fact, it depends on the idea that the substrate

00:23:25.250 --> 00:23:29.489
will change. You will mutate your cells. Some cells will die. New cells will be born. Material

00:23:29.489 --> 00:23:35.810
goes in and out. Unlike in our computational devices, you're not committed to the fidelity

00:23:35.810 --> 00:23:40.929
of information the way that we are in our computation. You are committed to the salience

00:23:40.929 --> 00:23:46.049
of that information. So you will need to take those memory traces and reinterpret them for

00:23:46.049 --> 00:23:49.729
whatever your future situation is. In the case of the butterfly, completely different. In the case

00:23:49.729 --> 00:23:54.449
of the adult human, somewhat different than your brain when you were a child. But even during

00:23:54.449 --> 00:24:01.970
adulthood, your context, your mental context, your environment, everything changes. And I think

00:24:03.009 --> 00:24:07.489
you don't really have an allegiance to what these memories meant in the past. You reinterpret them

00:24:07.489 --> 00:24:12.209
dynamically. And so this gives a kind of view of the self, kind of a process view of the self that

00:24:12.850 --> 00:24:18.370
what we really are is a continued, continuous dynamic attempt at storytelling, where what

00:24:18.370 --> 00:24:22.449
you're constantly doing is interpreting your own memories in a way that makes sense.

00:24:23.009 --> 00:24:29.329
A coherent story about what you are, what you believe about the outside world. And it's a

00:24:29.329 --> 00:24:33.650
constant process of self-construction. So that, I think, is what's going on with selves.

00:24:35.009 --> 00:24:39.329
If it's the case then that we interpret our memories as messages from our past selves to

00:24:39.329 --> 00:24:46.290
our current selves, then can we reverse that and say that our current actions are messages to our

00:24:46.290 --> 00:24:51.329
future self? Yeah, I think that's exactly right. I think that a lot of what we're doing now

00:24:51.889 --> 00:24:58.449
is, at any given moment, is behavior that is going to enable or constrain your future self.

00:25:00.609 --> 00:25:04.130
You're setting the conditions in which the environment in which your future self is going

00:25:04.130 --> 00:25:09.169
to be living, including changing yourself. Anything you undertake as a self-improvement

00:25:09.169 --> 00:25:16.690
program or, conversely, when people entertain intrusive or depressive thoughts, that changes

00:25:16.690 --> 00:25:21.009
your brain. That literally changes the way that your future self is going to be able to

00:25:21.009 --> 00:25:26.449
process information in the future. Everything you do radiates out, not only as messages and

00:25:27.250 --> 00:25:30.850
a kind of niche construction, where you're changing the environment in which you're going

00:25:30.850 --> 00:25:35.410
to live and which everybody else is going to live. We are constantly doing that to ourselves and to

00:25:35.410 --> 00:25:45.250
others. And so that really forces a kind of thinking about your future self as kind of akin

00:25:45.250 --> 00:25:50.130
to other people's future selves. I think that also has important ethical implications because

00:25:50.850 --> 00:25:58.609
once that symmetry becomes apparent that your future self is not quite you, and also others'

00:25:58.609 --> 00:26:04.290
future selves are also not you, that suggests that the same reason you do things so that your

00:26:04.290 --> 00:26:09.250
future self will have a better life, you might want to apply that to others' future selves.

00:26:10.130 --> 00:26:14.449
Breaking down this idea that—and I'm certainly not the first person to say this—but breaking down

00:26:14.449 --> 00:26:19.489
the idea that you are a persistent object, separate from everybody else, and sort of

00:26:19.489 --> 00:26:24.769
persisting through time, breaking that down into a set of selves, and what you are doing now is

00:26:24.769 --> 00:26:30.929
basically for the good of a future self, I think makes you think differently about others' future

00:26:30.929 --> 00:26:36.130
selves at the same time. Is it as simple as the larger the cognitive light cone, the better for

00:26:36.130 --> 00:26:43.729
the organism? Well, what does better mean? I mean, I think that certainly there are extremely successful

00:26:43.729 --> 00:26:47.729
organisms that do not have a large cognitive light cone. Having said all that, you know, the

00:26:47.729 --> 00:26:53.489
size of an organism's cognitive light cone is not obvious. We are not good at detecting them. It's an

00:26:53.489 --> 00:26:58.049
important research program to find out what any given agent cares about because it's not easily

00:26:58.850 --> 00:27:04.370
inferrable from measurements directly. You have to do a lot of experiments. So assuming we even

00:27:04.370 --> 00:27:10.929
know what anything's cognitive light cone is, I think lots of organisms do perfectly well, but

00:27:10.929 --> 00:27:16.449
then what's the definition of success? So in terms of the way we think about, well, the way

00:27:16.449 --> 00:27:21.650
many people think about evolution in terms of, you know, how many copy numbers, like how many of you

00:27:21.650 --> 00:27:28.209
are there, that's your success. So just persistence and expansion into the world. From that perspective,

00:27:28.209 --> 00:27:31.489
I don't think you need a particularly large cognitive light cone. You know, bacteria do great.

00:27:32.609 --> 00:27:37.810
But from other perspectives, if we sort of ask ourselves what the point is and why do we exert

00:27:37.810 --> 00:27:42.690
all this effort to exist in the physical world and try to persist and exert effort in all the

00:27:42.690 --> 00:27:47.729
things we do in our lives, one could make an argument that a larger cognitive light cone is

00:27:47.729 --> 00:27:53.410
probably better in the sense that it allows you to generate more meaning and allows you to bring

00:27:53.410 --> 00:27:57.090
meaning to all the effort and the, you know, the suffering and the joy and the hard work and

00:27:57.090 --> 00:28:02.689
everything else. From that perspective, one would want to enlarge one's cognitive light cone. And,

00:28:02.689 --> 00:28:08.610
you know, we collaborate, well, I collaborate with a number of people in this group called

00:28:08.610 --> 00:28:15.809
CSAS, the Center for the Study of Apparent Selves. And we talk about this notion of something,

00:28:15.809 --> 00:28:19.970
for example, in Buddhism, they have this notion of a bodhisattva vow. And it's basically a commitment

00:28:19.970 --> 00:28:26.290
to enlarge one's cognitive light cone so that over time, one becomes able to have a wider area

00:28:26.290 --> 00:28:33.090
of concern or compassion, right? The idea is you want to work on changing yourself in a way that

00:28:33.090 --> 00:28:39.730
enlarges your ability to really care about a wider set of beings. And so from that perspective,

00:28:39.730 --> 00:28:44.769
maybe you want a larger cognitive light cone. Okay, so there are three notions here. So

00:28:44.769 --> 00:28:50.689
enlarging what you care about, okay, then also enlarging what you find relevant. And then there's

00:28:50.689 --> 00:28:55.730
also increasing the amount of opportunities that you'll have in the future. So that's the adage,

00:28:55.730 --> 00:29:00.689
that's the business adage, go through the door that will open as many doors as possible. And then

00:29:01.650 --> 00:29:04.290
the relevance one, I don't think is the case because

00:29:04.450 --> 00:29:07.290
if you find more, if you find too much relevant,

00:29:07.290 --> 00:29:10.690
you will also freeze because you don't know what to do.

00:29:10.690 --> 00:29:12.250
Now then there's the concern for others.

00:29:12.250 --> 00:29:14.770
So help me disembroil these three from one another.

00:29:14.770 --> 00:29:19.770
Yeah, the relevance is, I think, really important.

00:29:20.370 --> 00:29:22.930
You know, one thing I often think about is,

00:29:22.930 --> 00:29:27.930
like, what's the fundamental unit that exists in the world?

00:29:28.329 --> 00:29:29.890
Is it, you know, is it genes?

00:29:29.890 --> 00:29:30.730
Is it information?

00:29:30.730 --> 00:29:32.890
Like, what is it that's really spreading

00:29:32.890 --> 00:29:35.290
through the universe and differentially reproducing

00:29:35.290 --> 00:29:36.290
and all that?

00:29:36.290 --> 00:29:37.970
I tend to think it's perspectives.

00:29:37.970 --> 00:29:39.770
I think that what's really out there

00:29:41.209 --> 00:29:46.209
as a diverse, as a way to describe really diverse agents,

00:29:48.249 --> 00:29:50.610
I think one thing they all have is a commitment

00:29:50.610 --> 00:29:52.010
to a particular perspective.

00:29:52.010 --> 00:29:53.490
So perspective, in my definition,

00:29:53.490 --> 00:29:56.569
is a bundle of commitments to what am I gonna measure

00:29:56.569 --> 00:29:57.810
about the outside world?

00:29:57.810 --> 00:29:59.569
What am I gonna pay attention to?

00:29:59.569 --> 00:30:01.450
And how am I going to weave that information

00:30:01.450 --> 00:30:03.249
into some sort of model about what's going on?

00:30:03.249 --> 00:30:05.170
And more importantly, what I should do next?

00:30:05.170 --> 00:30:07.450
So there are many, many different perspectives.

00:30:07.450 --> 00:30:10.210
And as you said, it's critical that every perspective

00:30:10.210 --> 00:30:14.130
has to shut out way more stuff than it lets in, right?

00:30:14.130 --> 00:30:17.210
Because if you, and this, interestingly,

00:30:17.210 --> 00:30:19.089
this gets back to your original point

00:30:19.089 --> 00:30:20.450
about the different levels of description,

00:30:20.450 --> 00:30:22.170
you know, physics and chemistry and all that.

00:30:22.170 --> 00:30:26.409
Because if you try to, if you wanted to be

00:30:26.409 --> 00:30:28.969
a Laplacian demon, if you wanted to track microstates,

00:30:28.969 --> 00:30:30.009
all the particles, right?

00:30:30.009 --> 00:30:32.689
I'm just gonna track reality as it really is.

00:30:32.689 --> 00:30:33.890
I'm just gonna watch all the particles.

00:30:33.890 --> 00:30:35.729
That's all I'm gonna do.

00:30:35.729 --> 00:30:38.130
No living system can survive this way, right?

00:30:38.130 --> 00:30:42.049
Because you would be eaten before anything else happens.

00:30:42.049 --> 00:30:42.930
You would be dead.

00:30:42.930 --> 00:30:47.850
So I think that any agent that evolves

00:30:47.850 --> 00:30:51.210
under resource constraint, so which is all of life,

00:30:51.210 --> 00:30:52.649
and it remains an interesting question,

00:30:52.649 --> 00:30:54.770
what does that mean for AIs and so on?

00:30:54.770 --> 00:30:57.329
But any agent that evolves under constraints

00:30:57.329 --> 00:31:02.329
of metabolic and time resources

00:31:03.689 --> 00:31:05.329
is going to have to coarse grain.

00:31:05.329 --> 00:31:07.530
They're going to have to not be a reductionist.

00:31:07.530 --> 00:31:09.530
They're going to have to tell stories about agents

00:31:09.530 --> 00:31:11.369
that do things as a means of compression,

00:31:11.369 --> 00:31:12.849
as a way of compressing the outside world

00:31:12.849 --> 00:31:14.089
and picking a perspective.

00:31:14.089 --> 00:31:16.489
You cannot afford to try to track everything.

00:31:16.489 --> 00:31:17.450
It's impossible.

00:31:17.450 --> 00:31:21.530
So that compression also comes back

00:31:21.530 --> 00:31:25.369
to the memory engrams issue that we were talking about,

00:31:25.369 --> 00:31:28.289
because as your past self compresses

00:31:28.289 --> 00:31:33.009
lots of diverse experiences into a compact representation

00:31:33.009 --> 00:31:34.770
of a memory trace of what happened,

00:31:34.770 --> 00:31:37.129
that kind of learning is fundamentally compression,

00:31:37.129 --> 00:31:39.209
when you're compressing lots of data

00:31:39.209 --> 00:31:42.250
into a short, pithy generative rule

00:31:42.250 --> 00:31:45.890
or a memory that you're going to remember

00:31:45.890 --> 00:31:47.089
that you can use later, right?

00:31:47.089 --> 00:31:50.690
So not the exact experiences that you had,

00:31:50.690 --> 00:31:52.890
but some compressed representation.

00:31:52.890 --> 00:31:54.810
Well, the thing about compression

00:31:54.810 --> 00:31:59.450
is that the most efficient,

00:32:00.530 --> 00:32:02.929
the data that's compressed really efficiently

00:32:02.929 --> 00:32:04.530
starts to look random, right?

00:32:04.530 --> 00:32:07.289
So because you've gotten rid of all the correlations

00:32:07.289 --> 00:32:08.770
and everything else,

00:32:08.770 --> 00:32:11.410
the more you compress it, the more random it looks.

00:32:11.410 --> 00:32:14.050
And you've really gotten rid of a lot of metadata

00:32:14.050 --> 00:32:16.289
that you have to, that's the point of compression.

00:32:16.289 --> 00:32:17.810
You've lost a lot of information.

00:32:17.810 --> 00:32:20.089
Wait, why do you say that the more compressed it is,

00:32:20.089 --> 00:32:20.929
the more random it is?

00:32:20.929 --> 00:32:22.770
Why isn't it the opposite?

00:32:23.649 --> 00:32:25.649
The more random it is, the more incompressible it is.

00:32:25.649 --> 00:32:27.530
That's true, because you've already compressed

00:32:27.530 --> 00:32:28.369
the hell out of it.

00:32:28.369 --> 00:32:29.330
That's why, right?

00:32:29.330 --> 00:32:30.569
That's why it's incompressible,

00:32:30.569 --> 00:32:32.649
because you've already compressed it as much as it can.

00:32:32.649 --> 00:32:35.089
This is the issue that, for example, the SETI people,

00:32:35.089 --> 00:32:37.289
right, the Search for Extraterrestrial Intelligence,

00:32:37.289 --> 00:32:38.890
that they come up against,

00:32:38.890 --> 00:32:41.649
because the messages that are going to be sent

00:32:41.649 --> 00:32:43.209
by truly advanced civilizations

00:32:43.209 --> 00:32:44.649
are gonna look like noise to us.

00:32:44.649 --> 00:32:48.410
Because really effective compression schemes,

00:32:49.410 --> 00:32:52.729
unless you know what the decomp,

00:32:52.729 --> 00:32:54.929
so you've compressed it,

00:32:54.929 --> 00:32:57.369
unless you know what the algorithm is to re-inflate it,

00:32:57.369 --> 00:32:59.450
the message itself looks like noise.

00:32:59.450 --> 00:33:00.810
It doesn't look like anything.

00:33:00.810 --> 00:33:03.929
Because you've pulled out all of the correlations,

00:33:03.929 --> 00:33:07.330
all of the order that would have made sense

00:33:07.330 --> 00:33:09.410
to a more naive observer is now gone.

00:33:09.410 --> 00:33:11.289
And if you don't have the key to interpret it with,

00:33:11.289 --> 00:33:12.729
it just looks like noise.

00:33:12.729 --> 00:33:15.770
And so that means that if you sort of think about this,

00:33:15.770 --> 00:33:18.489
there's an architecture like a bow tie,

00:33:18.489 --> 00:33:21.050
like a bow tie kind of architecture that's important here,

00:33:21.050 --> 00:33:22.930
where you take all these experiences,

00:33:22.930 --> 00:33:26.129
you compress them down into an engram, that's your memory,

00:33:26.129 --> 00:33:28.330
and then future you has to re-inflate it again

00:33:28.330 --> 00:33:30.450
and figure out, okay, so what does this mean for me now?

00:33:30.450 --> 00:33:32.770
Right, it's a simple rule that I inferred.

00:33:32.770 --> 00:33:34.809
Let's say you learned an associative learning task

00:33:34.809 --> 00:33:38.650
or some kind of, you've learned something general,

00:33:38.650 --> 00:33:42.450
you've learned to count a number or something like this.

00:33:42.450 --> 00:33:45.490
So rats, I think it takes about, if I recall correctly,

00:33:46.170 --> 00:33:48.930
like 3,000 trials before they understand the number three.

00:33:48.930 --> 00:33:50.930
That's distinct from any instance.

00:33:50.930 --> 00:33:54.129
So it's not like three peanuts or three sticks.

00:33:54.129 --> 00:33:55.930
It's like the number three of anything, right?

00:33:55.930 --> 00:33:58.930
So after some thousands of trials, they get it.

00:33:58.930 --> 00:34:00.969
And so now they have this compressed rule.

00:34:00.969 --> 00:34:03.890
They don't remember the sticks or the peanuts or whatever,

00:34:03.890 --> 00:34:07.529
but they remember the actual rule, right?

00:34:07.529 --> 00:34:10.610
And so that's the engram at the center of your bow tie.

00:34:10.610 --> 00:34:12.849
Well, future you has to re-inflate it,

00:34:12.849 --> 00:34:14.809
has to uncompress it and expand it.

00:34:15.170 --> 00:34:17.129
But now I'm looking at three flowers.

00:34:17.129 --> 00:34:18.009
Is that the same or not?

00:34:18.009 --> 00:34:20.689
How do I apply my rule to this?

00:34:20.689 --> 00:34:23.729
And I think that what's important

00:34:23.729 --> 00:34:26.090
is that you can't do that deductively

00:34:26.090 --> 00:34:28.610
because you're missing a lot of that basic information.

00:34:28.610 --> 00:34:30.729
You have to be creative.

00:34:30.729 --> 00:34:33.409
When you interpret your own engrams,

00:34:33.409 --> 00:34:37.969
there's a lot of creative input that has to come in

00:34:37.969 --> 00:34:39.289
to understand what it was

00:34:39.289 --> 00:34:40.409
that you were thinking at the time.

00:34:40.409 --> 00:34:43.770
And I think that kind of a thing,

00:34:43.969 --> 00:34:45.770
I mean, we know that recall of memories

00:34:45.770 --> 00:34:47.170
actually changes the memory, right?

00:34:47.170 --> 00:34:48.770
So in neuroscience, they know this,

00:34:48.770 --> 00:34:51.969
that there's no pure non-destructive reads of memories,

00:34:51.969 --> 00:34:53.650
that when you access your memory, you change it.

00:34:53.650 --> 00:34:54.529
And I think that's why,

00:34:54.529 --> 00:34:56.409
because the act of interpretation

00:34:56.409 --> 00:35:00.809
is not just a passive reading of what's there.

00:35:00.809 --> 00:35:04.090
It's actually a construction process of trying to recreate.

00:35:04.090 --> 00:35:05.090
So what does that mean for me?

00:35:05.090 --> 00:35:07.170
What does it mean now?

00:35:07.170 --> 00:35:12.170
And that's part of that process of the dynamic self,

00:35:12.370 --> 00:35:13.370
is trying to figure out.

00:35:13.490 --> 00:35:14.689
Obviously, all of this is subconscious,

00:35:14.689 --> 00:35:17.809
but trying to figure out what your own memories mean.

00:35:17.809 --> 00:35:18.809
Yes, okay.

00:35:18.809 --> 00:35:20.849
So you said, obviously, much of this is,

00:35:20.849 --> 00:35:22.490
or maybe you said, obviously, all of it,

00:35:22.490 --> 00:35:25.170
or much of it, I'm not sure, is subconscious.

00:35:25.170 --> 00:35:30.090
So when we say you currently are constructing an engram

00:35:30.090 --> 00:35:32.569
for the future you to then unpackage,

00:35:33.650 --> 00:35:34.849
I am not doing this,

00:35:34.849 --> 00:35:37.529
at least not at an effortful, conscious level.

00:35:37.529 --> 00:35:40.129
There's an instinctual, unconscious component to it.

00:35:40.129 --> 00:35:41.689
And then both to the encoding

00:35:41.729 --> 00:35:45.370
and then to the retrieval and the expansion of the engram.

00:35:45.370 --> 00:35:46.890
Yeah.

00:35:46.890 --> 00:35:51.370
So who, the person who's listening to this,

00:35:52.249 --> 00:35:53.650
they listen to these podcasts,

00:35:53.650 --> 00:35:55.409
they listen to theories of everything,

00:35:55.409 --> 00:35:56.770
in large part because they're trying

00:35:56.770 --> 00:35:58.050
to understand themselves,

00:35:58.050 --> 00:35:59.090
they're interested in science,

00:35:59.090 --> 00:36:01.210
they're interested in philosophy.

00:36:01.210 --> 00:36:02.689
You're also speaking to them now

00:36:02.689 --> 00:36:05.090
with this answer to this question.

00:36:05.090 --> 00:36:07.129
Who are they?

00:36:07.129 --> 00:36:08.490
They're listening to this and they're saying,

00:36:08.490 --> 00:36:10.569
I'm doing this, I'm not aware.

00:36:10.569 --> 00:36:12.650
This is all news to me, Mike.

00:36:12.650 --> 00:36:14.009
You're saying I've been doing this my whole life

00:36:14.009 --> 00:36:15.170
and this defines me?

00:36:15.170 --> 00:36:16.770
This doesn't sound anything like me.

00:36:16.770 --> 00:36:18.289
So who are you?

00:36:18.289 --> 00:36:21.210
Who are you, Mike, and who is the person who's listening?

00:36:21.210 --> 00:36:22.249
What defines them?

00:36:22.249 --> 00:36:23.849
Well, so a few things.

00:36:23.849 --> 00:36:27.210
So the fact that there are an incredible number

00:36:27.210 --> 00:36:28.849
of processes under the hood,

00:36:28.849 --> 00:36:30.849
it has been known for a really long time.

00:36:30.849 --> 00:36:34.210
So not only all the physiological stuff that's going on,

00:36:34.210 --> 00:36:36.249
I mean, you also don't have the experience

00:36:36.249 --> 00:36:37.729
of running your liver and your kidneys,

00:36:37.729 --> 00:36:40.450
which are very necessary for your brain function.

00:36:41.330 --> 00:36:44.809
You are also not aware of all the subconscious motivations

00:36:44.809 --> 00:36:47.490
and patterns and traits and everything else.

00:36:47.490 --> 00:36:49.450
So let's assume right now

00:36:49.450 --> 00:36:52.490
that whatever our conscious experience is,

00:36:52.490 --> 00:36:54.289
there is tons of stuff under the hood.

00:36:54.289 --> 00:36:56.009
Not just the thing that I just said,

00:36:56.009 --> 00:36:58.129
but everything else that neuroscience has been studying

00:36:58.129 --> 00:37:00.409
for a hundred years or more.

00:37:01.330 --> 00:37:03.170
There's lots going on under the hood.

00:37:03.170 --> 00:37:06.129
And that doesn't define you.

00:37:06.129 --> 00:37:08.770
It enables you to do certain things.

00:37:08.809 --> 00:37:10.689
It constrains you from doing certain other things

00:37:10.689 --> 00:37:12.409
that you might want to do.

00:37:12.409 --> 00:37:14.650
The hardware does not define you.

00:37:14.650 --> 00:37:15.969
I think the most important thing,

00:37:15.969 --> 00:37:17.809
and look, I think this is a really important question

00:37:17.809 --> 00:37:21.529
because I get lots of emails from people who say,

00:37:21.529 --> 00:37:22.729
I've read your papers.

00:37:22.729 --> 00:37:24.249
I understand that I'm now,

00:37:24.249 --> 00:37:25.969
now I understand I'm a collective intelligence

00:37:25.969 --> 00:37:26.969
of groups of cells.

00:37:26.969 --> 00:37:27.930
What do I do now?

00:37:27.930 --> 00:37:30.330
I don't know what to do anymore, right?

00:37:30.330 --> 00:37:34.050
And my answer is, do whatever amazing thing

00:37:34.050 --> 00:37:36.129
you were going to do before you read that paper.

00:37:36.770 --> 00:37:39.489
All of this information about what's under the hood

00:37:39.489 --> 00:37:44.489
is interesting and it has all kinds of implications,

00:37:45.369 --> 00:37:47.169
but the one thing it does not do

00:37:47.169 --> 00:37:49.330
is diminish your responsibility

00:37:49.330 --> 00:37:53.249
for living the best, most meaningful life you can.

00:37:53.249 --> 00:37:55.530
It doesn't affect any of that.

00:37:55.530 --> 00:37:58.689
And one way I think about this,

00:37:58.689 --> 00:38:00.369
and there's lots of sci-fi about this,

00:38:00.369 --> 00:38:02.650
but one thing that you might remember is,

00:38:02.650 --> 00:38:04.609
you've seen the film Ex Machina?

00:38:04.609 --> 00:38:05.450
Yes.

00:38:05.450 --> 00:38:08.450
And so there's one scene there where the protagonist,

00:38:08.450 --> 00:38:09.530
he's standing in front of a mirror

00:38:09.530 --> 00:38:10.609
and he's completely freaked out

00:38:10.609 --> 00:38:13.249
because the AI is so lifelike,

00:38:13.249 --> 00:38:18.090
he's now wondering maybe he's a robotic organism too.

00:38:18.090 --> 00:38:21.290
And so he's cutting his hand and he's looking in his eye

00:38:21.290 --> 00:38:22.850
and he's trying to figure out what he is.

00:38:22.850 --> 00:38:25.770
And so let's just dissect that for a minute.

00:38:27.210 --> 00:38:28.290
The reason he's doing this,

00:38:28.290 --> 00:38:30.090
and what happens to most people,

00:38:30.090 --> 00:38:31.450
which I think is quite interesting,

00:38:31.450 --> 00:38:34.850
is that if they were to open their arm

00:38:34.850 --> 00:38:37.330
and they find a bunch of cogs and gears inside,

00:38:37.330 --> 00:38:39.730
I think most people would be super depressed

00:38:39.730 --> 00:38:43.410
because I think where most people go with this is,

00:38:43.410 --> 00:38:45.350
I've just learned something about myself.

00:38:45.350 --> 00:38:55.950
Meaning, I know what cogs and gears can do, they're a machine, and I just learned that I'm full of cogs and gears, therefore I'm not what I thought I was.

00:38:55.950 --> 00:39:12.950
And I think this is a really unfortunate way to think because what you're saying is, your experience of your whole life and all of the joys and the suffering and the personal responsibility and everything else that you've experienced,

00:39:13.350 --> 00:39:17.750
you're now willing to give all that up because you think you know something about what cogs and gears can do.

00:39:17.750 --> 00:39:23.989
I would go in the exact opposite direction and I would say, amazing, I've just discovered that cogs and gears can do this incredible thing.

00:39:23.989 --> 00:39:36.949
Like, wow. And why not? Because why do you think that proteins and the ions and proteins and the various things in your body, those are great for true cognition?

00:39:36.949 --> 00:39:48.149
Like, I always knew I was full of protein and lipids and ions and all of those things, and that was cool, I was okay with being that kind of machine, but cogs and gears? No way.

00:39:48.149 --> 00:40:04.549
And so I think one thing that we get from our education focused on certain kinds of materialism is that we get this unwarranted confidence in what we think different materials are capable of.

00:40:04.549 --> 00:40:24.549
And we believe it to such an extent, I mean, I find this amazing as a kind of an educational or sociological thing that we imbibe that story so strongly that we're willing to then give up everything that we know about ourselves in order to stick to a story about materials.

00:40:24.549 --> 00:40:45.350
I think that's one thing that I think Descartes had really, really right, is that the one thing you actually know is that you are an agentic being with responsibility and a mind and all this potential, and whatever you learn is on the background of that.

00:40:45.350 --> 00:41:12.549
So if you find out that you are made of cogs and gears, all you should conclude is, well, great. Now I know this stuff can do it as well as proteins can. And so what I really hope that people get from this is simply the idea that pretty much no discovery about the hardware, no discovery about the biology or the physics of it should pull you away from the fundamental reality of your being.

00:41:12.549 --> 00:41:36.549
That whatever it is that you are, you know, groups of cells, an emergent mind pulled down from platonic space or whatever, whichever of these things are correct, the bottom line is you are still the amazing integrated being with potential and a responsibility to do things.

00:41:36.549 --> 00:42:00.549
Aha. So many people who dislike materialism and like the more whatever they consider to be not materialism, so it could be idealism, it could be spiritualism or whatever they want to call it, or non-dualism, or trialism instead of a dualism, in part what they're saying is, look, I'm not material because they denigrate the material and they view it as robotic, lifeless.

00:42:00.549 --> 00:42:16.549
But you're saying there's another route, if you are material, whatever it is you turn out to be, you can elevate that. So you can say, look, there's a dynamism to it, there's an exuberance, there's a larger-than-lifeness to what I previously thought was ossifying.

00:42:16.549 --> 00:42:35.549
Yeah, for sure. And Ian McGilchrist makes a point of this too, he says that we've underestimated matter. You know, when we talk about materialism, we have been sold and are selling still this notion of matter as lacking intelligence.

00:42:35.549 --> 00:42:54.549
And I think that we need to give up this unwarranted confidence in what we think matter can do. We are finding novel proto-cognitive capacities in extremely minimal systems, extremely minimal systems. And they're surprising to us, they're shocking when we find these things.

00:42:54.549 --> 00:43:11.550
And I think we are really bad at recognizing what kinds of systems can give rise to minds, and therefore being depressed because we think that we are a particular kind of system and there's no way that system can be this majestic, agentic being, it's way too early for that.

00:43:11.550 --> 00:43:30.550
We just, we absolutely, I mean, this is one of the, I think, the major things is that we have this idea that we know what different kinds of matter can do. And obviously, I'm not just talking about, you know, homogenous blocks of material, I'm talking about specific configurations.

00:43:31.550 --> 00:43:44.550
But really minimal kinds of things can have some very surprising cognitive qualities. And so, yeah, it's way too early to think that we know what's going on here.

00:43:44.550 --> 00:44:00.550
I think we have a record here of 45 minutes of recording or so, and we haven't mentioned the word bioelectricity once. So, kudos to you, kudos to me, how the heck did that happen, for a Mike Levin interview. So what does bioelectricity have to do with any of this?

00:44:00.550 --> 00:44:20.550
Yeah, so bioelectricity is not magic, it is not unique in the sense that there are probably, this is certainly out in the universe, there are probably other ways of doing what it does. But what it does here on Earth in living forms is something very interesting. It functions as a kind of cognitive glue.

00:44:20.550 --> 00:44:42.550
So, when you have collective intelligence, you need to have policies and you need to have mechanisms for enabling competent individuals to merge together into a larger emergent individual that's going to do several things.

00:44:42.550 --> 00:45:06.550
First of all, the larger network, the larger level is going to distort the option space for the lower levels. So the parts are doing things that the parts do, but they're now doing it in a way that is coherent with a much higher level story of what's going on, higher level goals, because their action landscape is bent, it's distorted by the larger level. Their perception, their energy landscape is distorted.

00:45:06.550 --> 00:45:29.550
So that collective is going to, that new self, is going to have memories, goals, preferences, a cognitive lico. That requires some very specific features, and there are a bunch of them. And one of the modalities that lets that happen, that lets the cognitive lico scale, that lets the intelligence scale, is bioelectricity.

00:45:29.550 --> 00:45:58.550
So by taking cells and enabling them to be part of an electrical network, there are some really interesting larger level dynamics, which, you know, this is what we exploit in artificial neural networks, of course, right? This is biology. You notice this since the time of bacterial biofilms, that electricity is just a really good way for higher level cells to emerge and higher level computation to emerge. There are probably other ways of doing it, but here on Earth, bioelectricity tends to be the way to go.

00:45:59.550 --> 00:46:20.550
Something I always wonder in conversations about are higher selves, lower selves, higher goals. How do we even say higher or lower, when what we're talking about is such a vast landscape of goals or cognitive lico in a higher dimensional space, where the real number line is the only continuum that has an ordering to it.

00:46:21.550 --> 00:46:34.550
As soon as you have the complex numbers, or R2 or R3, etc., you can't pick two points and say one is higher than another, unless you implement other structure. So what is it that allows us to say higher or lower?

00:46:34.550 --> 00:46:50.550
Bad vocabulary. You're 100% right. The only thing that matters here, because it doesn't necessarily mean the next level up is not necessarily smarter than the lower level, usually, but that doesn't guarantee that at all. Not necessarily bigger or smaller in physical scale.

00:46:50.550 --> 00:47:19.550
We really don't have a great vocabulary yet for all this stuff, but the only thing I mean by higher is something akin to set membership. Just the fact that a tissue is made up of cells, and cells are made up of molecular networks. That's it. That's all I'm talking about. I'm not saying that it's bigger or more intelligent or more valuable. All I mean is that in this heterarchy, certain things are made up of other things. That's it. That's all I mean.

00:47:20.550 --> 00:47:43.550
Earlier when defining intelligence, I believe you said William James's was something about ability, but also means. So ability to generate multiple paths to a single goal. I don't know if it was also the ability to have multiple goals, but we can explore that. But let's pick out a goal, then you can generate multiple paths to that goal, many ways of executing. But then you also, I believe you said the means to as well. Is that correct?

00:47:43.550 --> 00:48:07.550
Is that correct? Yeah, the means in James's, at least the way I read him, when he says means, he means the path. That is the path. A means to an end, right? It's a path that takes you to that end. So this is the kind of stuff we see in biology. Just to give you an example, one thing that people often think when they hear me talk about the intelligence of development and so on, people often think I mean the complexity.

00:48:07.550 --> 00:48:26.550
Just the fact that you start from an egg and you end up with, I don't know, a salamander or something, that there's an increase in complexity. And then rightly, people think, well, that's just, you know, there's lots of examples where simple rules give rise to complex outcomes. That's just emergent complexity. That's not intelligence. And they're right. That is not what I mean. That's not intelligence.

00:48:27.350 --> 00:48:32.670
What I mean by intelligence is the problem solving of the following kind. So let's say

00:48:32.670 --> 00:48:39.990
you have an egg belonging to a salamander. One of the tricks you can do is prevent it

00:48:39.990 --> 00:48:44.510
from dividing while the genetic material is copying. And so you end up with polyploid

00:48:44.510 --> 00:48:50.030
newts. So instead of 2n, you can have 4n, 5n, 6n, 8n, that kind of thing. Well, what

00:48:50.030 --> 00:48:53.750
happens when you do that, what happens is the cells get bigger in order to accommodate

00:48:53.750 --> 00:48:58.630
the extra genetic material, but the actual salamander stays the same size. So if you

00:48:58.630 --> 00:49:02.190
take a cross-section, so let's say we take a cross-section of a little tubule, a kidney

00:49:02.190 --> 00:49:05.949
tubule, that runs to the kidneys. Normally, there's like 8 to 10 little cells that go

00:49:05.949 --> 00:49:10.510
in a circle to make that tubule, and then there's a lumen in the middle. So if you make

00:49:10.510 --> 00:49:13.910
the cells gigantic, the first thing you notice is that, well, first of all, having multiple

00:49:13.910 --> 00:49:17.309
copies of the genetic material, you still get a normal newt. So that's pretty amazing

00:49:17.309 --> 00:49:23.149
already. Second amazing thing is when the cells scale to the amount of genetic material,

00:49:23.149 --> 00:49:26.910
so the cells get larger. That's amazing. Then you find that, well, actually, since

00:49:26.910 --> 00:49:33.189
the cells are really big, only a few of them are now working together to make the exact

00:49:33.189 --> 00:49:37.790
same size tubule. So they scale the number of cells to make up for the aberrant size

00:49:37.790 --> 00:49:42.869
of the cell, right? That makes sense? And then the most amazing thing of all happens

00:49:42.869 --> 00:49:47.269
when you make truly gigantic cells, there's not even room for more than one. One cell

00:49:47.269 --> 00:49:52.189
will bend around itself, leaving a lumen in the middle. The reason that's amazing is that

00:49:52.229 --> 00:49:55.750
that requires a different molecular mechanism. That's cytoskeletal bending, whereas before

00:49:55.750 --> 00:50:01.510
you had cell-to-cell communication. And so that is that kind of thing, right? So just

00:50:01.510 --> 00:50:05.510
think about this. You're a newt coming into the world. You have no idea. You can't count

00:50:05.510 --> 00:50:08.589
on how much genetic material you're going to have, how many cells you're going to have,

00:50:08.589 --> 00:50:12.390
what size cells you're going to have. What you do have is a bunch of cool tools at your

00:50:12.390 --> 00:50:16.030
disposal. You have cytoskeletal dynamics, you have gene regulatory networks, you have

00:50:16.030 --> 00:50:20.650
bioelectricity, you have all this stuff. And what you're able to do under totally novel

00:50:20.650 --> 00:50:26.890
circumstances is pick from your bag of tools to solve the problem. I go from an egg to

00:50:26.890 --> 00:50:31.930
in amorphous space, I take this journey from an egg to a proper newt. Not only can I not

00:50:31.930 --> 00:50:35.450
count on the environment being the same, I can't even count on my own parts being the

00:50:35.450 --> 00:50:42.730
same, right? That kind of, you know, another way to call this attitude is beginner's mind.

00:50:42.730 --> 00:50:46.769
It's like you don't over-train on your priors, on your evolutionary priors. You have a bag

00:50:46.769 --> 00:50:53.290
of tools and you're not just a fixed solution. This is why I think evolution doesn't just

00:50:53.290 --> 00:50:58.290
produce solutions to specific environmental problems. It produces problem-solving agents

00:50:58.290 --> 00:51:02.730
that are able to use the tools they have. I mean, what's a better example of intelligence

00:51:02.730 --> 00:51:06.689
than something that can use the tools it has in novel ways to solve a problem it's never

00:51:06.689 --> 00:51:14.329
seen before, right? That is a version of intelligence. And that's, you know, that's what is all over

00:51:14.329 --> 00:51:20.329
the place in biology. The ability to navigate these pathways, not only to avoid various

00:51:20.329 --> 00:51:27.170
barriers and so on, but to use the tools available to them in creative ways to solve the problem.

00:51:27.170 --> 00:51:31.730
And we see some of this in extremely minimal systems. It does not require a brain, doesn't

00:51:31.730 --> 00:51:38.290
even require cells. Very minimal systems have surprising problem-solving capacities. And

00:51:38.290 --> 00:51:42.570
this is why we should be extremely humble when we try to make claims about what something

00:51:42.570 --> 00:51:48.570
is or isn't or what competencies it has. We are not yet good at recognizing those things.

00:51:48.570 --> 00:51:55.850
We do not have a mature science yet of knowing what the properties of any of this stuff is.

00:51:55.850 --> 00:52:00.609
The tricky part with this definition of intelligence, help me out with this, is that what we want

00:52:00.609 --> 00:52:08.090
to say is that it's conceivable that the kid from Saskatoon, the poor kid, is more intelligent

00:52:08.090 --> 00:52:15.329
than the rich kid from the Bay Area. So that's conceivable. But the rich kid has far more

00:52:15.329 --> 00:52:22.249
means, far more ability to achieve their goals. So if there was implementability within the

00:52:22.249 --> 00:52:28.329
path, so if we say, look, the ability to generate paths that are realizable is in part what

00:52:28.329 --> 00:52:35.090
defines the IQ or the intelligence. Well, the poor kid from Saskatoon has less raw material

00:52:35.090 --> 00:52:41.210
to play with to generate a path. So how do we avoid saying, unless you want to say, which

00:52:41.210 --> 00:52:44.770
I don't imagine you want to say, how do we avoid saying that the poor kid from Saskatoon

00:52:44.770 --> 00:52:50.129
is just by definition less intelligent by happenstance than the person from the Bay

00:52:50.129 --> 00:52:51.129
Area?

00:52:51.129 --> 00:52:56.290
Yeah. The thing to keep in mind here is that estimates of intelligence, and I think all

00:52:56.290 --> 00:53:02.529
cognitive terms, so everything about, you know, all the words that people use, sentience,

00:53:02.850 --> 00:53:09.890
goal-directedness, all of them, I think we have to remember that those are not objective properties

00:53:09.890 --> 00:53:15.089
of a given system. IQ is not the property of whatever system you're trying to gauge the IQ of.

00:53:15.089 --> 00:53:20.929
It is your guess, your best guess, about what kind of problem-solving you can expect out of

00:53:20.929 --> 00:53:25.570
that system. So it's as much about you as it is about the system. And we've shown this in our

00:53:25.570 --> 00:53:29.969
experiments a lot of times, that when people talk about certain kinds of developmental constraints,

00:53:29.969 --> 00:53:34.770
or they talk about the competency of tissues to do one thing or the other, it's much more about

00:53:34.770 --> 00:53:39.649
our own knowledge of the right stimuli and the right ways to communicate with that system, and

00:53:39.649 --> 00:53:44.450
not so much about the system itself. When you make an estimate of the intelligence of something,

00:53:44.450 --> 00:53:49.890
you are taking an IQ test yourself. All you're saying is, this is what I know in terms of,

00:53:49.890 --> 00:53:54.450
and this is what I can see in terms of, what kind of problem-solving I can see. And

00:53:54.929 --> 00:54:01.170
this applies to animals, this applies to AIs, this applies to humans in various economic environments.

00:54:02.850 --> 00:54:08.770
You know, the simple version of this is, you show somebody a human brain, and they say,

00:54:08.770 --> 00:54:12.529
that's a pretty awesome paperweight, and I can see that it can do, you know, least action and

00:54:12.529 --> 00:54:16.369
hold down my papers against gravity, and that's all I think it can do. And somebody else says,

00:54:16.369 --> 00:54:21.249
now you've missed the whole thing, right? Like, this thing does all this other stuff. So I think

00:54:21.249 --> 00:54:28.529
that type of mistake, where A, we think that it's an objective property of the system, and B,

00:54:28.529 --> 00:54:34.850
that we think that we're good at determining what that is, is what bites us a lot when we're

00:54:34.850 --> 00:54:39.730
dealing with especially unconventional systems. So if someone, so to use your example, if someone

00:54:39.730 --> 00:54:45.890
looks at a kid with that environment and says, well, I don't think this kid has much intelligence,

00:54:46.529 --> 00:54:50.450
the problem isn't on the side of the kid, the problem is that somebody else might come along

00:54:50.450 --> 00:54:56.290
and says, oh, you don't get it. In a different environment, this kid would exhibit all these

00:54:56.290 --> 00:55:03.570
amazing behaviors. The good news about all of this, and it's not in my wheelhouse to comment

00:55:03.570 --> 00:55:10.770
on any of the kind of economic stuff or the sociology of it, but for the biology and for the

00:55:10.770 --> 00:55:17.730
computer science and so on, the good news is that all of these things are empirically testable.

00:55:17.730 --> 00:55:25.570
So when we come across a certain system, each of us is going to guess what is the problem space

00:55:25.570 --> 00:55:30.770
it's operating in, what are its goals, and what capabilities do we think it has to reach those

00:55:30.770 --> 00:55:34.369
goals, and then we do the experiment. And then we see who's right. That's the thing, that this is

00:55:34.369 --> 00:55:39.249
not a philosophical debate. This is absolutely experimental. So if you say, I don't think these

00:55:39.249 --> 00:55:46.290
cells have any intelligence, I think they're just a feed forward, emergent dynamics. And I think,

00:55:46.290 --> 00:55:49.969
oh no, I think they're actually minimizing or maximizing some particular thing, and they're

00:55:49.969 --> 00:55:54.450
clever about doing it. We do the experiment. We put a barrier in their place between them and

00:55:54.450 --> 00:56:00.610
their goals, and we actually see, do they or do they not have what I claimed to be their

00:56:00.610 --> 00:56:05.809
competency? And then we find out how much each of our views lets us discover the next best thing.

00:56:05.809 --> 00:56:08.529
So these are all empirically testable kinds of ideas.

00:56:09.490 --> 00:56:17.249
So before we get to consciousness and 11 labs, I want to talk about cognition. So in 2021 or so,

00:56:17.249 --> 00:56:23.809
you had a paper called reframing cognition. Okay. Something akin to that?

00:56:23.809 --> 00:56:27.969
Yeah. That sounds like, I think that might've been a review with Pamela Lyon.

00:56:27.969 --> 00:56:34.450
Yes. And then on page 10, section five, something like that, you defined,

00:56:34.450 --> 00:56:38.290
or you started talking about basal cognition and uncaveated cognition.

00:56:39.089 --> 00:56:40.369
So what do those terms mean?

00:56:42.929 --> 00:56:48.209
To be completely honest, I don't remember this part. I mean, I, yes, I certainly don't remember

00:56:48.209 --> 00:56:52.850
the pages or the basal cognition. Yeah. I mean, so, okay. So, so the idea for basal cognition

00:56:52.850 --> 00:56:59.170
is basically that whatever cognitive capacities we have, they have to have an origin. And we

00:56:59.170 --> 00:57:04.449
have to ask where did they come from? Because this idea that, you know, we are completely unique and

00:57:04.449 --> 00:57:08.690
they suddenly sort of snap into, into place. It doesn't, it doesn't work evolutionarily and it

00:57:08.690 --> 00:57:12.610
doesn't work developmentally. Both of those are very slow processes. So the stories we have to

00:57:12.610 --> 00:57:18.370
tell our stories of scaling there to really understand these processes. We have to understand

00:57:18.370 --> 00:57:24.850
how, how simple information processing capacities scale up to, to become larger cognitive icons,

00:57:24.850 --> 00:57:29.730
more intelligent systems project into new problem spaces and so on. So basal cognition is the

00:57:29.730 --> 00:57:35.009
question of, okay, so where did our cognitive capacities come from? So that means looking at

00:57:35.730 --> 00:57:43.490
the functional intelligence of cells, tissues, slime molds, microbes, bacteria and minimal matter,

00:57:43.490 --> 00:57:47.810
you know, active materials, that kind of stuff. That's, that's basal cognition. Well, what do the

00:57:47.810 --> 00:57:52.370
primitive, what do the really primitive versions of cognition look like? And it's a really important

00:57:52.370 --> 00:57:59.490
skill to, to, to, to practice that kind of imagination. Because often what trips people up

00:57:59.490 --> 00:58:05.810
is they, they imagine, for example, for example, panpsychist views, right? So somebody says,

00:58:05.810 --> 00:58:09.649
oh, you're trying to tell me that this rock, you know, is sitting there.

00:58:09.800 --> 00:58:12.640
Having hopes and dreams. Well, no, that's not the claim.

00:58:12.640 --> 00:58:15.740
The claim is that the claim isn't that, that these,

00:58:15.740 --> 00:58:19.440
these full blown large scale cognitive properties that you have are exactly

00:58:19.440 --> 00:58:20.280
there everywhere else.

00:58:20.600 --> 00:58:24.320
The claim is that it's a spectrum or a continuum and that there are primitive,

00:58:24.320 --> 00:58:27.960
tiny versions of them that are also should be recognized because we need to

00:58:28.080 --> 00:58:31.120
understand how they scale. So that's, that's, that's basal cognition.

00:58:31.480 --> 00:58:35.439
So if it's a spectrum, I hear this plenty. Look, I'm not saying someone will say,

00:58:35.439 --> 00:58:38.800
I'm not saying everything is conscious. It's a spectrum. It's not on off.

00:58:39.200 --> 00:58:40.040
But then to me,

00:58:40.240 --> 00:58:43.599
can't you just define on off to be if you have a nonzero on the spectrum,

00:58:43.640 --> 00:58:46.640
then you're on like, for instance, you don't say,

00:58:46.880 --> 00:58:50.800
you say a particle has electric charge. Is it electrically charged? Well,

00:58:50.800 --> 00:58:53.680
it's on the spectrum. Yeah. If it has a nonzero amount,

00:58:53.680 --> 00:58:57.160
you call it electrically charged. If it's zero, then you say it's neutral.

00:58:57.599 --> 00:59:02.480
So can't you just say then that, yes, the rock does have hopes and dreams,

00:59:02.500 --> 00:59:07.040
even if it's at 0.00002% of whatever you have?

00:59:07.480 --> 00:59:12.759
Oh, well, I, I personally am on board with that. I, I, I think, you know,

00:59:12.759 --> 00:59:13.120
I think,

00:59:13.120 --> 00:59:18.120
I think potential energy and least action principles are the tiniest hopes and

00:59:18.139 --> 00:59:21.759
dreams that there are. I, so, so I agree with that completely.

00:59:21.759 --> 00:59:25.800
I think that is the most basal version and in our universe. So, so I don't know,

00:59:25.800 --> 00:59:28.560
this goes way beyond my pay grade, but, but for example,

00:59:28.560 --> 00:59:31.800
I've talked to Chris Fields who is really an expert in this stuff.

00:59:31.800 --> 00:59:35.600
And I asked him, is it possible to have a universe without least action laws?

00:59:35.999 --> 00:59:39.439
Right. And he said, the only way you can have that is if nothing ever happens.

00:59:39.880 --> 00:59:42.800
So if that's, if, if that's the case,

00:59:43.039 --> 00:59:47.280
that tells me that in our world there is no zero on the,

00:59:47.280 --> 00:59:50.999
on the cognitive scale and everything is on it. But, but with, but again,

00:59:51.800 --> 00:59:55.160
we have to, we have to ask then. So, so I agree with you. I think, I think,

00:59:55.200 --> 00:59:57.759
I think if you're on the spectrum, then, then you're on and that's it.

00:59:57.759 --> 01:00:01.560
And I think in this universe, everything is on, but we have to ask ourselves,

01:00:01.560 --> 01:00:05.240
what do we want this terminology to do for us? So, uh,

01:00:05.240 --> 01:00:09.319
that's why some people critique these kinds of perspectives by saying, well,

01:00:09.319 --> 01:00:12.240
then if, if everything is on it, then the word means nothing. Then why, you know,

01:00:12.240 --> 01:00:14.319
why do we, why do we even have the word? Cause everything is,

01:00:14.319 --> 01:00:17.439
if everything is cognitive and I didn't say consciousness yet, but,

01:00:17.439 --> 01:00:19.079
but let's say, let's say everything is cognitive,

01:00:19.079 --> 01:00:20.559
then why do we need the word everything?

01:00:20.999 --> 01:00:25.999
And I really think that we need to focus on what we expect the terminology to do

01:00:26.600 --> 01:00:30.199
for us. So let's, let's imagine, let's just dissect this for a minute. Um,

01:00:30.400 --> 01:00:34.479
the old paradox of the heap, right? So you gotta, you gotta pile of sand and,

01:00:34.520 --> 01:00:37.040
you know, you know that if you take off one little piece of sand,

01:00:37.040 --> 01:00:39.999
you still got a pile, but eventually you have nothing. So, so what, what,

01:00:39.999 --> 01:00:43.559
how do you define the pile? So I think for all of these, so,

01:00:43.559 --> 01:00:44.800
so my answer to this,

01:00:44.800 --> 01:00:49.600
and I think the solution to all of these kinds of terminological issues is that

01:00:49.800 --> 01:00:51.639
it's not about the object itself.

01:00:51.839 --> 01:00:54.479
It's about what tools you're going to use to interact with it.

01:00:54.639 --> 01:00:56.960
So if you call me and you say, I have a pile of sand,

01:00:57.359 --> 01:01:01.439
all I want to know about the definition of pile is, am I bringing tweezers,

01:01:01.479 --> 01:01:06.160
a spoon, a shovel, a bulldozer, a dynamite? What, how are we like, what, what,

01:01:06.160 --> 01:01:08.600
what are the tools that I have to do what we need to get done?

01:01:08.800 --> 01:01:13.040
So that is the only value in, in these, in this, in this terminology. So,

01:01:13.079 --> 01:01:15.680
you know, by saying that everything is cognitive,

01:01:15.680 --> 01:01:17.800
does that by itself help us with anything? No.

01:01:17.999 --> 01:01:22.359
I think what does help is if you tell me what kind of cognition and how much,

01:01:22.479 --> 01:01:24.919
and that's an empirical question. And then we can argue about it.

01:01:25.079 --> 01:01:28.359
And the answer to that question is what are the tools that help us the most?

01:01:28.559 --> 01:01:33.120
So you show me a bunch of cells and you say, I think this, uh, the,

01:01:33.120 --> 01:01:37.320
the right way to do this is, um, physics, chemistry, and, uh,

01:01:37.359 --> 01:01:39.199
feed forward emergence and complexity.

01:01:39.240 --> 01:01:42.160
That's how I think we're going to interact with it. And I look at it and say,

01:01:42.600 --> 01:01:46.199
I think the way to interact with this is through some interesting concepts from

01:01:46.439 --> 01:01:50.040
cognitive neuroscience, including active inference, learning, training, and so on.

01:01:50.240 --> 01:01:52.680
Then we get to find out who's right. You know, if I, if I,

01:01:52.680 --> 01:01:54.520
if I can show that using my concepts,

01:01:54.520 --> 01:01:59.040
I got to new discoveries that you didn't get to, there you go. On the other hand,

01:01:59.040 --> 01:02:00.839
if I waste all my time or, you know,

01:02:01.160 --> 01:02:04.719
writing poems to a rock and nothing ever comes of it, well, then you're right.

01:02:04.960 --> 01:02:09.880
And so, and so I think that, um, uh, the point of all this terminology,

01:02:09.880 --> 01:02:11.479
yes, we can say it's all on a spectrum,

01:02:11.639 --> 01:02:14.320
but now comes the fun and interesting work of saying, okay,

01:02:14.320 --> 01:02:17.760
so what does the spectrum look like and where on the spectrum do the various

01:02:17.760 --> 01:02:19.079
things that we see land?

01:02:20.359 --> 01:02:21.800
Okay. Let's get to consciousness.

01:02:22.520 --> 01:02:26.240
I want to say that I don't agree with Chris Fields about the principle of least

01:02:26.240 --> 01:02:30.759
action, because firstly, people say the universe is lazy,

01:02:31.319 --> 01:02:34.560
but you can also put a minus sign and say the principle of most of maximum

01:02:34.560 --> 01:02:37.280
effort. Okay. But then also there are many,

01:02:38.680 --> 01:02:42.039
there are many quantum field theories that aren't based in Lagrangians to

01:02:42.039 --> 01:02:47.120
minimize. So there's algebraic, constructive, axiomatic and categorical.

01:02:47.359 --> 01:02:49.120
And then there's, there's this whole,

01:02:49.199 --> 01:02:52.479
there's a new video that actually got released a couple of days ago by Gabriel

01:02:52.479 --> 01:02:55.199
Carcassi. And I'll put the link on screen,

01:02:55.359 --> 01:02:59.199
which says there's a distinction between Newtonian Lagrangian and Hamiltonian

01:02:59.199 --> 01:03:01.440
mechanics. So Hamiltonian is more about flows.

01:03:01.479 --> 01:03:04.960
You just watch the flow of the system. Lagrangian is the one where you minimize.

01:03:05.199 --> 01:03:08.120
And then Newtonian, there's actually some Newtonian systems,

01:03:08.319 --> 01:03:12.400
F equals MA that you can't map to a, to a Hamiltonian system.

01:03:12.840 --> 01:03:14.960
So I have a bone to pick with Chris Fields.

01:03:14.960 --> 01:03:16.280
You should have them on. This is the, you know,

01:03:16.280 --> 01:03:18.560
this is getting way beyond anything I could argue with you about,

01:03:18.560 --> 01:03:21.560
but you should have him on and you guys could talk. I would watch that for sure.

01:03:21.599 --> 01:03:23.319
We had a three-way discussion. Again,

01:03:23.359 --> 01:03:28.039
a plug here with Michael Levin, Carl Friston and Chris Fields. That was fun.

01:03:28.199 --> 01:03:29.039
Yeah. Yeah.

01:03:29.079 --> 01:03:33.199
Okay. So many people want to know what is your

01:03:34.599 --> 01:03:36.720
hunch at which, see,

01:03:36.720 --> 01:03:38.560
there are various interpretations of quantum mechanics.

01:03:38.560 --> 01:03:39.280
We're not going to go there,

01:03:39.280 --> 01:03:42.359
but there are various theories of consciousness in the same way.

01:03:42.680 --> 01:03:44.639
There's a litany. There's a litany.

01:03:45.240 --> 01:03:47.000
Which one do you feel like is on the right track?

01:03:48.000 --> 01:03:50.520
Well, let's see. I can say a few things.

01:03:51.079 --> 01:03:54.280
I, what I definitely don't have yet, I'm working on it,

01:03:54.280 --> 01:03:56.800
but I don't have anything that I would, I would talk about now.

01:03:57.120 --> 01:03:58.960
A new theory of consciousness.

01:03:58.960 --> 01:04:03.000
So I do not have anything brilliant to add to this that somebody else hasn't

01:04:03.000 --> 01:04:06.560
already said. So I'm just going to kind of tell you what, what I have to say now.

01:04:06.599 --> 01:04:07.440
Sure.

01:04:08.479 --> 01:04:09.400
I think that

01:04:11.840 --> 01:04:16.039
one thing that's really hard about consciousness and what makes it the hard

01:04:16.319 --> 01:04:19.039
problem is that unlike everything else that we work with,

01:04:19.479 --> 01:04:24.039
we don't have any idea what a correct

01:04:24.599 --> 01:04:29.039
theory would output. So what would the, what format would the predictions?

01:04:29.720 --> 01:04:32.240
Sorry, we don't have an idea of what the correct theory would look like.

01:04:32.400 --> 01:04:34.319
No, no, no, no. We don't have a correct,

01:04:34.919 --> 01:04:38.479
we don't have any idea of what the output of a correct theory would look like.

01:04:38.479 --> 01:04:41.479
What would it give you? Right. So, so, so for everything else, the correct,

01:04:41.879 --> 01:04:44.520
a good theory gives you numbers, but you know,

01:04:44.520 --> 01:04:46.840
predictions about specific things that are going to happen. What does,

01:04:46.840 --> 01:04:51.159
what does a good theory of consciousness give you? So, you know, what,

01:04:51.159 --> 01:04:55.319
what we would like is something that, you know, we, we say, okay, here's a,

01:04:55.400 --> 01:05:00.120
here's a cat or here's a cat with three extra brain hemispheres grafted on that

01:05:00.120 --> 01:05:03.079
also has wings. What is it like to be these, these creatures, right?

01:05:03.560 --> 01:05:07.240
What is the output of a correct theory of consciousness? Because,

01:05:07.400 --> 01:05:11.759
because if it outputs patterns of behavior or physiological states,

01:05:11.759 --> 01:05:13.879
then what you've explained is physiology and behavior.

01:05:14.120 --> 01:05:16.000
There are going to be people say that say, well,

01:05:16.039 --> 01:05:18.919
you haven't explained the consciousness at all. In fact,

01:05:19.800 --> 01:05:23.440
almost all theories of consciousness look like,

01:05:23.840 --> 01:05:26.599
look kind of eliminativist, even the ones that aren't trying to be,

01:05:26.759 --> 01:05:27.879
even the ones that say, no, no,

01:05:27.879 --> 01:05:29.919
we're not trying to explain away consciousness. It's real.

01:05:29.919 --> 01:05:33.359
And I'm going to explain it. Then you look at the explanation and you always feel

01:05:33.359 --> 01:05:37.240
like, yeah, but, but, but you haven't explained the actual, you know, yeah,

01:05:37.280 --> 01:05:40.960
the actual consciousness, you've explained some kind of behavioral propensities,

01:05:40.960 --> 01:05:44.000
physiological states or whatever. So, so that's the problem that we have.

01:05:44.120 --> 01:05:48.319
Consciousness is the one of those things that cannot exclusively be studied in

01:05:48.319 --> 01:05:50.359
the third person. Everything else,

01:05:50.359 --> 01:05:54.720
you can study as an external observer and you don't change much as the observer

01:05:54.720 --> 01:05:58.919
by, by studying them. Consciousness, you can really only, you know,

01:05:58.919 --> 01:05:59.440
in a full way,

01:05:59.440 --> 01:06:03.879
you can only study consciousness by being part of the experiment by, by, by C,

01:06:03.879 --> 01:06:06.960
by experiencing it from the, from the first person perspective.

01:06:07.159 --> 01:06:09.680
So the weak version of this is you might say, well,

01:06:09.680 --> 01:06:11.879
a good theory of consciousness is, is a kind, is art.

01:06:12.120 --> 01:06:15.599
What it outputs is art, poetry, whatever, that when we experience it,

01:06:15.759 --> 01:06:18.359
it makes us experience that conscious state. And we say, Oh,

01:06:18.359 --> 01:06:21.560
so that's what it's like. I see. Right. So, so that's, that's one that,

01:06:21.560 --> 01:06:24.120
but now that's kind of a weak form. You can do a stronger form and you say,

01:06:24.319 --> 01:06:27.720
well, the real way to do it is to have a rich brain interface.

01:06:27.879 --> 01:06:30.159
So if I want to know what some other system is,

01:06:30.159 --> 01:06:33.639
is what its consciousness is like, we need to fuse together.

01:06:33.840 --> 01:06:37.680
Now caveat to that is you don't find out what it's, if you do that, you know,

01:06:37.720 --> 01:06:40.800
so, so let's say a rich kind of brain interface, you know,

01:06:40.800 --> 01:06:43.359
we really connect our brains together or something.

01:06:43.640 --> 01:06:47.479
You don't get to find out what it's like to be that system. You find,

01:06:47.479 --> 01:06:50.760
both of you find out what it's like to be a new system composed of the two of

01:06:50.760 --> 01:06:55.800
you. So it's still not. So from that perspective it's, it's really hard.

01:06:55.800 --> 01:06:58.760
I mean, you know, people, I suppose people who do meditation or take psychedelics,

01:06:58.760 --> 01:07:01.760
I suppose they're doing experiments in actual consciousness, but,

01:07:01.800 --> 01:07:05.120
but third person experiments in consciousness are really hard.

01:07:05.120 --> 01:07:07.760
You can do things like turn it off, you know, so there's general anesthesia.

01:07:07.959 --> 01:07:12.000
And you can say, Oh look, you know, the consciousness is gone. And, and even,

01:07:12.000 --> 01:07:15.320
and even then some people will say, yeah, but I experienced, you know,

01:07:15.560 --> 01:07:18.640
floating above my body while you did the surgery. And I, you know,

01:07:18.640 --> 01:07:22.200
when I saw you drop the scalpel and do this or that. So, so it's still, you know,

01:07:22.200 --> 01:07:25.359
even, even with that amazing reagent of being able to supposedly shut off

01:07:25.359 --> 01:07:28.039
consciousness, you still got some issues. So, so,

01:07:28.080 --> 01:07:32.519
so the study of consciousness is hard for those kinds of for those kinds of

01:07:32.519 --> 01:07:35.599
reasons. Um, and, uh, I,

01:07:35.599 --> 01:07:40.599
I think that about the only useful thing I could say here is that for the same

01:07:40.959 --> 01:07:45.959
reasons that we associate consciousness with brains for exactly those same

01:07:46.279 --> 01:07:47.000
reasons,

01:07:47.000 --> 01:07:51.359
we should take very seriously the possibility of other forms of consciousness in

01:07:51.359 --> 01:07:52.399
the rest of our bodies.

01:07:52.450 --> 01:08:22.450
And, and also lots of other things, but, um, you know, we, and so, so I'm working, so Nick Rouleau and I are working on a, on a paper on this, where you can sort of look at all the different popular theories of consciousness on the table, and you can just ask which of them are specific for brains and why, like what, what, what aspects of each of those theories really tells you that it's got to be brains, my guess is we haven't finished the paper yet, but my guess right now is that there's not a single one that can distinguish brains from other, uh, other, other types of structures in your body.

01:08:22.450 --> 01:08:31.450
And so I think we should take very seriously the possibility that other subsystems of the body have some sort of consciousness. It's not verbal consciousness.

01:08:31.450 --> 01:08:41.450
Sorry, I'm not understanding. Are you saying, what if we list all the theories of consciousness and then we place, does it distinguish the brain as being responsible for consciousness?

01:08:41.450 --> 01:08:46.450
Yeah, we ask what, what is it about that theory that says it's in the brain rather than somewhere else? Let's say your, let's say your liver.

01:08:46.450 --> 01:08:56.450
So IIT would say no, because IIT is a panpsychist theory that would say, look, if your liver is doing some processing, then it has some nonzero amount of consciousness.

01:08:56.450 --> 01:09:07.450
Right, right. And I, and I agree with that. Now, now, now, now, as far as I understand, as far as I understand, IIT also has an exclusion postulate that says there should only be one central consciousness in the, in the system.

01:09:08.450 --> 01:09:23.450
I think that's true. At least it used to be true. Um, I don't know. Julia may, may disagree with that, but, uh, but, but, but I think we are actually a, um, uh, a collection of interacting, uh, perspectives and interacting consciousnesses for that, for that reason.

01:09:23.450 --> 01:09:32.450
And, uh, you know, then sometimes people say, well, I don't feel my liver being conscious. Right. You don't, uh, but you don't feel me being conscious either. Of course you don't.

01:09:32.450 --> 01:09:41.450
And, and the fact that your left hemisphere has the, the, the language ability for us to sit here and talk about it and the, the, the liver doesn't, doesn't actually mean that it's not conscious.

01:09:41.450 --> 01:09:48.450
It just means that we don't have direct access to it and we don't have direct access to each other. So that doesn't, that doesn't bother me.

01:09:48.450 --> 01:09:58.450
Um, so I, that's, that's my suspicion about, about consciousness is that for, for the same reason that people think it's in the brain, we should take very seriously that it's in other places in the body.

01:09:58.450 --> 01:10:07.450
And then, and then more, more generally, uh, you know, um, other, uh, other types of constructs that are not human bodies at all, or not even animal bodies.

01:10:08.450 --> 01:10:21.450
You've spoken to Bernardo Kastrup several times now. What is it you agree with him the most that you think most people would disagree about? Because you agree with him that it's nice to go for a walk. Okay, sure. But most people agree it's nice to go for a walk.

01:10:21.450 --> 01:10:32.450
So what is it that you agree with him about that you think is a contentious issue to most people? So this isn't, this is a controversial statement. And then what is it you disagree with him about regarding consciousness?

01:10:32.450 --> 01:10:45.450
Yeah, boy, uh, I don't, you know, it's hard for me to know what most people agree or disagree with him about. I, I really don't know. Um, we, we, we agree on a lot of things. We agree on, I think the primacy of, of, of consciousness.

01:10:45.450 --> 01:11:11.450
Uh, I, I think that, uh, you know, his, his idealist position has a lot of, uh, a lot to recommend it. The one thing I think we disagree on is, um, the issue of compositionality. So if I recall correctly from, from a talk that we had together a little while ago, he felt that, uh, it is important in order to be a true self, to be a, to be, to, to have a conscious experience as an inner perspective.

01:11:12.450 --> 01:11:30.450
Um, you have to be, you know, he, he, he focuses on the view of, um, embryonic development as a single system that, you know, whatever subdivides and develops, but it, but it starts out as a single system. And I was arguing that that really is just a, um, uh, a contingent feature of biology.

01:11:30.450 --> 01:11:58.450
I mean, we certainly can take two, two early embryos and mush them together. You get a perfectly normal, you know, embryo out of it. And in general, there are lots of biological systems like our, our xenobots, like, uh, like anthropods that you can, you can create by composition, by pulling other things together. So I, I don't give as much, um, I don't put as much emphasis on a system being demarcated from the outside world because it was somehow, uh, because it started out that way and it sort of remained, uh, you know, disconnected.

01:11:58.450 --> 01:12:26.450
I, I think those are, I think that's kind of a superficial aspect of the biology and you can do things a different way. I don't think that's what, um, what's responsible for it. But, but he, he, you know, I, I, yeah, I think, I think he thinks it's important that, that individual selves are not, um, compositions. They're not made as compositions. They're, they're somehow, um, you know, individualized from the word go, which again, even the egg, right? So, so we, I mean, we, we, we humans like eggs because we can see it as a distinct little thing with a membrane.

01:12:26.450 --> 01:12:42.450
You'd say, ah, there's an individual, but, but, but even an egg is composed by the maternal organism from molecular components. Like I, I see, I see no, no point at which any of this is, is truly distinct from, from anything else. So, so I put less emphasis on it, but I, but I think he thinks it's important.

01:12:42.450 --> 01:12:58.450
It seems like the point that you're saying is, look, we can think about this as several rooms. This building comprises several rooms, but even in, and Bernardo may say, that's what makes a person is the distinct rooms. But you're saying, yeah, but even in a room, there are different people, there are different chairs, there are different tables. Is that what you're saying?

01:12:58.450 --> 01:13:22.450
What I'm saying is, and, and I, you know, I may not be doing justice to his view, and I think, I think you should ask him more about this, but, um, I think he thinks that it's important in order to be a unified. So, so I think we were discussing what makes for a unified inner perspective, right? So, so we don't feel like, uh, billions of individual brain cells. I mean, I have no idea why, well, we kind of do, because that's what it feels like to be billions of individuals of neurons. That's really what it feels like.

01:13:22.450 --> 01:13:48.450
But, um, but we do feel at least most of us, most of the time feel like some kind of unified, centralized inner perspective. And so we were talking about how that comes about. And I think he felt that having that in, in the physical universe is, uh, importantly related to, um, arising from a single origin. So he sees the egg as a single point of origin and, and arising from that, that's how you are a separate individual from others.

01:13:48.450 --> 01:14:08.450
And I see it as much more fluid and I see the boundary between self and world as something that can change all the time. I think it changes in embryogenesis and that's the scale of, that's the story of the scaling of the cognitive licon that we talked about. I think it can shrink during cancer. Uh, I think it can change during metamorphosis, during maturation. Um, I, I think, I think it's much more fluid than that.

01:14:08.450 --> 01:14:24.450
Now, as we're on speculative ground, if what makes an agent is the distinction between the self and the world, and some people think of God as the entirety of everything, thus the entire world, and there's no distinction, then can one say that God is an agent?

01:14:24.450 --> 01:14:50.450
I don't know. I mean, certainly I think most, uh, well, religions that have a, that have a God anyway, as far as my understanding is, they would think that yes, the God has, uh, extreme agency, in fact, higher than, than ours. I, I don't know what that really buys us, um, you know, in any, in any, uh, helpful way. Um, remove the word God. Does the world have agency?

01:14:50.450 --> 01:15:11.450
Okay. So, so that's an interesting question. So, so let's start with, first of all, how do we know when anything has agency? And that's an, that's an experimental research program. So you basically, you hypothesize what, uh, problem space it's working in, what you think its goals are, and then you do experiments to figure out what competency it has. And then you find out, did I guess well, poorly? Do I need to make a better guess? And so on.

01:15:12.450 --> 01:15:38.450
So, uh, for example, um, uh, people have said, uh, to me, well, you know, you're kind of a panpsychist almost view says that the weather should be, you know, cognitive. And I, you know, I, I say, uh, I don't say that it is or isn't because we haven't done the experiments. Do I know that, uh, weather systems, let's say, let's say hurricanes or so on. Do I know that they don't show habituation sensitization, that they couldn't be trained if you had the right scale of, of machinery? I have no idea.

01:15:38.450 --> 01:16:04.450
But what I do know is that it's not a, um, this is not a philosophical, uh, thing that we can decide arguing in an armchair. Yes, it is. No, it isn't. No, you have to do experiments and then you find out. So now the question is, okay, so what about, you know, the galaxy? What about the universe, right? Are these the, you know, Gaia ecosystems? Again, I think these are all empirical questions. Now, some of them are intractable. I, you know, we don't have the capability to do, um, experiments on a, on a, on a planetary scale.

01:16:04.450 --> 01:16:33.450
But for example, one thing that I did try to do once was design a gravitational synapse. So design a solar system size arrangement where masses would fly in and based on the history of masses flying in, it would respond to new masses in a different way. So you can do, you know, historicity and you can have habituation and sensitization and things like that. So could you have something like that? That would be very sort of ponderously slowly on an enormous scale computing something and having, you know, sort of simple thoughts. I bet you could, you know, I bet you could.

01:16:34.450 --> 01:17:03.450
I have no idea. We have to do experiments. So, so, you know, here, here you bump up against another question, which is how do you know if, if, and when you are part of a larger cognitive system, right? So, so I don't know, you know, how do we know if we are in fact part of a bigger, a bigger mind? So I don't know. Um, and my suspicion is that there are some sort of Gödel like theorem that will tell you that you can never know for sure. Uh, and you can, you know, you can never be certain, but I bet that you could gather evidence for it.

01:17:04.450 --> 01:17:30.549
Well, for, for or against. And I often think about, um, a kind of a, um, uh, uh, you know, kind of a mental mental images. Imagine two neurons in the brain and one is a, is a, you know, kind of a, kind of a strict materialist and one's a little more mystical. And the one neuron says like, uh, you know, we're, we're just, we just run on chemistry and the outside world is a cold mechanical universe and it doesn't care what we do. There's no mind outside of us. And the

01:17:30.550 --> 01:17:34.070
other one says, can't prove it, but I kind of feel like there's an order to things. And

01:17:34.070 --> 01:17:37.990
I kind of feel like our environment is not stupid. I kind of feel like our environment

01:17:37.990 --> 01:17:42.710
wants things from us. And I kind of feel these waves of, of, you know, these waves back propagating

01:17:42.710 --> 01:17:46.470
through us that are like almost rewards and punishments. I feel like the, the, the universe

01:17:46.470 --> 01:17:50.150
is, is trying to tell us something. And, and the first one says, ah, you're just seeing,

01:17:50.150 --> 01:17:55.030
you know, um, faces and clouds. It doesn't, it doesn't exist. And of course in, in, in my

01:17:55.030 --> 01:17:58.550
example, the second one is correct because they are in fact part of a larger system.

01:17:58.550 --> 01:18:03.590
They're part of a brain that is learning things. And it's very hard for any one node in that

01:18:03.590 --> 01:18:10.710
system to recognize that, or even a sub node, you know, sub network. But I wonder if we could,

01:18:10.710 --> 01:18:15.270
uh, having, having a, you know, a degree of intelligence ourselves, if we could gain

01:18:15.270 --> 01:18:20.630
evidence that we were part of a larger system that was actually processing information.

01:18:20.630 --> 01:18:25.270
And I don't, I don't know exactly what that would look like, but my hunch is that it would

01:18:25.270 --> 01:18:31.509
look like what we call synchronicity. I think that what it would look like are, um, coincidence,

01:18:32.870 --> 01:18:39.189
are, are events that don't have a, uh, causal connection at our lower level, like, like

01:18:39.189 --> 01:18:44.230
mechanistically, like by physics, there's no reason why that should be, but at a larger scale in terms

01:18:44.230 --> 01:18:49.910
of meaning and, um, uh, you know, grant grant, uh, the, the, the greater meanings of things that,

01:18:49.910 --> 01:18:54.310
that they do have, uh, some kind of interpretation. And I think that's what it would look like to be

01:18:54.389 --> 01:18:58.469
part of a larger system. I think it would look, it would look and feel like synchronicity. So does

01:18:58.469 --> 01:19:02.389
it exist? I, you know, I don't know, but that, that's what I think it would feel like.

01:19:03.189 --> 01:19:07.030
Take me through the history of the Levin Lab. When did it start?

01:19:07.030 --> 01:19:07.509
Whoa.

01:19:07.509 --> 01:19:10.630
What were your, what were your first breakthroughs?

01:19:11.990 --> 01:19:19.829
Yeah. Um, okay. Uh, let's see. Well, it started, I mean, it, it, it started in my head when I was

01:19:19.829 --> 01:19:23.829
pretty young. Like I was, it was a dream that I had, uh, to, to do this kind of stuff. I mean,

01:19:23.829 --> 01:19:27.910
I, I consider myself to be the luckiest person in the world. I get to, I get to do, you know,

01:19:27.910 --> 01:19:31.990
the, the funnest stuff with the best people. So, um, I, yeah, I, I think it's, I think it's,

01:19:31.990 --> 01:19:37.429
uh, super, super fortunate. Um, but, but I had, I kind of had this, this idea when I was very young,

01:19:37.429 --> 01:19:41.829
I had no idea what it was like. Uh, I was pretty sure that it was actually impossible. Um, I never

01:19:41.829 --> 01:19:46.070
really thought it would be practically feasible, but I figured I would push it as far as I could

01:19:46.150 --> 01:19:50.469
before, you know, before, um, I would have to go back to coding and, uh, you know, because, um,

01:19:51.109 --> 01:19:55.510
yeah. Uh, for people who are unaware, your background's also in computer science.

01:19:55.510 --> 01:19:59.589
Right. Right. Yeah. Yeah. Um, yeah, we, we, uh, you know, I, I, I learned to program pretty young

01:19:59.589 --> 01:20:03.589
and at that time, uh, that was a good way to, uh, that was a pretty good way to, um, to make money.

01:20:03.589 --> 01:20:07.270
And I just figured I would do the biology as long as I could. And then eventually I would get kicked

01:20:07.270 --> 01:20:13.829
out. Uh, and then, then I would just go, you know, go back to coding. Um, so yeah, my, my lab actually

01:20:13.829 --> 01:20:20.309
began, uh, in September of 2000. Uh, that's when, um, uh, I got, I got a faculty position, uh, at

01:20:20.309 --> 01:20:25.350
the, uh, Forsyth Institute at the Harvard Medical School. And, uh, and I, yeah, we opened, we opened

01:20:25.350 --> 01:20:30.229
our doors in 2000. It was just, it was just me at first and then me and one other technician.

01:20:30.229 --> 01:20:34.389
Um, there's, there's like 42 of us now, but at the time it was just, it was just me and,

01:20:34.389 --> 01:20:41.189
and a tech named Adam. Um, and, uh, that was the first time, you know, starting then was the first

01:20:41.189 --> 01:20:47.270
time that I could really start, uh, to take, uh, practically in, in, you know, to, to be practical

01:20:47.270 --> 01:20:51.430
about some of the, some of the, um, ideas I had about bioelectricity and cognition and all these

01:20:51.430 --> 01:20:56.790
things. Prior to that, I was building up a tool chest. So I was building up, uh, skills, techniques,

01:20:56.790 --> 01:21:03.910
um, uh, you know, um, uh, information and so on, but being a grad student and then a postdoc,

01:21:03.910 --> 01:21:08.070
I wasn't able to talk about any of these things. Uh, but, but then when I was on my own and, and,

01:21:08.389 --> 01:21:13.270
and then that was the time to get going. So, um, just a couple of, you know, a couple of

01:21:13.270 --> 01:21:20.550
interesting, interesting milestones, uh, uh, already by the time, by the time I got, you know,

01:21:20.550 --> 01:21:25.510
I, I, uh, we, we opened the lab. I was involved in a collaboration with, um, with Ken Robinson and

01:21:25.510 --> 01:21:31.749
his, uh, his postdoc Thorley Thorland and together, uh, with, and with my postdoc mentor, Mark Mercola,

01:21:32.309 --> 01:21:39.669
we, um, really showed the first molecular tools for bioelectricity. So we had a paper on left,

01:21:39.669 --> 01:21:45.669
right, asymmetry. And, uh, we showed, uh, we showed the first, uh, bioelectric tracking of

01:21:45.669 --> 01:21:49.349
non-neural bioelectric states in the chicken embryo. We showed that it was important for

01:21:49.349 --> 01:21:54.310
setting up which side is left, which side is right. And, and then, uh, manipulating that

01:21:54.310 --> 01:21:59.590
information using injected ion channel constructs. So that was the first time any of that, you know,

01:21:59.590 --> 01:22:03.190
reading and writing the mind of the body, which is how I, I certainly wouldn't have said it back

01:22:03.190 --> 01:22:08.310
then, but this is how I see it now. Um, that, that was the first time that was done in a molecular,

01:22:08.310 --> 01:22:13.750
in a molecular way. So that, that, that cell paper came out and I think, uh, 2002, I think it finally

01:22:13.750 --> 01:22:18.389
came out. Um, but that, that was a really early, uh, really early project. The other, the other

01:22:18.389 --> 01:22:25.829
really early project was, um, I had, uh, as a, as a, as a, as a postdoc, um, I started gathering

01:22:25.829 --> 01:22:31.590
tools for this whole, for this whole effort. And a lot of those tools were DNA plasmids encoding

01:22:31.590 --> 01:22:36.870
different ion channels. And so what I would do is I would write, uh, send, send emails or letters

01:22:36.870 --> 01:22:41.349
to people working in electrophysiology, gut physiology, inner ear, and, you know, they would

01:22:41.349 --> 01:22:45.190
have some potassium channel that I had cloned. And I would say, you know, could I, could I get

01:22:45.190 --> 01:22:52.310
one of these plasmids? Um, and, uh, I, I was, uh, I was, um, I was telling them what I was going to

01:22:52.310 --> 01:22:57.430
do. I, you know, I would say, and what I'm going to do is, is, is use it to express it in embryos

01:22:57.430 --> 01:23:02.150
in various locations and use it to, to, uh, in a very targeted way, change the bioelectrical

01:23:02.150 --> 01:23:05.669
properties of these things. And, you know, most people were very nice and they sent me these

01:23:05.669 --> 01:23:10.550
constructs. One person sent a, uh, a letter to my postdoc mentor to say that I had had a, clearly

01:23:10.550 --> 01:23:14.310
had had a, you know, a mental breakdown and that he shouldn't be careful because this is so insane

01:23:14.310 --> 01:23:18.710
that I'm obviously off my rocket, right? And so I remember... Now, wait, is this your recapitulation

01:23:18.710 --> 01:23:22.310
of what they said or they actually said mental breakdown? Well, okay. So I, I didn't see the

01:23:22.310 --> 01:23:26.229
letter, but my boss came to me. So, so my boss came to me and he was laughing and he said, and

01:23:26.229 --> 01:23:29.909
he said, look at this, this guy says you're nuts. So you asked him for, for a plasmid. He told me

01:23:29.909 --> 01:23:33.750
to be, you know, to watch out. He says, you're having a psychiatric break. So, um, so that's

01:23:33.750 --> 01:23:39.590
what, that's what I'm relaying is what, what he said to me. Okay. So, um, but, uh, but nevertheless,

01:23:39.590 --> 01:23:46.789
most people sent constructs, uh, and, um, uh, in, when, when we got to lab, uh, when, when my lab

01:23:46.789 --> 01:23:50.949
opened, I started doing that. I started, um, mis been mis-expressing these things in embryos to

01:23:50.949 --> 01:23:55.109
just to, just to see the space of possible changes, right? What does bioelectricity really do? I mean,

01:23:55.109 --> 01:23:59.590
nobody knew at the time it was thought it was really crazy. It was thought that, uh,

01:23:59.590 --> 01:24:03.909
membrane voltage was a, um, a housekeeping parameter. There was an epiphenomenon of

01:24:03.909 --> 01:24:08.310
other things that cells were doing and that, uh, if you mess with it, all you're going to get is

01:24:08.310 --> 01:24:12.389
uninterpretable death. That's, that's, you know, everybody thought this was a stupid idea. And so,

01:24:12.389 --> 01:24:17.990
and so we started doing this and I had this, uh, I had this, uh, um, um, graduate student,

01:24:17.990 --> 01:24:22.629
she was, she was in the dental program. Her name was Ivy Chen and she was in the dental program.

01:24:22.629 --> 01:24:27.430
And, uh, she had, she had amazing hands. And so I taught her to micro inject RNA into cells in the,

01:24:27.430 --> 01:24:30.710
in the embryos. Cause you know, she had like really, really good hands. How did you know she

01:24:30.710 --> 01:24:35.829
had good hands before she tried that? Well, you look like you have good hands. Well, she was a

01:24:35.829 --> 01:24:39.430
dental student. And so, so I talked to her, she wanted to do research and I said, tell me, tell

01:24:39.430 --> 01:24:42.789
me what you do. And they said, Oh, I do these, you know, I saw people's, you know, gums and

01:24:42.789 --> 01:24:46.389
whatever. And I said, okay, you, you probably could do this. Okay. So she wasn't playing call

01:24:46.389 --> 01:24:51.750
of duty. No, no, no. She, well, she may have been also, but I don't know. I don't know that. Uh,

01:24:51.750 --> 01:24:55.270
what I know is that she was doing, you know, surgeries and in people's mouths. And, and I

01:24:55.270 --> 01:24:59.190
thought that, that she may be able to, you know, in, in tight confined places, you know, with the

01:24:59.190 --> 01:25:02.470
glasses and everything. So I thought, I thought she would be able to do this through a microscope

01:25:02.470 --> 01:25:06.949
and she, and she was. Um, and so, and so we, we did this, we did this together and we injected

01:25:06.949 --> 01:25:12.069
these, these constructs. And I still remember to this day, uh, she calls me in one day and she

01:25:12.069 --> 01:25:16.150
says, um, so I looked at the embryos and they're, they're covered with some kind of black dots.

01:25:16.150 --> 01:25:20.229
And I said, uh, black dots. Uh, let me, let me see. Let's go. Let's go look. So I, so I come

01:25:20.229 --> 01:25:24.629
out and we look, we look through the microscope, the black dots were eyes. What she had done was

01:25:24.629 --> 01:25:28.789
what she had done was the potassium channel that she injected, um, was the one that we later year

01:25:28.789 --> 01:25:33.990
took years to publish the paper. But, uh, what she, what she had discovered is that is, is a

01:25:33.990 --> 01:25:38.629
particular bioelectrical state that tells cells to build an eye. It's, it's remarkable because

01:25:38.629 --> 01:25:44.069
right, right there. And then, uh, you knew that a bioelectricity was instructive. It was not an

01:25:44.069 --> 01:25:48.949
epiphenomenon because it controls which organs you get. B that it's that the whole system is modular

01:25:48.949 --> 01:25:54.870
and hierarchical because we did not tell the cells how to build an eye. So we, we didn't say where

01:25:54.870 --> 01:25:58.789
the stem cells go or what cells go next to what other cells or what genes should be expressed.

01:25:58.789 --> 01:26:03.269
We did none of that. We triggered a high level subroutine that says build an eye here. So right

01:26:03.269 --> 01:26:07.990
away that, that one experiment like told us, told us all these amazing things. Then, then eventually,

01:26:07.990 --> 01:26:11.830
and this was the work of a grad student, um, Sherry Ao in my group who, uh, took, you know,

01:26:11.830 --> 01:26:16.950
took on the project and she did a whole PhD on this showing that the other amazing thing about

01:26:16.950 --> 01:26:21.669
it is that if you only target a few cells, what they do is they get their neighbors to help out

01:26:21.669 --> 01:26:24.709
because they can tell there's not enough of them to build an eye, you know, kind of like ants,

01:26:24.709 --> 01:26:29.909
you know, ants recruit their, their, their buddies to take on a bigger task. So that tells you that

01:26:29.909 --> 01:26:35.349
the, that, that the material you're working with has these amazing properties that you don't have

01:26:35.349 --> 01:26:39.430
to micromanage, right? It's a different kind of engineering. It's engineering as, as I put it

01:26:39.430 --> 01:26:44.310
recently in a recent paper, it's engineering with, um, a gentle materials because it's a material

01:26:44.310 --> 01:26:48.630
with competencies with an agenda. You don't have to control it the way you do wood and metal and

01:26:48.630 --> 01:26:54.950
things like that. So, okay. So anyway, so, so, so that, that, that kind of thing, um, uh, then, uh,

01:26:54.950 --> 01:27:01.990
then we had a bunch of work on a bunch more work on left, right asymmetry and showing how, uh,

01:27:01.990 --> 01:27:07.990
the cells in the body decide which side they're on based on, um, based on these electrical cues.

01:27:07.990 --> 01:27:08.950
Then we discovered that.

01:27:09.200 --> 01:27:15.160
In order for cells to, uh, the way they interpret these electrical cues had to do with, uh, the movement of serotonin.

01:27:15.360 --> 01:27:20.360
So long before the nervous system or the brain shows up, the body is using serotonin to interpret electrical signals.

01:27:20.560 --> 01:27:34.759
So, so this was, this was really underscoring, um, the, uh, the idea that a lot of the tools, concepts, reagents, pathways, mechanisms from neuroscience really have their origin much earlier.

01:27:34.880 --> 01:27:37.220
And so this was a completely new role for serotonin, right?

01:27:37.659 --> 01:27:47.180
So, so serotonin is a neurotransmitter does many interesting things, but long before your brain appears, it also controls which direction of your body, your heart, and your various other organs go to.

01:27:47.459 --> 01:27:53.740
So trying to understand in, in the kind of, you know, in the short term, how does electrical activity control cell behavior, but bigger picture.

01:27:54.060 --> 01:27:54.540
Wow.

01:27:54.540 --> 01:28:00.940
These, these, these neural like processes are going on in cells that are absolutely not neurons much more, you know, but much long, long before that.

01:28:01.380 --> 01:28:03.540
So, um, so that was, that was kind of cool.

01:28:03.540 --> 01:28:09.299
Um, then, then I hired a postdoc named Danny Adams who later became a faculty member, uh, and a, and a colleague.

01:28:09.580 --> 01:28:17.820
And one of the things that she did was to, um, pioneer the early use of voltage sensitive dyes to read these electrical potentials.

01:28:18.140 --> 01:28:24.140
And so she discovered, uh, in the work that she did in my group, she, she discovered this, um, this thing we call the electric face.

01:28:24.339 --> 01:28:25.820
And approximately what year is this now?

01:28:26.259 --> 01:28:27.979
Oh, this is the electric face.

01:28:27.979 --> 01:28:34.299
This is probably 2000, 2008, something like that, 2007, 2008.

01:28:34.860 --> 01:28:55.060
Um, and, uh, what she had discovered was that if you look at the nascent ectoderm that later will regionalize to become face and mouth, you know, eyes and mouth and all of that, that, um, uh, that, uh, early, early on before all the genes turn on that, um, uh, determine where all those things will go.

01:28:55.259 --> 01:28:58.899
The bioelectric pattern within that ectoderm looks like the face.

01:28:58.939 --> 01:29:01.020
It, it shows you where all this stuff is going to go.

01:29:01.219 --> 01:29:03.579
And then, and then we ultimately, we were able to show that.

01:29:04.259 --> 01:29:07.780
And by the way, there was that eye spot, which, which is, which is why the eye thing worked.

01:29:08.100 --> 01:29:18.379
And we were able to show that all kinds of birth defects that mess up the formation of face, do it by, uh, uh, uh, inhibiting the normal bioelectric pattern and that you could fix it.

01:29:18.379 --> 01:29:22.339
You know, you could, you could, you could, um, exert, um, repair effects that way.

01:29:22.979 --> 01:29:26.140
So, uh, so that was, uh, so that was, that was interesting.

01:29:26.179 --> 01:29:32.099
Then, then we, when we started looking at regeneration, um, and again, the early work was done also by Danny.

01:29:32.099 --> 01:29:42.580
And then later on by Kelly Chang, who's now a faculty member at university of Las Vegas, where what we did was, uh, we showed that, um, tadpole tail regeneration was also bioelectrically driven.

01:29:42.860 --> 01:29:50.140
And that was our first gain of function, uh, effect in regeneration, where we are able to show that we could actually induce new regeneration.

01:29:50.339 --> 01:29:51.940
So the tail is a very complex organ.

01:29:51.940 --> 01:29:58.459
It has a spinal cord, muscle, bone, well, not bone, vasculature, um, uh, innervation, um, peripheral innervation, skin.

01:29:58.940 --> 01:30:06.220
And so, um, we took, we took tadpoles that normally do not regenerate and there's a, there's a stage at which they, they can't regenerate their tails.

01:30:06.580 --> 01:30:11.660
And we developed a bioelectric cocktail that induces it to, to grow.

01:30:11.860 --> 01:30:18.339
My, my, my, my postdoc at the time, Kelly Chang said, um, I, I, I soaked them and I said, well, how long did you, how long did you soak them for?

01:30:18.339 --> 01:30:19.140
And she said an hour.

01:30:19.539 --> 01:30:21.899
And I thought, I felt, but that's gotta be too short.

01:30:21.899 --> 01:30:23.500
There's no way an hour soak is going to do anything.

01:30:23.780 --> 01:30:30.500
And sure enough, that, that hour soak led to, uh, eight days of regeneration where we don't touch it at all.

01:30:30.660 --> 01:30:43.819
And the most recent version of that work is in the frog leg, where we show that 24 hour stimulation with our cocktail induces a year and a half of leg growth during which time we don't touch it at all.

01:30:44.459 --> 01:30:47.339
So the amazing thing there is again, this is not micromanagement.

01:30:47.339 --> 01:30:48.379
This is not 3d printing.

01:30:48.379 --> 01:30:52.899
This is not us telling every cell where to go during this incredible year and a half long process.

01:30:53.140 --> 01:30:59.259
This is at the very earliest moment you communicate to the cells, go down the leg building path, not the scarring path.

01:30:59.300 --> 01:30:59.800
And that's it.

01:30:59.819 --> 01:31:00.660
And then you take your hands off.

01:31:00.860 --> 01:31:02.379
It's, it's, it's calling a subroutine.

01:31:02.379 --> 01:31:03.140
It's modularity.

01:31:03.140 --> 01:31:07.979
It's relying on the competency of the, of the material where you're not going to micromanage it.

01:31:08.179 --> 01:31:17.099
So that was, so that was the first time that kind of became obvious that that was possible is when, when she, she showed that an hour, um, just an hour stimulation of the

01:31:17.099 --> 01:31:21.060
correct bioelectrical state got the whole tail to commit to regenerate itself.

01:31:21.979 --> 01:31:29.939
Uh, so that was, that was the beginning of our regeneration program after which we went into limbs and, uh, and, and, uh, now of course we're trying to push into, into

01:31:29.939 --> 01:31:31.779
mammalian, you know, into mammalian limbs.

01:31:32.059 --> 01:31:41.620
Um, yeah, along, along the, along the way, uh, Celia Herrera-Rincon and, uh, Naroshi Murugan were other postdocs that, uh, that, that showed leg regeneration in frog and so on.

01:31:42.180 --> 01:31:53.180
Um, around, around that time we had, uh, we had another thing we, we really, I really wanted to work on cancer and I really wanted to work on this, um, on this idea that, uh, there's a bioelectric component to it.

01:31:53.180 --> 01:32:00.180
And, and the, and the way you can, you can think about it is simply that not why is there cancer, but why is there anything but cancer?

01:32:00.460 --> 01:32:03.259
So, so why do cells ever cooperate instead of being amoebas?

01:32:03.259 --> 01:32:04.379
Why do they ever cooperate?

01:32:04.620 --> 01:32:14.099
And so we know that the bioelectric signaling is the kind of, um, cognitive glue that, that binds them together towards these large scale construction projects, maintaining organs and things like that.

01:32:14.580 --> 01:32:17.939
And so, um, yeah, so we wanted to study that bioelectrically.

01:32:17.939 --> 01:32:24.180
And so I had, I had two students, uh, Brooke Cherinette and, uh, Maria Labikin who, uh, undertook that.

01:32:24.219 --> 01:32:31.539
And we were able to show that using this bioelectrical imaging, you can tell which cells were going to convert ahead of time.

01:32:31.939 --> 01:32:40.099
You could also convince perfectly normal cells to become metastatic melanoma just by giving them inappropriate bioelectric cues about their environment.

01:32:40.180 --> 01:32:49.059
So you can, you can know, no, no genetic damage, no carcinogens, no oncogenes, but, but just the wrong bioelectric information and they become like metastatic melanoma.

01:32:50.099 --> 01:33:01.499
Um, and, and best of all, they were able to show that you can actually reverse, not reverse, um, carcinogenic stimuli, for example, human oncogenes by appropriate bioelectric connections to their neighbors.

01:33:01.539 --> 01:33:08.020
So we had a whole set of, uh, we had a whole set of papers, um, showing how to, uh, how to control, uh, cells bioelectrically.

01:33:08.180 --> 01:33:14.979
And, uh, uh, Juanita Matthews in my lab now is tracking to take, um, take all those strategies into human, into human cancer.

01:33:15.939 --> 01:33:17.460
So this is 2009?

01:33:17.779 --> 01:33:24.740
This was, yeah, the first, the, the first experiments were, were done around, um, 2010, 2011, something like that.

01:33:25.099 --> 01:33:30.379
So when did this conjectural connection between bioelectricity and cancer occur to you?

01:33:30.779 --> 01:33:32.779
The field was clueless about that.

01:33:32.779 --> 01:33:35.259
It's not as if they had an opinion and said no.

01:33:35.580 --> 01:33:43.259
Well, uh, to, to be, to be, to be clear, the very first person who talked about this was Clarence Cohn in 1971.

01:33:43.580 --> 01:33:56.460
So Clarence Cohn in 71 wrote that, uh, he had a couple of papers, uh, in, in, in science where he showed that, uh, resting potential of cells was an important, um, driver of cell proliferation.

01:33:56.460 --> 01:33:59.580
And he conjectured that it might have something to do with, with, with cancer.

01:33:59.580 --> 01:34:02.059
So this idea had been floated.

01:34:02.059 --> 01:34:03.499
Nobody had ever done anything with it.

01:34:03.499 --> 01:34:10.939
And, and, and they, and the, uh, tools to study this at a molecular level didn't exist until, until we made them.

01:34:11.259 --> 01:34:18.140
So, you know, that, that idea, just, just that bioelectricity is important in cancer had been around before.

01:34:18.460 --> 01:34:24.300
Um, what I think we brought to it that was completely new is the notion of that this is also related to cognition.

01:34:25.020 --> 01:34:44.700
The idea that it's not just that it drives proliferation and cancer, that this is really involved in setting the, limiting the size of the cognitive light cone, at which point cells acquire ancient, uh, you know, um, uh, metastatic like behavior, the way that, um, you know, amoebas do, um, that, that aspect of it, I think is, is completely new with us.

01:34:44.700 --> 01:34:51.340
That, that, that idea that, uh, that this really is about the boundaries of the self, you know, and I've never seen anybody else talk about that.

01:34:51.740 --> 01:35:01.180
So, um, so those, you know, those, those around that same time, there's something else interesting that happened in 2009, which is that we were, we were studying planaria, we were studying flatworms.

01:35:01.499 --> 01:35:19.979
Um, and, uh, we had, uh, we had shown that when you cut planaria into pieces, the way that they, these pieces decide how many heads they were going to have, uh, is actually related to the ability of cells to communicate with each other using gap junctions.

01:35:19.979 --> 01:35:21.420
These, these electrical synapses.

01:35:21.659 --> 01:35:23.460
And so we had made some two headed worms and so on.

01:35:24.020 --> 01:35:33.180
Um, and, uh, around two, 2009, um, I had this, um, had this, uh, student, this visiting student from BU, her name was Larissa.

01:35:33.539 --> 01:35:42.299
And, uh, she, she, we, I asked her to recut the two headed worms and just in plain water, no more, no more manipulation of any kind.

01:35:42.299 --> 01:35:42.619
We, we.

01:35:42.619 --> 01:35:44.660
Recut them, meaning cut off the heads of them?

01:35:44.739 --> 01:35:45.179
Again.

01:35:45.179 --> 01:35:56.460
Yeah.
So, so, so you have a normal one headed worm, you cut off the head and the tail, you have the middle fragment, you, uh, soak that middle fragment in a drug that blocks the cells from electrically communicating with each other and they develop heads at both ends.

01:35:56.619 --> 01:36:00.859
Would that drug that you soak it in be called a biological cocktail?

01:36:00.859 --> 01:36:02.340
Like, is that what you referred to earlier?

01:36:02.540 --> 01:36:04.059
It's a different biological cocktail.

01:36:04.059 --> 01:36:04.939
It wasn't even a cocktail.

01:36:04.939 --> 01:36:06.220
It was a single, one single chemical.

01:36:06.340 --> 01:36:07.379
It was, it was really simple.

01:36:07.379 --> 01:36:10.419
It was just one, one single chemical and all it does is block gap junctions.

01:36:10.419 --> 01:36:17.939
And so, and so what, what that did was change the electric circuit, uh, properties that, that the cells have and they all, and, and both wounds decided they had to be heads.

01:36:18.100 --> 01:36:19.259
So now you get these two headed worms.

01:36:19.819 --> 01:36:28.819
So, so yeah, so, so Larissa, um, recuts these two headed worms in plain water, no more manipulation and she gets more two headed worms.

01:36:28.859 --> 01:36:29.419
It's permanent.

01:36:29.460 --> 01:36:32.419
Once, once you've convinced them, now the genetics are untouched, right?

01:36:32.419 --> 01:36:39.340
No, no, no, uh, no genomic, um, uh, editing, no transgenes, uh, genetically identical.

01:36:39.460 --> 01:36:43.580
But the two worms are, uh, the two headed worms are a permanent line now.

01:36:43.819 --> 01:36:45.700
So, so a couple of interesting things there.

01:36:45.939 --> 01:36:47.059
One is, uh.

01:36:47.500 --> 01:36:52.140
Well, one is, is, is it shows the, um, the interesting memory properties of the medium,

01:36:52.140 --> 01:36:55.900
meaning once you've brought it to a new state, it holds, it remembers the two. So it's a kind

01:36:55.900 --> 01:37:00.460
of memory. It remembers the two headed state. Another interesting thing is that two headed

01:37:00.460 --> 01:37:05.420
worms were first seen, well, they were first described in the early 1900s. So people had

01:37:05.420 --> 01:37:10.620
seen to be made by other, by other means, people had seen two headed worms. Apparently to, to,

01:37:10.620 --> 01:37:14.860
to my knowledge, I don't think anybody's ever, ever written about this. Nobody thought to recut

01:37:14.860 --> 01:37:21.580
them until we did it in 2009. And I think the reason is because it was considered totally

01:37:21.580 --> 01:37:25.019
obvious what would happen. I mean, their genome is normal. You cut off that second ectopic head,

01:37:25.019 --> 01:37:28.780
of course it'll just go back to normal. That's what people assume. So this is, this is another,

01:37:28.780 --> 01:37:34.460
another example of, um, why thinking in these, in these different conceptual ways is, uh, it,

01:37:34.460 --> 01:37:38.379
it matters. It leads to new experiments because if you don't think about this as memory, if you're

01:37:38.379 --> 01:37:43.739
focused on, on the genes as, uh, as driving phenotypes, then you would never, it doesn't

01:37:43.739 --> 01:37:46.940
make any sense to, to recut them. But if you start thinking, well, I wonder if there's a

01:37:46.940 --> 01:37:50.859
physiological memory here, then, then that leads you to this experiment, right? So, so thinking in

01:37:50.859 --> 01:37:56.299
this way leads to, um, leads to new experiments. Um, and then, and then the, and then the other

01:37:56.299 --> 01:38:01.900
thing it points out is something really interesting. So for pretty much any animal model,

01:38:02.460 --> 01:38:06.540
you can call a stock center and you can get genetic, you can get lines of genetic mutants.

01:38:06.540 --> 01:38:11.180
So you can get flies with curly wings and mice with crooked tails and weird coat patterns and,

01:38:11.180 --> 01:38:15.100
you know, chickens with funky TOEs. You can, you can get any, you know, any, any kind of,

01:38:15.100 --> 01:38:21.659
um, uh, any kind of mutant lines. In planaria, there are no mutant lines. Nobody's ever succeeded

01:38:21.659 --> 01:38:27.019
in making anything other than a normal planarian except for our two headed form. And that one's

01:38:27.019 --> 01:38:30.939
not genetic. And so there's a deep reason, which I didn't understand back then. In fact, uh, I

01:38:30.939 --> 01:38:36.059
think we only, I think I only really figured out what I think it means, um, in the last few months.

01:38:36.059 --> 01:38:42.059
But, uh, but, but it was, it was striking that, that the only unusual planarian form permanent

01:38:42.059 --> 01:38:45.820
planarian form out there was the one that we had made. And it was, and that's the one that's not

01:38:45.820 --> 01:38:50.379
genetic. It's not done by the way that you would do this with any other animal. Yeah.

01:38:50.379 --> 01:38:52.220
What's your recent discovery then?

01:38:52.220 --> 01:38:58.219
Well, it's, it's, it's not so much a discovery. It's more of a, um, a new way of thinking about

01:38:58.219 --> 01:39:06.219
it. So, um, so one of the, one of the weird things about planaria is that because the way,

01:39:06.219 --> 01:39:09.260
the way they reproduce, at least the ones that we study, the way they reproduce is

01:39:09.260 --> 01:39:14.460
they tear themselves in half and then each half grows the rest of the body. And, um,

01:39:17.820 --> 01:39:22.379
typically what happens for, for most of us that reproduce by sexual reproduction is that

01:39:22.379 --> 01:39:27.100
when you get mutations in your body during your lifetime, those mutations are not passed

01:39:27.100 --> 01:39:31.180
on to your offspring, right? They, they, they, they disappear with your body and then the eggs

01:39:31.180 --> 01:39:36.859
go on and so on. Well, in planaria, it's not like that in planaria. Um, uh, any mutation that doesn't

01:39:36.859 --> 01:39:41.579
kill the cell gets expanded into the next generation because each half grows, you know,

01:39:41.579 --> 01:39:45.420
grows the new, grows the remainder of the body. And so, so their genome is very messy. They have,

01:39:45.420 --> 01:39:49.100
uh, I mean, in fact, cells can be mixed employed. They can have different numbers of chromosomes.

01:39:49.100 --> 01:39:54.219
And that's, that's very weird. And I always, I always thought, isn't it strange? And nobody

01:39:54.219 --> 01:39:59.100
ever talked about this in any biology class that I've ever had. Isn't it strange that the animal

01:39:59.100 --> 01:40:06.859
that is the most regenerative, uh, apparently immortal, they don't age, uh, cancer resistant,

01:40:06.859 --> 01:40:11.499
and by the way, resistant to transgene. So, so, so nobody is still, nobody's been able to make

01:40:11.499 --> 01:40:16.700
transgenic worms, um, is also the one with the most chaotic genome. And that's bizarre. You would

01:40:16.700 --> 01:40:20.779
think, but from everything that we've, we, we are told about genomes and, and, and how they determine

01:40:20.779 --> 01:40:27.420
phenotypes, that the animal, um, uh, with, with all those amazing properties should have really

01:40:27.420 --> 01:40:32.139
pristine hardware. You would think that, that, that you should have a really clean, really stable

01:40:32.139 --> 01:40:36.139
genome, uh, if you, if you're going to be regenerative and cancer resistant and not age

01:40:36.139 --> 01:40:40.060
and whatever, it's the exact opposite. I always thought that was incredibly weird. And so, so

01:40:40.060 --> 01:40:44.139
finally, I think, uh, and we've done some computational work now to show, to show why

01:40:44.139 --> 01:40:48.700
this is, uh, I think we now understand what's happening and what I think is happening is this.

01:40:48.779 --> 01:40:54.219
Imagine, uh, let's go, let's go back to this issue of, uh, of, of, of developmental problem solving.

01:40:54.779 --> 01:41:00.060
So if you have a, if you had a passive material such that you've got some genes, the genes

01:41:00.060 --> 01:41:04.860
determine what the material does. And so therefore you have an outcome and that outcome gets selected,

01:41:04.860 --> 01:41:08.540
uh, you know, it either does well or not. And then, and then there's differential reproduction.

01:41:08.540 --> 01:41:14.059
So the standard story of evolution, then everything works well and everything works like, uh, it would

01:41:14.059 --> 01:41:19.499
in a genetic algorithm. Very simple, very simple. The problem with it, of course, is that it takes

01:41:19.499 --> 01:41:23.659
forever because let's say that, uh, let's say that you're a tadpole and you have a mutation.

01:41:24.300 --> 01:41:28.779
Mutations usually do multiple things. Let's say this mutation, uh, makes your mouth be off kilter,

01:41:28.779 --> 01:41:31.740
but it also does something else somewhere else in the tail, something positive, somewhere in the

01:41:31.740 --> 01:41:38.059
tail, uh, under the standard, uh, evolutionary paradigm, uh, you would never get to experience

01:41:38.059 --> 01:41:42.140
the positive effects of that, of that mutation because with a mouth being off, you would die

01:41:42.140 --> 01:41:45.820
and that would be that. So selection would weed you out very quickly and you would have to wait

01:41:45.820 --> 01:41:49.740
for a new mutation that gives you the positive effects without the bad effects on the mouth,

01:41:49.740 --> 01:41:54.219
right? So that, that, it's, it's very hard to make new changes without ripping up old gains and so on.

01:41:54.219 --> 01:41:59.339
So that, that, that, that's some of the limitations of, of that kind of view. But, but, but a much

01:41:59.339 --> 01:42:04.540
more realistic scenario is, is the fact that, um, you don't go straight from a genotype to the

01:42:04.540 --> 01:42:08.779
phenotype. You don't go from the genes to the actual body. There's this layer of development

01:42:08.779 --> 01:42:12.700
in the middle. And the thing about development is not just that it's complex, it's that it's

01:42:12.700 --> 01:42:16.860
intelligent, meaning it has problem-solving competencies. So what actually happens in

01:42:16.860 --> 01:42:21.980
tadpoles is if I move the mouth off to the side of the head, uh, within a few weeks,

01:42:21.980 --> 01:42:27.580
it comes back to normal on its own, meaning, meaning it can, it can, um, uh, re, uh, you know,

01:42:28.219 --> 01:42:32.700
reach again that region of anatomical space where it wants to be. So imagine what this means.

01:42:33.899 --> 01:42:37.499
Imagine what this means for evolution when you're evolving a competent substrate,

01:42:37.499 --> 01:42:42.779
not a passive substrate. By the time a nice tadpole goes up for selection to see whether

01:42:42.779 --> 01:42:47.339
it gets to reproduce or not, selection can't really see whether it looks good because the

01:42:47.339 --> 01:42:51.899
genome was great or because the genome was actually so-so, but it fixed whatever, whatever

01:42:51.899 --> 01:42:57.100
issue it had. Right? So, so that competency starts to hide information from selection. So,

01:42:57.100 --> 01:43:01.179
so selection finds it kind of hard to, to choose the best genome because even the ones with

01:43:01.179 --> 01:43:05.820
problems look pretty good by the time it, you know, it's time to be selected. So what happens

01:43:05.820 --> 01:43:12.779
and we did computational simulations of all this, what happens is that, uh, when you, when you do

01:43:12.779 --> 01:43:17.980
this, um, evolution ends up spending all of its effort ramping up the competency because it

01:43:17.980 --> 01:43:22.459
doesn't see the structural genes. All it sees is the competency mechanism. And, and, and if you

01:43:22.459 --> 01:43:26.459
improve the competency mechanism, well, that makes it even harder to see the genome. Right? And so

01:43:26.459 --> 01:43:30.300
you have this ratchet, you have this positive feedback loop where the more, uh, the more

01:43:30.300 --> 01:43:34.619
competent the material is, the harder it is to evolve the actual genome. All the pressure is now

01:43:34.619 --> 01:43:40.059
on the competency. So you end up with kind of like a, like a ladder, um, uh, really an intelligence,

01:43:40.059 --> 01:43:46.700
uh, uh, ratchet because right. And, and, and people like, um, uh, uh, Steve Frank and others

01:43:46.700 --> 01:43:51.179
have pointed this out for, for, you know, in, in, in other aspects of biology and also in technology.

01:43:51.179 --> 01:43:56.700
Right. Once you, um, you know, once rate array technology came up, it's not, it became not as

01:43:56.700 --> 01:44:01.179
important to have really pristine and stable, uh, disk media because the raid or the raid takes care

01:44:01.179 --> 01:44:06.059
of it. Right. So, so the pressure on having really, really stable, um, you know, disc is off.

01:44:06.059 --> 01:44:11.980
So, so, so what it means is that in the case of the planaria, that, that positive feedback loop,

01:44:11.980 --> 01:44:16.379
that ratchet went all the way to the end. That basically what, what happened here is that,

01:44:16.379 --> 01:44:21.980
uh, what you've got is an organism where it is assumed that your hardware is crap. It's assumed

01:44:21.980 --> 01:44:25.980
that you're full of mutations. All the cells have different numbers of chromosomes. We already know

01:44:25.980 --> 01:44:31.339
the genetics are all over the place. Uh, but all of the effort went into developing an algorithm

01:44:31.339 --> 01:44:35.980
that can do the necessary error correction and do, and, and, and take that journey in

01:44:35.980 --> 01:44:41.580
morphospace no matter what the hardware looks like. That is why they don't age. That is why,

01:44:41.580 --> 01:44:45.899
uh, they're resistant to cancer. And that's why nobody can make a transgenic worm because

01:44:45.899 --> 01:44:50.540
they really pay less attention to their genome in that sense than, than many other organisms.

01:44:50.540 --> 01:44:55.100
So you can imagine, um, a sort of continuum. So you've got, um, something like C elegans,

01:44:55.179 --> 01:44:59.179
the nematode where they're pretty cookie cutters. So, so, so as far as we know,

01:44:59.179 --> 01:45:03.260
they don't regenerate much. It's, you know, what you can see, what the genome says is pretty much

01:45:03.260 --> 01:45:07.420
what you get. Then, then you've got some mammals, right? So, so mammals, at least in the embryonic

01:45:07.420 --> 01:45:12.540
stages, they've got some competency. You can chop, you know, early mammalian embryos into pieces and

01:45:12.540 --> 01:45:18.219
you get twins and triplets and so on. Uh, then you get salamanders. Salamanders are really,

01:45:18.219 --> 01:45:22.459
they're quite good regenerators. They're quite resistant to cancer. They are long lived.

01:45:22.459 --> 01:45:27.819
And then, you know, when, when you, when you run that, that spiral all the way to the end,

01:45:27.819 --> 01:45:31.819
you get planaria, which are these amazing things that have committed to the fact that the hardware

01:45:31.819 --> 01:45:36.219
is going to be noisy and that all the effort is going to go into an amazing algorithm that

01:45:36.219 --> 01:45:40.380
lets them do their thing. And, and that's why if you're going to make lines of weird planaria,

01:45:40.380 --> 01:45:44.540
targeting the structural genome is, is not helpful. But if you screw with the, um,

01:45:45.259 --> 01:45:49.740
the actual mechanisms that, uh, that enable the error correction, AKA the bioelectricity,

01:45:49.740 --> 01:45:53.420
that's when you can make lines of double-headed and, and, and, and so on, because now you're

01:45:53.420 --> 01:45:58.699
targeting the actual, uh, uh, you know, the, the, the, the, the problem solving machinery.

01:45:59.579 --> 01:46:03.019
And if you were to look at the genome of the salamander versus the C. elegans,

01:46:03.019 --> 01:46:06.620
would the C. elegans be more chaotic or more ordered than the salamander?

01:46:06.620 --> 01:46:11.100
It's a good question. So nobody's done that specifically. No, as far as I know, this is,

01:46:11.100 --> 01:46:14.459
this is something that we're just ramping up to do now is to start, uh.

01:46:14.459 --> 01:46:18.459
Because correct me if I'm, if I'm incorrect, it sounds like the hypothesis is that

01:46:18.459 --> 01:46:29.500
if you have a large amount of genetic chaos, or what, if you can quantify that.
Then you would have something that would be compensated for in terms of competency or some higher level structure.

01:46:29.500 --> 01:46:33.500
Yeah, I think that, yes, I think that's a, that's a prediction of, of, of this model that I just laid out.

01:46:33.500 --> 01:46:39.500
And so, yeah, so we can test that. I mean, a part of it also is, uh, there, there's an ecological component.

01:46:39.500 --> 01:46:42.300
I mean, you can ask the question, so why doesn't everything end up like planaria?

01:46:42.300 --> 01:46:49.500
And I think there's a, there's an aspect of this that, that, that, that ratchet obviously doesn't run to the end in every, in every scenario.

01:46:49.500 --> 01:46:52.699
Because in some species, there's a better trade-off to be had somewhere else.

01:46:52.699 --> 01:46:58.699
I wonder if there are three components then, because then if you don't see a direct correlation, it could be hidden by a third factor.

01:46:58.699 --> 01:47:08.300
Yeah, which, which I think would probably be environment. It would, it would probably be the ecology of how do you reproduce, um, you know, how noisy, how dangerous, how unpredictable is your environment.

01:47:08.300 --> 01:47:18.300
I'm going to guess there's something like that involved here. Yeah, but I think, but I think that's, um, you know, that's, that's, that's starting to kind of explain what's going on with, with, with planaria.

01:47:18.300 --> 01:47:33.499
And that, uh, yeah, that, so, so, so those, so, so we found, um, uh, we, we, we found the persistence of the two-headed phenotype and then, um, Nestor Oviedo and, uh, Junji Morikuma, um, in my group, uh, wrote a, wrote a nice paper on that and, and so on.

01:47:33.499 --> 01:47:43.099
And then the next kind of big advance, uh, there by, in, in 2017 was by Fallon Durant, um, a grad student in my lab who also did something interesting.

01:47:43.099 --> 01:47:57.739
So, so when you take a bunch of worms and you, uh, you treat them with, let's say this reagent that blocks the gap junctions, typically what you see is, okay, you, you treat a hundred worms, 70% of them go on to make two heads and 30% are unaffected.

01:47:57.739 --> 01:48:10.139
So we thought they were unaffected because they stay one-headed and we always, uh, we always call them escapees because we thought that they somehow just escaped the action of the octenal, maybe their skin was a little thicker or something and we never had a good explanation for it.

01:48:10.220 --> 01:48:16.459
But, but anyway, uh, you know, we had, there was a 70% penetrance to the phenotype and most things have not a hundred percent phenotype.

01:48:16.459 --> 01:48:17.020
So it wasn't...

01:48:17.020 --> 01:48:17.739
Penetrance?

01:48:17.739 --> 01:48:24.539
A penetrance just means that, um, when you apply some treatment to a population, not all of them have an effect and not all of them have the same effect.

01:48:24.539 --> 01:48:27.419
That's true for pretty much every, every drug, every mutation and so on.

01:48:28.220 --> 01:48:46.620
So, um, so for years we called them escapees and then, um, uh, around 2015 when Fallon joined the lab, she recut some of those one-headed escapees and found that they also do 70-30, that 70% of them became double-headed and 30% didn't.

01:48:46.620 --> 01:48:53.900
And so what we realized was that they're not actually escapees, they're not unaffected, they're affected, but the way they're affected is quite different.

01:48:53.900 --> 01:48:55.420
They are randomized.

01:48:55.420 --> 01:49:03.340
They can't tell if they should be one-headed or two-headed and they flip a coin set with a 70-30 bias about what they should do in any given generation.

01:49:03.340 --> 01:49:13.099
In fact, we were able to show that when you cut multiple pieces from the same worm, and we call them cryptic worms, cryptic because physically they look completely normal, one head, one tail, they look normal, but they're not normal.

01:49:13.099 --> 01:49:15.739
And, and because, because if you recut them, they're not sure what to do.

01:49:15.739 --> 01:49:18.539
Their memories are, are bistable.

01:49:18.620 --> 01:49:31.179
So what happens is that you can cut them into pieces and every piece makes its own decision if it's going to be one-headed or two-headed, even though they came from the same, you know, the same parent organism, uh, with the same roughly 70-30, um, frequency.

01:49:31.179 --> 01:49:35.260
So, so there, so, so that's another, uh, kind of permanent line.

01:49:35.260 --> 01:49:38.939
And the way we studied it more recently was as a kind of perceptual bistability.

01:49:38.939 --> 01:49:40.939
So, so like the rabbit-duck illusion, right?

01:49:40.939 --> 01:49:43.260
You look at it and you look, it looks like one thing looks like something else.

01:49:43.260 --> 01:49:45.260
That's kind of, um, what's happening here.

01:49:45.260 --> 01:49:53.579
There's a bioelectrical pattern that can be interpreted in one of two ways and, and that's why they're, they're confused, you know, they're sort of bistable and it can fall in, in, in either direction.

01:49:53.579 --> 01:49:57.579
Um, so that's, that's another thing we, uh, you know, we did in, in, in Planaria.

01:49:57.579 --> 01:49:59.579
Okay, so that's 2017.

01:49:59.579 --> 01:50:03.579
I'm going to get you to bring us up to 2020 and then to 2024.

01:50:03.579 --> 01:50:05.579
But first, what is meant?

01:50:05.579 --> 01:50:10.060
Explain to myself, what is meant when you say Levin Lab?

01:50:10.060 --> 01:50:12.060
So there's also Huberman Lab.

01:50:12.299 --> 01:50:22.299
Do biologists, do professors who are in neuroscience or biology get given a lab by the university as the standard?

01:50:22.299 --> 01:50:24.299
Do you share a lab with other people?

01:50:24.299 --> 01:50:26.299
What's meant by lab?

01:50:26.299 --> 01:50:28.299
Is it a room?

01:50:28.299 --> 01:50:30.299
What is it?

01:50:30.299 --> 01:50:32.299
Yeah.

01:50:32.299 --> 01:50:34.299
Um, okay.

01:50:34.299 --> 01:50:36.299
So, so the way, the way this works is basically that, uh, when you're finishing up your postdoc, you, uh, you do what people call going out on the market, which means you interview at a bunch of places and see who will hire you as a brand new, um, junior faculty member.

01:50:36.299 --> 01:50:38.299
So when you get a job, and so this is, this is, you know, considered your first real independent job because, uh, you are now in charge of all your successes and failures.

01:50:38.299 --> 01:50:40.299
It's all, it's all up to you.

01:50:40.299 --> 01:50:42.299
And typically, uh, yes, at that point you get a lab.

01:50:42.299 --> 01:50:44.299
So one of the things you do is you negotiate, uh, the amount of space you have.

01:50:44.299 --> 01:50:46.299
Typically you start off pretty small.

01:50:46.299 --> 01:50:48.299
Um, and then over time, if you bring in new grants, then you ask for more space and the lab grows.

01:50:48.299 --> 01:50:50.299
And when they say Levin Lab or Huberman Lab, what they're just referring to is the, um, all of the research that is controlled by you where you make the decisions, you know, where that person gets the job.

01:50:50.299 --> 01:50:52.299
And so typically, uh, when you get a job, you do what people call going out on the market, which means you interview at a bunch of places and see who will hire you as a brand new, junior faculty member.

01:50:52.299 --> 01:50:54.299
And typically, uh, yes, at that point you get a lab.

01:50:54.299 --> 01:50:56.299
So one of the things you do is you negotiate, uh, the amount of space you have.

01:50:56.299 --> 01:50:58.299
Typically you start off pretty small.

01:50:58.299 --> 01:51:00.299
Um, and then over time, if you bring in new grants, then you ask for more space and the lab grows.

01:51:00.299 --> 01:51:20.299
And when they say Levin Lab or Huberman Lab, what they're just referring to is the, um, all of the research that is controlled by you where you make the decisions, you know, where that particular person makes the decisions.

01:51:20.299 --> 01:51:42.299
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:51:42.299 --> 01:52:04.299
And typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:52:04.299 --> 01:52:26.299
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:52:26.299 --> 01:52:48.299
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:52:48.299 --> 01:53:16.299
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:53:16.299 --> 01:53:44.299
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:53:44.299 --> 01:54:12.299
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:54:12.299 --> 01:54:40.299
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:54:40.299 --> 01:55:08.300
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:55:08.300 --> 01:55:36.300
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:55:36.300 --> 01:56:04.300
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:56:04.300 --> 01:56:05.300
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:56:06.700 --> 01:56:08.700
And so typically, uh, when you get a job, you do what people call going out on the market, which means you negotiate, uh, the amount of space you have.

01:56:16.700 --> 01:56:20.700
So um, I wanted you to get as far away from Prague and Embryo as possible because, because I wanted to show that this was a kind of general and abroad department. So what's the furthest you can get from embryonic frog adult human so. So.

01:56:20.700 --> 01:56:22.700
So um, I wanted you to get as far away from Prague and Embryo as possible because, because I wanted to show that this was a kind of general and a lot of broader phenomena. So what's the furthest you can get from embryonic frog adult human so.

01:56:22.700 --> 01:56:24.700
So um, I wanted you to get as far away from Prague and Embryo as possible because, because I wanted to show that this was a kind of general and a lot of broader phenomena.

01:56:24.700 --> 01:56:28.700
So um, I wanted you to get as far away from Prague and Embryo as possible because, because I wanted to show that this was a kind of general and a lot of broader phenomena.

01:56:54.700 --> 01:56:58.700
So um, I wanted you to get as far away from Prague and Embryo as possible because, because I wanted to show that this was a kind of general and a lot of broader phenomena.

01:57:24.700 --> 01:57:28.700
So um, I wanted you to get as far away from Prague and Embryo as possible because, because I wanted to show that this was a kind of general and a lot of broader phenomena.

01:57:54.700 --> 01:57:58.700
I want you to get as far away from Prague as possible because, because I wanted you to get as far away from Prague and Embryo as possible because, because I wanted you to get as far away from Prague as possible.

01:58:24.700 --> 01:58:31.700
You don't just want agency, you want agency that's attuned to yourself because you can get someone else's agency and it's not great for you.

01:58:54.700 --> 01:58:56.700
This is something they do on their own.

01:58:56.700 --> 01:59:06.700
Who would have ever thought that your tracheal cells, which sit there quietly for decades, if you let them have a little life of their own, they can actually go around and fix neural wounds.

01:59:06.700 --> 01:59:10.700
You must have had some idea that this would be possible, otherwise you wouldn't have tested it, no?

01:59:10.700 --> 01:59:12.700
True, true, yes.

01:59:12.700 --> 01:59:19.700
This is true for a lot of stuff in our lab where people say, well, did you know that was going to happen?

01:59:19.700 --> 01:59:26.700
And so, on the one hand, no, because it's a wild and it wasn't predicted by any existing structures.

01:59:26.700 --> 01:59:34.700
On the other hand, yes, because we did the experiment and that's why I did it, because I had an intuition that that's how this thing would work.

01:59:34.700 --> 01:59:39.700
So, did I know that it was going to specifically repair peripheral innervation?

01:59:39.700 --> 01:59:48.700
No, but I did think that it would, that among its behavioral repertoire would be to exert positive influence on human cells around it.

01:59:48.700 --> 01:59:50.700
And so, this was a convenient assay to try.

01:59:50.700 --> 01:59:52.700
We have a hundred more that we're going to try. There's all kinds of other stuff.

01:59:52.700 --> 01:59:55.700
Yes, I see, I see. So, you're testing out a variety.

01:59:55.700 --> 01:59:57.700
Correct. You have to start somewhere, right?

01:59:57.700 --> 02:00:02.700
And so, we said, okay, so Gizem and I said, well, why don't we try a nice, easy neural scar?

02:00:02.700 --> 02:00:05.700
There's many other things to try.

02:00:05.700 --> 02:00:11.700
So, that's kind of the practical application, but the kind of bigger intellectual issue is, much like with the xenobots,

02:00:11.700 --> 02:00:19.700
what's cool about making these sorts of synthetic constructs is that they don't have a long evolutionary history in that form factor.

02:00:19.700 --> 02:00:24.700
There's never been any xenobots, there's never been any anthropots in the evolutionary history.

02:00:24.700 --> 02:00:28.700
The anthropots don't look anything like stages of human development.

02:00:28.700 --> 02:00:35.700
And so, the question arises, where do their form and behavior come from then, right?

02:00:35.700 --> 02:00:38.700
And so, this is where you get back to this issue of the platonic space, right?

02:00:38.700 --> 02:00:46.700
If you can't pin it on eons of specific selection for specific functions, where do these novel capabilities come from?

02:00:46.700 --> 02:00:51.700
And so, I really view all of these synthetic constructs as exploration vehicles.

02:00:51.700 --> 02:00:55.700
They're ways to look around in that platonic space and see what else is out there.

02:00:55.700 --> 02:01:02.700
We know normal development shows us one point in that space that says, this is the form that's there.

02:01:03.700 --> 02:01:10.700
But once you start making these synthetic things, you widen your view of that latent space as to what's actually possible.

02:01:10.700 --> 02:01:18.700
And I see this research program as really investigating the structure of that platonic space in the way that mathematicians, you know, people make the map of mathematics, right?

02:01:18.700 --> 02:01:21.700
And there's sort of a structure of how the different pieces of math fit together.

02:01:21.700 --> 02:01:33.700
I think that's actually what we're doing here when we make these synthetic things, is we're making vehicles to observe what else is possible in that space that evolution has not shown us yet.

02:01:34.700 --> 02:01:35.700
Yeah.

02:01:35.700 --> 02:01:44.700
So, oh, you know, and then you can do interesting things like, and this is still unpublished, but you can ask questions like, what do their transcriptomes look like?

02:01:44.700 --> 02:01:47.700
You know, what genes do xenobots and anthrobots express?

02:01:47.700 --> 02:01:58.700
And, you know, without blowing any of the sort of surprise, the paper should be out sometime this year, massively new transcriptional profiles in these things.

02:01:58.700 --> 02:02:03.700
No drugs, no synthetic biology circuits, no genomic editing.

02:02:03.700 --> 02:02:09.700
Just by virtue of having a new lifestyle, they adapt their transcriptional profile.

02:02:09.700 --> 02:02:12.700
The genes that they express are quite different.

02:02:12.700 --> 02:02:13.700
Quite different.

02:02:13.700 --> 02:02:15.700
So that'll be an interesting study.

02:02:15.700 --> 02:02:25.700
And then, you know, for the rest of it, I mean, what we've been doing in the last few years is trying to bring a lot of the work that we've done earlier into clinically relevant models.

02:02:25.700 --> 02:02:30.700
So the cancer stuff has moved from frog into human cells and organoids, spheroids.

02:02:30.700 --> 02:02:36.700
So human cancer spheroids and glioblastoma, colon cancer, stuff like that.

02:02:36.700 --> 02:02:39.700
The regeneration work has moved from frog into mice.

02:02:40.700 --> 02:02:41.700
You know, it's coming along.

02:02:41.700 --> 02:02:44.700
I'm not claiming any particular result yet.

02:02:44.700 --> 02:02:56.700
I should also say there's an invention, what do you call it, a disclosure here I have to do because we have a couple of companies now.

02:02:56.700 --> 02:03:04.700
And so I have to, you know, I have to do a disclosure that in the case of regeneration, so Morphoceuticals is a company that Dave Kaplan and I have.

02:03:04.700 --> 02:03:15.700
So David is a bioengineer here at Tufts and he and I have this company aiming at limb regeneration and more broadly bioelectrics in regeneration.

02:03:15.700 --> 02:03:30.700
So, yeah, so the cancer, the limb regeneration stuff, you know, more experiments in trying to understand how to read and interpret the information that flows across levels.

02:03:31.700 --> 02:03:35.700
So we know cells exchange electrical signals to know how to make an embryo.

02:03:35.700 --> 02:03:38.700
Turns out embryos actually communicate with each other.

02:03:38.700 --> 02:03:42.700
So that's been a really exciting finding recently for Angela Tong in my group.

02:03:42.700 --> 02:03:54.700
We just got her PhD as well where we studied this embryo to embryo communication showing that groups of embryos actually are much better at resisting certain defects than individuals.

02:03:54.700 --> 02:03:56.700
And they have their own transcriptional profiles.

02:03:56.700 --> 02:03:59.700
So I call it a hyper embryo because it's like the next level.

02:03:59.700 --> 02:04:05.700
They have an expression and transcriptome that is different from normal embryos developing alone, let's say.

02:04:05.700 --> 02:04:07.700
So that's pretty exciting.

02:04:07.700 --> 02:04:11.700
And, yeah, those are the kinds of things we've been focused on.

02:04:11.700 --> 02:04:18.700
Okay, now we're going to end on advice for a newcomer to biology.

02:04:18.700 --> 02:04:20.700
They're entering the field.

02:04:20.700 --> 02:04:21.700
What do you say?

02:04:21.700 --> 02:04:25.700
Boy, well, step one is to ignore most people's advice.

02:04:25.700 --> 02:04:28.700
So that's, I don't know how helpful that will be.

02:04:28.700 --> 02:04:31.700
But I actually have a whole thing about it.

02:04:31.700 --> 02:04:32.700
Maybe we can put up a link.

02:04:32.700 --> 02:04:36.700
I have a whole long description of this on my blog.

02:04:36.700 --> 02:04:40.700
So on my blog, I have a thing that basically talks about advice.

02:04:40.700 --> 02:04:42.700
Okay, that's on screen.

02:04:42.700 --> 02:04:46.700
Also, you should know that the previous research by Angela Tong and Gamaskaya.

02:04:46.700 --> 02:04:48.700
Yeah, Gizem Gamaskaya.

02:04:48.700 --> 02:04:50.700
We did a podcast together.

02:04:50.700 --> 02:04:52.700
So that link will be on screen as well.

02:04:52.700 --> 02:04:55.700
There's also another podcast with Michael Levin, which is on screen.

02:04:55.700 --> 02:05:00.700
And then another one, which is on screen with Chris Fields and Carl Friston.

02:05:00.700 --> 02:05:02.700
Another one with Michael Levin and Joscha Bach.

02:05:02.700 --> 02:05:03.700
That's on screen.

02:05:03.700 --> 02:05:06.700
So Michael is a legend on theories of everything.

02:05:06.700 --> 02:05:13.700
Okay, so does your advice for the biologist differ from your advice to the general scientist entering the field?

02:05:13.700 --> 02:05:20.700
I mean, the most important thing I'll say is I do not in any way feel like I could be giving anybody advice.

02:05:20.700 --> 02:05:28.700
I think that there are so many individual circumstances that I'm not going to claim I have any sort of—

02:05:28.700 --> 02:05:32.700
How about what you would have wished you had known when you were 20?

02:05:33.700 --> 02:05:39.700
So this is pretty much the only thing I can say about any of this.

02:05:39.700 --> 02:05:47.700
That even very smart, successful people—

02:05:48.050 --> 02:05:52.090
are only well-calibrated on their own field,

02:05:52.090 --> 02:05:54.050
their own things that they are passionate about.

02:05:54.050 --> 02:05:56.730
They're not well-calibrated on your stuff.

02:05:56.730 --> 02:05:59.850
So what that means is that if somebody gives you—

02:05:59.850 --> 02:06:02.130
So this is all about—it's kind of meta-advice.

02:06:02.130 --> 02:06:04.330
It's all about advice on advice.

02:06:04.330 --> 02:06:07.849
And the idea is that when somebody gives you a critique

02:06:07.849 --> 02:06:09.170
of a specific product—

02:06:09.170 --> 02:06:11.050
so let's say you gave a talk or wrote a paper

02:06:11.050 --> 02:06:12.250
or you did an experiment

02:06:12.250 --> 02:06:15.570
and somebody's critiquing what you did, right?

02:06:15.570 --> 02:06:18.009
That's gold. So squeeze the hell out of that

02:06:18.009 --> 02:06:20.370
for any way to improve your craft.

02:06:20.370 --> 02:06:21.610
What could I have done better?

02:06:21.610 --> 02:06:23.570
What could I have done better to do a better experiment?

02:06:23.570 --> 02:06:25.290
What could I have done better in my presentation

02:06:25.290 --> 02:06:28.570
so that they would understand what I want them to understand?

02:06:28.570 --> 02:06:29.730
That's gold.

02:06:29.730 --> 02:06:33.050
The part where everybody gives large-scale advice—

02:06:33.050 --> 02:06:35.050
Oh, work on this. Don't work on that.

02:06:35.050 --> 02:06:37.570
Focus. Don't think of it this way.

02:06:37.570 --> 02:06:38.770
Think of it that way.

02:06:38.770 --> 02:06:41.649
All of that stuff is, generally speaking,

02:06:41.649 --> 02:06:43.809
better off ignored completely.

02:06:43.809 --> 02:06:50.809
So people are really not calibrated on you,

02:06:50.809 --> 02:06:53.810
your dreams in the field, your ideas.

02:06:56.810 --> 02:06:59.569
It does not pay to listen to anybody else

02:06:59.569 --> 02:07:02.170
about what you should be doing and how.

02:07:02.170 --> 02:07:03.090
You really need to be—

02:07:03.090 --> 02:07:05.889
everybody needs to be developing their own intuition

02:07:05.889 --> 02:07:08.730
about what that is and testing it out by doing things

02:07:08.730 --> 02:07:10.689
and seeing how they land.

02:07:10.689 --> 02:07:14.329
And I think that most everything

02:07:14.329 --> 02:07:17.050
that we've done along the way that's interesting—

02:07:17.050 --> 02:07:18.410
and certainly we've had plenty of dead ends

02:07:18.410 --> 02:07:20.810
and made plenty of mistakes—

02:07:20.810 --> 02:07:23.050
but most of the interesting things

02:07:23.050 --> 02:07:24.810
that our lab has done along the way,

02:07:24.810 --> 02:07:28.530
very, very good, very successful smart people said,

02:07:28.530 --> 02:07:31.170
Don't do this. There's no way this is going to lead to anything.

02:07:31.170 --> 02:07:35.009
And so the only thing I know is that paths in science are—

02:07:35.009 --> 02:07:36.450
nobody has a crystal ball.

02:07:36.450 --> 02:07:38.490
Paths in science are very hard to predict,

02:07:38.490 --> 02:07:41.969
and people should really be very circumspect

02:07:41.969 --> 02:07:45.009
about taking extremely seriously

02:07:45.009 --> 02:07:46.889
specific critiques of specific things

02:07:46.889 --> 02:07:48.889
that will help them improve their process

02:07:48.889 --> 02:07:52.370
versus these large-scale sort of career-level things

02:07:52.370 --> 02:07:54.889
that, yeah, I don't think you should be taking

02:07:54.889 --> 02:07:57.290
almost anybody's advice about that.

02:07:57.290 --> 02:07:58.930
Can you be specific and give an example

02:07:58.930 --> 02:08:02.010
of where you like the minutiae of a critique

02:08:02.010 --> 02:08:06.010
and then where you disliked the grand-scale critique?

02:08:06.010 --> 02:08:08.889
Yeah, I mean, the minutiae happens every day

02:08:08.889 --> 02:08:13.689
because, you know, every day we get comments on,

02:08:13.689 --> 02:08:15.729
you know, let's say a paper submission,

02:08:15.729 --> 02:08:17.570
and we see and somebody says,

02:08:17.570 --> 02:08:20.689
Well, you know, it would have been better

02:08:20.689 --> 02:08:24.609
if you included this control or I don't get it because,

02:08:24.609 --> 02:08:31.210
you know, it's clear that the reviewer

02:08:31.210 --> 02:08:32.689
didn't understand what you were trying to get at.

02:08:32.689 --> 02:08:34.169
And so that's on us.

02:08:34.169 --> 02:08:36.809
That's on us to describe it better,

02:08:36.809 --> 02:08:38.689
to do a better experiment that forces them

02:08:38.689 --> 02:08:40.729
to accept the conclusion whether they like it or not, right?

02:08:40.729 --> 02:08:44.490
The best experiment is one that really,

02:08:44.490 --> 02:08:47.130
it forces the reader to a specific conclusion,

02:08:47.130 --> 02:08:48.570
whether or not they want it to go there.

02:08:48.570 --> 02:08:49.650
It's irresistible.

02:08:49.650 --> 02:08:50.889
It's so compelling.

02:08:50.889 --> 02:08:52.329
You know, it's clean. It's compelling.

02:08:52.329 --> 02:08:54.449
So that kind of stuff happens on a daily basis

02:08:54.449 --> 02:08:56.850
where you see what somebody was

02:08:56.850 --> 02:08:58.889
and wasn't able to absorb from what you did,

02:08:58.889 --> 02:09:00.850
and you say, Okay, how can I do this experiment better?

02:09:00.850 --> 02:09:02.809
What kind of a result would have gotten us

02:09:02.850 --> 02:09:04.249
to a better conclusion

02:09:04.249 --> 02:09:06.370
where everybody would have, you know, been able to see?

02:09:06.370 --> 02:09:08.770
So that stuff happens all the time.

02:09:08.770 --> 02:09:11.969
The other kind of thing, I mean, I'll give you an example

02:09:11.969 --> 02:09:16.249
from the tail regeneration kind of era.

02:09:16.249 --> 02:09:18.930
We showed that normally,

02:09:18.930 --> 02:09:21.889
when tadpoles normally regenerate their tail,

02:09:21.889 --> 02:09:23.089
there's a particular proton pump

02:09:23.089 --> 02:09:24.930
that's required for that to happen,

02:09:24.930 --> 02:09:28.410
you know, a proton pump in the frog embryo.

02:09:28.410 --> 02:09:30.089
And so what we showed is that you can get rid

02:09:30.130 --> 02:09:30.969
of that proton pump,

02:09:30.969 --> 02:09:33.010
and then the tail stops regenerating,

02:09:33.010 --> 02:09:34.770
and then you can rescue it

02:09:34.770 --> 02:09:36.889
by putting in a proton pump from yeast

02:09:36.889 --> 02:09:39.249
that has no sequence of structural homology

02:09:39.249 --> 02:09:41.930
to the one you knocked out of the frog,

02:09:41.930 --> 02:09:44.650
but it has the same bioelectric effect, right?

02:09:44.650 --> 02:09:45.490
And that's how you show

02:09:45.490 --> 02:09:47.490
that it really is bioelectricity, right?

02:09:47.490 --> 02:09:49.689
So we got two reviews on that paper,

02:09:49.689 --> 02:09:51.529
and the first reviewer said,

02:09:51.529 --> 02:09:53.889
Oh, you found the gene for tail regeneration.

02:09:53.889 --> 02:09:56.529
That proton pump is the gene for tail regeneration.

02:09:56.529 --> 02:09:57.770
Get rid of all the electrical stuff.

02:09:57.770 --> 02:09:58.609
You don't need it.

02:09:58.609 --> 02:10:00.410
You don't need the gene for tail regeneration.

02:10:00.410 --> 02:10:03.089
The second reviewer said,

02:10:03.089 --> 02:10:05.490
Oh, the gene obviously doesn't matter

02:10:05.490 --> 02:10:07.490
because you just replace it by the proton pump,

02:10:07.490 --> 02:10:10.009
so by the one from yeast.

02:10:10.009 --> 02:10:11.250
Yeah, get rid of all of that

02:10:11.250 --> 02:10:13.690
and just do the bioelectrical stuff, right?

02:10:13.690 --> 02:10:14.889
So that shows you right away

02:10:14.889 --> 02:10:16.609
that two different perspectives, right?

02:10:16.609 --> 02:10:18.770
Each person had a particular way

02:10:18.770 --> 02:10:19.889
they wanted to look at it.

02:10:19.889 --> 02:10:22.930
They had exactly opposite suggestions

02:10:22.930 --> 02:10:25.090
for what to throw out of the paper.

02:10:25.090 --> 02:10:28.169
And only together do those two perspectives

02:10:28.169 --> 02:10:30.210
explain that what's going on here is that,

02:10:30.210 --> 02:10:33.129
yes, the embryo naturally has a way

02:10:33.129 --> 02:10:34.930
of producing that bioelectrical state,

02:10:34.930 --> 02:10:36.490
but what actually matters is not the gene.

02:10:36.490 --> 02:10:37.930
It's not how you got there.

02:10:37.930 --> 02:10:39.530
It's the state itself, right?

02:10:39.530 --> 02:10:41.129
And so that kind of a thing,

02:10:41.129 --> 02:10:42.409
those kind of perspectives,

02:10:42.409 --> 02:10:47.409
or the people who are upset at,

02:10:49.569 --> 02:10:51.690
for example, calling xenobots bots, right?

02:10:51.690 --> 02:10:52.530
We call them bots

02:10:52.530 --> 02:10:55.490
because we think it's a biorobotics platform.

02:10:55.490 --> 02:10:57.370
So one thing that happens is that

02:10:58.409 --> 02:11:02.409
you've got the people that are sort of

02:11:02.409 --> 02:11:03.810
from the organicist tradition,

02:11:03.810 --> 02:11:04.650
and they'll say,

02:11:04.650 --> 02:11:06.370
it's not a robot, it's a living thing.

02:11:06.370 --> 02:11:08.129
How dare you call it a robot?

02:11:09.129 --> 02:11:12.849
And part of the issue is that all of these terms,

02:11:12.849 --> 02:11:14.849
much like the cognitive terms that we talked about,

02:11:14.849 --> 02:11:17.530
it's not that the xenobot is or isn't a robot.

02:11:17.530 --> 02:11:20.490
It's simply the idea that by using these different,

02:11:20.490 --> 02:11:21.329
using different terms,

02:11:21.329 --> 02:11:23.490
what you're signaling is what are some of the ways

02:11:23.490 --> 02:11:25.289
that you could have a relationship with it?

02:11:25.289 --> 02:11:26.129
So for example,

02:11:26.129 --> 02:11:27.449
we think that we might be able to program it

02:11:27.449 --> 02:11:29.090
to use it for useful purposes.

02:11:29.090 --> 02:11:32.650
That's what the terminology bot emphasizes.

02:11:32.650 --> 02:11:34.329
Do I think it's only a xenobot?

02:11:34.329 --> 02:11:35.169
Absolutely not.

02:11:35.169 --> 02:11:36.530
I also think it's a proto-organism

02:11:36.530 --> 02:11:39.250
with its own limited agency

02:11:39.250 --> 02:11:41.490
and its own things that we haven't published yet,

02:11:41.490 --> 02:11:45.250
which we're working on their learning capacity and so on.

02:11:45.250 --> 02:11:47.530
So you often run into that,

02:11:47.530 --> 02:11:50.449
is that people think everything should only be one thing,

02:11:50.449 --> 02:11:53.810
and that this is all a debate about which thing is it.

02:11:53.810 --> 02:11:57.090
And I don't think that's true at all.

02:11:57.770 --> 02:12:00.810
There's another, just kind of one last example,

02:12:00.810 --> 02:12:02.889
again, having to do with terminology.

02:12:02.889 --> 02:12:04.090
Somebody said to me once,

02:12:05.690 --> 02:12:09.210
people are very resistant to the use of the word memory

02:12:09.210 --> 02:12:11.050
for some of the things that we study.

02:12:11.050 --> 02:12:11.889
And she said,

02:12:11.889 --> 02:12:15.169
why don't you just come up with a new term,

02:12:15.169 --> 02:12:16.129
shmemory or something.

02:12:16.129 --> 02:12:17.569
And then nobody has to be mad.

02:12:17.569 --> 02:12:18.490
You can say, okay,

02:12:18.490 --> 02:12:20.530
this is human learning is memory.

02:12:20.530 --> 02:12:22.129
And then this other thing where these other things learn,

02:12:22.129 --> 02:12:22.970
well, that's shmemory.

02:12:22.970 --> 02:12:25.650
So then, and that's the kind of-

02:12:25.690 --> 02:12:26.690
Shmem intelligence.

02:12:26.690 --> 02:12:27.770
Why are you calling it intelligence?

02:12:27.770 --> 02:12:28.849
Yeah, exactly.

02:12:28.849 --> 02:12:30.169
And that's the kind of, okay,

02:12:30.169 --> 02:12:32.050
so that's just an example of the kind of advice

02:12:32.050 --> 02:12:33.250
you might get from somebody.

02:12:33.250 --> 02:12:34.490
And in a certain sense,

02:12:34.490 --> 02:12:36.849
it's true that if you do that,

02:12:36.849 --> 02:12:38.530
you will have fewer fights with people

02:12:38.530 --> 02:12:40.050
who are very purist about,

02:12:40.050 --> 02:12:42.009
they want memory to be in a very particular box.

02:12:42.009 --> 02:12:43.129
You'll have less fights with those.

02:12:43.129 --> 02:12:44.129
Those are true.

02:12:44.129 --> 02:12:46.770
But bigger picture though, imagine,

02:12:46.770 --> 02:12:50.210
so there's Isaac Newton and the apples fall.

02:12:50.210 --> 02:12:51.770
I mean, I know it didn't really probably happen,

02:12:51.770 --> 02:12:54.210
but the apples fall on the tree and he says, okay.

02:12:54.210 --> 02:12:56.849
So gravity, I'm going to call gravity

02:12:56.849 --> 02:12:59.690
the thing that keeps the moon in orbit of the earth.

02:12:59.690 --> 02:13:01.009
And then I'm going to call shmemory

02:13:01.009 --> 02:13:02.250
the thing that makes the apple fall.

02:13:02.250 --> 02:13:03.770
That way there won't be any arguments, right?

02:13:03.770 --> 02:13:06.409
Like, yeah, but what you've done there

02:13:06.409 --> 02:13:07.889
is you've missed the biggest opportunity

02:13:07.889 --> 02:13:09.569
of the whole thing, which is the unification.

02:13:09.569 --> 02:13:11.090
The thing that, the fact that actually,

02:13:11.090 --> 02:13:12.129
no, the hill you want to die on

02:13:12.129 --> 02:13:14.050
is that it really is the same thing.

02:13:14.050 --> 02:13:15.289
You don't want a new term for it.

02:13:15.289 --> 02:13:18.129
So that's just an example of the kind of,

02:13:18.129 --> 02:13:21.250
it's good advice if you want to avoid arguments,

02:13:21.250 --> 02:13:24.050
but if your point is that, no, it actually is,

02:13:24.889 --> 02:13:25.729
that's the whole point.

02:13:25.729 --> 02:13:27.090
We need to have a better understanding of memory.

02:13:27.090 --> 02:13:30.169
I want those arguments, then that's something else.

02:13:30.169 --> 02:13:34.090
And that's the kind of strategic thing

02:13:34.090 --> 02:13:36.370
that you should decide on your own what you want to do.

02:13:36.370 --> 02:13:38.409
Now, in that case, why couldn't you just say,

02:13:38.409 --> 02:13:40.210
actually, it wouldn't have been a mistake

02:13:40.210 --> 02:13:42.289
for Newton to call this one gravity one

02:13:42.289 --> 02:13:45.129
and that one gravity two until he proves

02:13:45.129 --> 02:13:47.289
that they're the same mathematically,

02:13:47.289 --> 02:13:48.169
just like they're different.

02:13:48.169 --> 02:13:50.930
There's inertial mass and then there's another form of mass

02:13:50.930 --> 02:13:53.690
and then you have the equivalence principle.

02:13:54.329 --> 02:13:55.609
Yeah, you could.

02:13:55.609 --> 02:13:59.650
The thing is that, my point is-

02:13:59.650 --> 02:14:02.009
The issue is that we never know a priori

02:14:02.009 --> 02:14:04.210
whether we're supposed to unify or distinguish.

02:14:04.210 --> 02:14:05.289
That's correct, yes.

02:14:05.289 --> 02:14:06.169
No, true, true, true.

02:14:06.169 --> 02:14:07.210
A priori, you don't know.

02:14:07.210 --> 02:14:10.650
And so the question is, in your own research program,

02:14:10.650 --> 02:14:12.609
which road do you want to go down to?

02:14:12.609 --> 02:14:17.289
Because if you commit to the fact that they're separate,

02:14:17.289 --> 02:14:21.010
you don't do the, you don't try the unification, right?

02:14:21.010 --> 02:14:23.370
You try the unification, you spend your time.

02:14:24.050 --> 02:14:24.890
I mean, it takes years, right?

02:14:24.890 --> 02:14:27.250
You spend time and effort in a particular direction

02:14:27.250 --> 02:14:28.930
because you feel it will pay off.

02:14:28.930 --> 02:14:31.529
If it were truly, you know,

02:14:31.529 --> 02:14:32.849
wow, it could be this or that,

02:14:32.849 --> 02:14:35.289
are you going to spend 10 years on one of these paths, right?

02:14:35.289 --> 02:14:37.050
You really need to in science.

02:14:37.050 --> 02:14:37.890
There's no do-overs.

02:14:37.890 --> 02:14:39.810
Like you commit, those 10 years are gone.

02:14:39.810 --> 02:14:42.169
So you need to have a feeling

02:14:42.169 --> 02:14:43.130
or you need to have an intuition

02:14:43.130 --> 02:14:44.209
of which way it's gonna go.

02:14:44.209 --> 02:14:45.969
And you definitely don't need to declare ahead of time

02:14:45.969 --> 02:14:47.969
that I know how it's gonna turn out because you don't.

02:14:47.969 --> 02:14:49.370
But you do need to know,

02:14:49.370 --> 02:14:51.010
despite everybody telling me this or that,

02:14:51.010 --> 02:14:51.849
I am going to commit.

02:14:51.849 --> 02:14:53.130
That's really all you have, right?

02:14:53.769 --> 02:14:55.050
You don't have any kind of crystal ball.

02:14:55.050 --> 02:14:56.250
You don't have a monopoly on the truth,

02:14:56.250 --> 02:14:58.769
but what you do have is a responsibility

02:14:58.769 --> 02:15:00.649
to manage the limited time that you have.

02:15:00.649 --> 02:15:02.690
So how are you going to spend your 10 years?

02:15:02.690 --> 02:15:04.050
And it's gonna be hard, right?

02:15:04.050 --> 02:15:05.130
Lots of blood, sweat, and tears.

02:15:05.130 --> 02:15:05.969
It's a hard job.

02:15:05.969 --> 02:15:08.649
There's constant criticism and that's how science goes.

02:15:09.690 --> 02:15:12.050
Lots of stress.

02:15:12.050 --> 02:15:13.849
But so now the question is,

02:15:13.849 --> 02:15:15.209
are you going to have that stress

02:15:15.209 --> 02:15:18.289
following somebody else's research agenda or yours?

02:15:18.289 --> 02:15:20.289
You'll still be old and stressed out by the end of it.

02:15:20.289 --> 02:15:21.130
But the question is,

02:15:21.130 --> 02:15:23.010
will you have tested out your own best ideas

02:15:23.769 --> 02:15:25.130
or somebody else's view of what science should be?

02:15:25.130 --> 02:15:26.849
That's my only hope.

02:15:26.849 --> 02:15:28.969
Well, Michael, speaking of limited time,

02:15:28.969 --> 02:15:30.969
I appreciate you spending yours with.

02:15:31.120 --> 02:15:35.840
With me and with the crew here today. Super. Thanks so much. Thank you so much.

02:15:36.720 --> 02:15:41.280
Thank you. Thank you so much. Yeah, it's great to see you again. Great discussion. I love talking

02:15:41.280 --> 02:15:46.400
to you. Thanks for having me so many times. It's been really excellent. So Taylor Swift has a tour

02:15:46.400 --> 02:15:51.519
called the Eras Tour. Okay. Okay. You've been around since 2000, active in the field. Okay.

02:15:51.519 --> 02:15:58.240
This is akin to the Michael Levin Eras Tour. All of Michael's work, well, not all of it, but

02:15:58.240 --> 02:16:06.000
the milestones, the greatest hits in approximately two hours or so. So share this if you're a fan of

02:16:06.000 --> 02:16:11.439
Michael's work and well, Michael, thank you. Thank you so much. I really appreciate it. Thank you.

02:16:29.040 --> 02:16:33.840
That's just part of the terms of service. Now, a direct mailing list ensures that I have an

02:16:33.840 --> 02:16:40.240
untrammeled communication with you. Plus soon I'll be releasing a one page PDF of my top 10 TOEs.

02:16:40.240 --> 02:16:45.359
It's not as Quentin Tarantino as it sounds like. Secondly, if you haven't subscribed or clicked

02:16:45.359 --> 02:16:52.480
that like button, now is the time to do so. Why? Because each subscribe, each like helps YouTube

02:16:52.480 --> 02:16:59.280
push this content to more people like yourself. Plus it helps out Curt directly, AKA me. I also

02:16:59.280 --> 02:17:03.280
found out last year that external links count plenty toward the algorithm, which means that

02:17:03.280 --> 02:17:08.960
whenever you share on Twitter, say on Facebook or even on Reddit, et cetera, it shows YouTube,

02:17:08.960 --> 02:17:14.880
Hey, people are talking about this content outside of YouTube, which in turn greatly aids the

02:17:14.880 --> 02:17:19.600
distribution on YouTube. Thirdly, there's a remarkably active discord and subreddit for

02:17:19.600 --> 02:17:24.639
theories of everything where people explicate TOEs. They disagree respectfully about theories

02:17:24.639 --> 02:17:30.399
and build as a community, our own TOE links to both are in the description. Fourthly, you should

02:17:30.399 --> 02:17:36.319
know this podcast is on iTunes. It's on Spotify. It's on all of the audio platforms. All you have

02:17:36.319 --> 02:17:40.719
to do is type in theories of everything and you'll find it. Personally, I gained from rewatching

02:17:40.719 --> 02:17:46.240
lectures and podcasts. I also read in the comments that, Hey, TOE listeners also gain from replaying.

02:17:46.240 --> 02:17:51.120
So how about instead you read, listen on those platforms like iTunes, Spotify, Google podcasts,

02:17:51.120 --> 02:17:56.719
whichever podcast catcher you use. And finally, if you'd like to support more conversations like

02:17:56.719 --> 02:18:02.160
this, more content like this, then do consider visiting patrion.com slash Curt Jaimungal and

02:18:02.160 --> 02:18:06.880
donating with whatever you like. There's also PayPal. There's also crypto. There's also just

02:18:06.880 --> 02:18:12.639
joining on YouTube. Again, keep in mind it's support from the sponsors and you that allow me

02:18:12.639 --> 02:18:17.839
to work on TOE full time. You also get early access to add free episodes, whether it's audio

02:18:17.839 --> 02:18:22.400
or video it's audio in the case of Patreon video in the case of YouTube. For instance, this episode

02:18:22.400 --> 02:18:27.439
that you're listening to right now was released a few days earlier. Every dollar helps far more

02:18:27.439 --> 02:18:31.919
than you think. Either way, your viewership is generosity enough. Thank you so much.

