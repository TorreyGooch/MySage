WEBVTT
Kind: captions
Language: en-US

00:00:00.080 --> 00:00:05.920
But I think we are actually&nbsp;
a collection of interacting&nbsp;&nbsp;

00:00:05.920 --> 00:00:10.640
perspectives and interacting consciousnesses.
And you know, then sometimes people say, well,&nbsp;&nbsp;

00:00:10.640 --> 00:00:15.240
I don't feel my liver being conscious.
Right, you don't, but you don't feel me&nbsp;&nbsp;

00:00:15.240 --> 00:00:17.000
being conscious either.
Of course you don't.&nbsp;

00:00:17.000 --> 00:00:21.560
And the fact that your left hemisphere has&nbsp;
the language ability for us to sit here and&nbsp;

00:00:21.560 --> 00:00:26.160
talk about it and the liver doesn't, doesn't&nbsp;
actually mean that it's not conscious.&nbsp;

00:00:26.160 --> 00:00:31.200
It just means that we don't have direct access&nbsp;
to it, and we don't have direct access to&nbsp;

00:00:31.200 --> 00:00:33.920
each other.
So that doesn't, that doesn't bother me.&nbsp;

00:00:33.920 --> 00:00:38.880
So I, that's, that's my suspicion about, about&nbsp;
consciousness is that for the same reason&nbsp;

00:00:38.880 --> 00:00:42.600
that people think it's in the brain, we should&nbsp;
take very seriously that it's in other places&nbsp;

00:00:42.600 --> 00:00:45.640
in the body.
And then, and then more, more generally,&nbsp;&nbsp;

00:00:45.640 --> 00:00:51.520
you know, other, other types of constructs that
are not human bodies at all, or not even&nbsp;&nbsp;

00:00:51.520 --> 00:00:53.320
animal bodies.
We've spoken&nbsp;&nbsp;

00:00:53.320 --> 00:00:57.840
to Bernardo Kastrup several times now.
What is it you agree with him the most&nbsp;&nbsp;

00:00:57.840 --> 00:01:02.200
that you think most people would disagree about?
Because you agree with him that it's nice to go&nbsp;&nbsp;

00:01:02.200 --> 00:01:03.160
for a walk.
Okay, sure.&nbsp;

00:01:03.160 --> 00:01:09.000
But most people agree it's nice to go for a walk.
So what is it that you agree with him about that&nbsp;&nbsp;

00:01:09.000 --> 00:01:11.040
you think is a contentious issue to most
people?&nbsp;

00:01:11.040 --> 00:01:14.800
So this isn't, this is a controversial statement.
And then what is it you disagree with&nbsp;&nbsp;

00:01:14.800 --> 00:01:19.640
him about regarding consciousness?
Yeah, boy, I don't, you know, it's hard for&nbsp;&nbsp;

00:01:19.640 --> 00:01:22.360
me to know what most people agree or disagree
with him about.&nbsp;

00:01:22.360 --> 00:01:26.440
I really don't know.
We agree on a lot of things.&nbsp;

00:01:26.440 --> 00:01:29.920
We agree on, I think, the&nbsp;
primacy of consciousness.&nbsp;

00:01:30.440 --> 00:01:36.280
I think that, you know, his idealist&nbsp;
position has a lot of, a lot to recommend it.&nbsp;

00:01:36.840 --> 00:01:42.800
One thing I think we disagree on&nbsp;
is the issue of compositionality.&nbsp;

00:01:42.800 --> 00:01:48.240
So if I recall correctly from a talk that&nbsp;
we had together a little while ago, he felt&nbsp;

00:01:48.240 --> 00:01:53.640
that it is important in order to be a true&nbsp;
self, to be a, to be, to, to have a conscious&nbsp;

00:01:53.640 --> 00:01:59.960
experience as an inner perspective.
You have to be, you know, he focuses&nbsp;&nbsp;

00:01:59.960 --> 00:02:05.280
on the view of embryonic development as a single
system that, you know, whatever subdivides and&nbsp;&nbsp;

00:02:05.280 --> 00:02:08.080
develops, but it, but it starts out as
a single system.&nbsp;

00:02:08.080 --> 00:02:14.760
And I was arguing that that really is&nbsp;
just a, a contingent feature of biology.&nbsp;

00:02:14.760 --> 00:02:17.720
I mean, we certainly can take two, two&nbsp;
early embryos and mush them together.&nbsp;

00:02:17.720 --> 00:02:20.160
You get a perfectly normal,&nbsp;
you know, embryo out of it.&nbsp;

00:02:20.160 --> 00:02:24.520
And in general, there are lots of biological&nbsp;
systems like our, our xenobots, like, like&nbsp;

00:02:24.520 --> 00:02:30.680
anthrobots that you can, you can create by&nbsp;
composition, by pulling other things together.&nbsp;

00:02:30.680 --> 00:02:37.200
So I don't give as much, I don't put as much&nbsp;
emphasis on a system being demarcated from&nbsp;

00:02:37.200 --> 00:02:41.280
the outside world because it was somehow,&nbsp;
because it started out that way and it sort&nbsp;

00:02:41.280 --> 00:02:45.960
of remained, you know, disconnected.
I think those are, I think that's kind of&nbsp;&nbsp;

00:02:45.960 --> 00:02:48.840
a superficial aspect of the biology and you
can do things a different way.&nbsp;

00:02:48.840 --> 00:02:52.200
I don't think that's what,&nbsp;
what's responsible for it.&nbsp;

00:02:52.200 --> 00:02:55.920
But, but he, you know, I, I, yeah, I think,&nbsp;
I think he thinks it's important that, that&nbsp;

00:02:55.920 --> 00:03:00.920
individual selves are not compositions,&nbsp;
they're not made as compositions.&nbsp;

00:03:00.920 --> 00:03:05.520
They're somehow, you know, individualized&nbsp;
from the word go, which again, even the egg,&nbsp;

00:03:05.520 --> 00:03:08.960
right?
So, so we, I mean, we, we, humans like eggs&nbsp;&nbsp;

00:03:08.960 --> 00:03:11.240
because we can see it as a distinct little
thing with a membrane.&nbsp;

00:03:11.240 --> 00:03:13.120
We can say, ah, there's a,&nbsp;
you know, an individual,&nbsp;&nbsp;

00:03:13.120 --> 00:03:17.400
but, but, but even an egg is composed by the
maternal organism from molecular components.&nbsp;

00:03:17.400 --> 00:03:22.640
Like I, I see, I see no, no point at which&nbsp;
any of this is, is truly distinct from, from&nbsp;

00:03:22.640 --> 00:03:24.880
anything else.
So, so I put less emphasis on it,&nbsp;&nbsp;

00:03:24.880 --> 00:03:28.760
but I, but I think he thinks it's important.
It seems like the point that you're saying is,&nbsp;&nbsp;

00:03:28.760 --> 00:03:31.600
look, we can think about this as several
rooms.&nbsp;

00:03:31.600 --> 00:03:36.200
This building comprises several rooms, but&nbsp;
even in, and Bernardo may say, that's what&nbsp;

00:03:36.200 --> 00:03:39.920
makes a person is the distinct rooms, but&nbsp;
you're saying, yeah, but even in a room, there&nbsp;

00:03:39.920 --> 00:03:41.440
are different people.
There are different chairs.&nbsp;

00:03:41.440 --> 00:03:43.680
There are different tables.
Is that what you're saying?&nbsp;

00:03:43.680 --> 00:03:46.840
What I'm saying is, and, and I, you know,&nbsp;
I may not be doing justice to his view, and&nbsp;

00:03:46.840 --> 00:03:51.480
I think, I think you should ask him more about&nbsp;
this, but, um, I think he thinks that it's&nbsp;

00:03:51.480 --> 00:03:55.400
important in order to be a unified, so, so&nbsp;
I think we were discussing what makes for&nbsp;

00:03:55.400 --> 00:03:57.400
a unified inner perspective, right?&nbsp;

00:03:57.400 --> 00:04:00.720
So, so we don't feel like, uh,&nbsp;
billions of individual brain cells.&nbsp;

00:04:00.720 --> 00:04:03.760
I mean, I have no idea why, well, we kind&nbsp;
of do because that's what it feels like to&nbsp;

00:04:03.760 --> 00:04:08.600
be billions of individual set of neurons.
That's really what it feels like, but, um,&nbsp;&nbsp;

00:04:08.600 --> 00:04:13.000
but we do feel at least most of us, most of
the time, feel like some kind of unified,&nbsp;&nbsp;

00:04:13.000 --> 00:04:16.040
centralized inner perspective, and so we were
talking about how that comes about,&nbsp;&nbsp;

00:04:16.040 --> 00:04:23.600
and I think he felt that having that in, in the
physical universe is, uh, importantly related to,&nbsp;&nbsp;

00:04:23.600 --> 00:04:29.080
um, arising from a single origin, a single,
so he sees the egg as a single point of origin,&nbsp;&nbsp;

00:04:29.080 --> 00:04:33.000
and, and arising from that, that's how you
are a separate individual from others,&nbsp;&nbsp;

00:04:33.000 --> 00:04:37.840
and I see it as much more fluid, and I see the
boundary between self and world as&nbsp;&nbsp;

00:04:37.840 --> 00:04:41.320
something that can change all the time.
I think it changes in embryogenesis, and that's&nbsp;&nbsp;

00:04:41.320 --> 00:04:44.880
the scale of, that's the story of the scaling
of the cognitive licon that we talked about.&nbsp;

00:04:44.880 --> 00:04:49.520
I think it can shrink during cancer, uh, I&nbsp;
think it can change during metamorphosis,&nbsp;

00:04:49.520 --> 00:04:53.600
during maturation, um, I, I think, I&nbsp;
think it's much more fluid than that.&nbsp;

00:04:53.600 --> 00:04:57.600
Now, as we're on speculative ground, if what&nbsp;
makes an agent is the distinction between&nbsp;

00:04:57.600 --> 00:05:02.600
the self and the world, and some people think&nbsp;
of God as the entirety of everything, thus&nbsp;

00:05:02.600 --> 00:05:09.800
the entire world, and there's no distinction,&nbsp;
then can one say that God is an agent?&nbsp;

00:05:09.800 --> 00:05:16.240
I, I don't know, I, I mean, certainly I think&nbsp;
most, uh, well, religions that have a, that&nbsp;

00:05:16.240 --> 00:05:20.400
have a God, anyway, as far as my understanding&nbsp;
is, they would think that, yes, that God has,&nbsp;

00:05:20.400 --> 00:05:23.440
uh, extreme agency, in fact,&nbsp;
higher than, than ours.&nbsp;

00:05:23.440 --> 00:05:29.800
I, I, I don't know what that really buys us,&nbsp;
um, you know, in any, in any, uh, helpful&nbsp;

00:05:29.800 --> 00:05:31.160
way.
Um,&nbsp;&nbsp;

00:05:31.160 --> 00:05:36.760
remove the word God, does the world have agency?
Okay, so, so that's an interesting question.&nbsp;

00:05:36.760 --> 00:05:40.640
So, so let's start with, first of all,&nbsp;
how do we know when anything has agency?&nbsp;

00:05:40.640 --> 00:05:43.640
And that's an, that's an&nbsp;
experimental research program.&nbsp;

00:05:43.640 --> 00:05:48.480
So you basically, you hypothesize what, uh,&nbsp;
problem space it's working in, what you think&nbsp;

00:05:48.480 --> 00:05:52.120
its goals are, and then you do experiments&nbsp;
to figure out what competency it has, and&nbsp;

00:05:52.120 --> 00:05:56.240
then you find out, did I guess well, poorly,&nbsp;
do I need to make a better guess, and so on.&nbsp;

00:05:56.240 --> 00:06:01.200
So, uh, for example, um, uh, people have&nbsp;
said, uh, to me, well, you know, your kind&nbsp;

00:06:01.200 --> 00:06:06.440
of, uh, panpsychist, uh, almost view says that&nbsp;
the weather should be, you know, cognitive,&nbsp;

00:06:06.440 --> 00:06:11.240
and I, you know, I, I say, uh, I don't say&nbsp;
that it is or isn't because we haven't done&nbsp;

00:06:11.240 --> 00:06:14.800
the experiments.
Do I know that, uh, weather systems, let's&nbsp;&nbsp;

00:06:14.800 --> 00:06:18.480
say, let's say hurricanes or so on, do I know
that they don't show habituation sensitization,&nbsp;&nbsp;

00:06:18.480 --> 00:06:22.320
that they couldn't be trained if you had the
right, uh, scale of, of machinery?&nbsp;

00:06:22.320 --> 00:06:25.040
I have no idea.
But what I do know is that it's not a,&nbsp;&nbsp;

00:06:25.040 --> 00:06:29.040
um, this is not a philosophical, uh, thing that
we can decide arguing in an armchair.&nbsp;

00:06:29.040 --> 00:06:30.000
Yes, it is.
No, it isn't.&nbsp;

00:06:30.000 --> 00:06:32.000
No, you have to do experiments,&nbsp;
and then you find out.&nbsp;

00:06:32.000 --> 00:06:34.960
So, now, the question is, okay, so&nbsp;
what about, you know, the galaxy?&nbsp;

00:06:34.960 --> 00:06:36.360
What about the universe?
Right?&nbsp;

00:06:36.360 --> 00:06:41.320
Are these the, you know, Gaia, um, ecosystems?
Again, I think these are all empirical questions.&nbsp;

00:06:41.320 --> 00:06:47.040
Now, some of them are intractable, you know, we&nbsp;
don't have the capability to do, um, experiments&nbsp;

00:06:47.040 --> 00:06:50.920
on a, uh, on a, on a planetary scale, but&nbsp;
for example, one thing that I did try to do&nbsp;

00:06:50.920 --> 00:06:57.680
once was design a gravitational synapse,&nbsp;
so design a solar system size arrangement&nbsp;

00:06:57.680 --> 00:07:01.680
where masses would fly in, and based on the&nbsp;
history of masses flying in, it would respond&nbsp;

00:07:01.680 --> 00:07:04.480
to new masses in a different way.
So, you can do, you know, historicity,&nbsp;&nbsp;

00:07:04.480 --> 00:07:07.360
and you can have habituation and sensitization
and things like that.&nbsp;

00:07:07.360 --> 00:07:11.880
So, could, could you have something like that&nbsp;
that would be very, sort of, ponderously slowly&nbsp;

00:07:11.880 --> 00:07:15.840
on an enormous scale, computing something and&nbsp;
having, you know, sort of simple thoughts?&nbsp;

00:07:15.840 --> 00:07:18.080
I bet you could.
You know, I bet you could.&nbsp;

00:07:18.080 --> 00:07:20.160
Um, is the real universe doing that?
I have no idea.&nbsp;

00:07:20.160 --> 00:07:23.320
You'd have to do experiments.
So, so, you know, here, here, you&nbsp;&nbsp;

00:07:23.320 --> 00:07:29.520
bump up against another question, which is, how do
you know if, if, and when you are part of a larger&nbsp;&nbsp;

00:07:29.520 --> 00:07:31.080
cognitive system?
Right?&nbsp;

00:07:31.080 --> 00:07:34.680
So, so I don't, you know, how do we know if&nbsp;
we are, in fact, part of a bigger, a bigger&nbsp;

00:07:34.680 --> 00:07:36.760
mind?
So, I, I don't know.&nbsp;

00:07:36.760 --> 00:07:41.120
Um, and my suspicion is that there are some&nbsp;
sort of GÃ¶del-like theorem that will tell&nbsp;

00:07:41.120 --> 00:07:45.080
you that you can never know for sure, uh,&nbsp;
and you can, you can, you know, you can never&nbsp;

00:07:45.080 --> 00:07:50.200
be certain, but I bet that you could gather&nbsp;
evidence for it, well, for or against.&nbsp;

00:07:50.200 --> 00:07:57.160
And I often think about, um, a kind of a, um,&nbsp;
uh, uh, you know, kind of a mental, mental&nbsp;

00:07:57.160 --> 00:07:58.040
image.
Just imagine&nbsp;&nbsp;

00:07:58.040 --> 00:08:01.840
two neurons in the brain and one is&nbsp;
a, is a, you know, kind of a, kind&nbsp;

00:08:01.840 --> 00:08:04.000
of a strict materialist and&nbsp;
one's a little more mystical.&nbsp;

00:08:04.000 --> 00:08:09.360
And the one neuron says, look, uh, you know,&nbsp;
we're, we're, we're just, we just run on chemistry&nbsp;

00:08:09.360 --> 00:08:12.080
and the outside world is a cold&nbsp;
mechanical universe and it doesn't.&nbsp;

00:08:12.080 --> 00:08:16.680
care what we do. There's no mind outside of us.&nbsp;
And the other one says, I can't prove it, but I&nbsp;

00:08:16.680 --> 00:08:20.760
kind of feel like there's an order to things. And&nbsp;
I kind of feel like our environment is not stupid.&nbsp;

00:08:20.760 --> 00:08:25.440
I kind of feel like our environment wants things&nbsp;
from us. And I kind of feel these waves of, you&nbsp;

00:08:25.440 --> 00:08:29.720
know, these waves backpropagating through us that&nbsp;
are like almost rewards and punishments. I feel&nbsp;

00:08:29.720 --> 00:08:34.400
like the universe is trying to tell us something.&nbsp;
And the first one says, yeah, you're just seeing,&nbsp;

00:08:34.400 --> 00:08:40.320
you know, faces and clouds. It doesn't exist.&nbsp;
And of course, in my example, the second one is&nbsp;

00:08:40.320 --> 00:08:44.320
correct because they are in fact part of a larger&nbsp;
system. They're part of a brain that is learning&nbsp;

00:08:44.320 --> 00:08:50.320
things. And it's very hard for any one node in&nbsp;
that system to recognize that or even a sub, you&nbsp;

00:08:50.320 --> 00:08:56.520
know, sub network. But I wonder if we&nbsp;
could, uh, having, having a, you know,&nbsp;&nbsp;

00:08:56.520 --> 00:08:59.560
a degree of intelligence
ourselves, if we could gain&nbsp;&nbsp;

00:08:59.560 --> 00:09:03.360
evidence that we were part of a&nbsp;
larger system that was actually&nbsp;

00:09:03.360 --> 00:09:08.680
processing information. And I don't, I don't know&nbsp;
exactly what that would look like, but my hunch&nbsp;

00:09:08.680 --> 00:09:12.720
is that it would look like what we call&nbsp;
synchronicity. I think that what it would look&nbsp;

00:09:12.720 --> 00:09:23.080
like are, um, coincidence, our events that don't&nbsp;
have a, uh, causal connection at our lower level,&nbsp;

00:09:23.080 --> 00:09:27.520
like, like mechanistically, like by physics,&nbsp;
there's no reason why that should be, but at a&nbsp;

00:09:27.520 --> 00:09:33.640
larger scale in terms of meaning and, um, uh, you&nbsp;
know, grant grant grant the greater meanings of&nbsp;

00:09:33.640 --> 00:09:37.800
things that, that they do have some kind of&nbsp;
interpretation. And I think that's what it would&nbsp;

00:09:37.800 --> 00:09:41.480
look like to be part of a larger system. I&nbsp;
think it would look, it would look and feel like&nbsp;

00:09:41.480 --> 00:09:46.080
synchronicity. So does it exist either? You know,&nbsp;
I don't know, but that that's what I think it&nbsp;

00:09:46.080 --> 00:09:52.200
would feel like. If you enjoyed this TOE clipping,&nbsp;
then the full video is linked in the description.&nbsp;

00:09:52.200 --> 00:09:57.080
You should also sign up for TOEmail, which is&nbsp;
again in the description and the pinned comment,&nbsp;

00:09:57.080 --> 00:10:02.320
you'll receive immediate access to all exclusive&nbsp;
updates from the theories of everything podcast.&nbsp;

00:10:02.320 --> 00:10:07.000
It also helps me communicate directly with the&nbsp;
core TOE community. You'll also receive my top 10&nbsp;

00:10:07.000 --> 00:10:11.720
TOEs. Think of it as the intellectual&nbsp;
version of Quentin Tarantino's obsession.

